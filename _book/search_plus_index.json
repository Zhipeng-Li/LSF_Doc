{"./":{"url":"./","title":"前言","keywords":"","body":"LSF handbook 内容简介 主要内容是 IBM 官方 LSF manual 的文档翻译，具体内容涉及 LSF 的产品介绍、安装升级、用户操作、作业调度、集群运维、功能开发及拓展等。 其次结合译者的工作需求，会有一些相关知识点的增补，与实际操作经验的总结。大致包含 Linux 运行环境的常见服务配置、vim 编辑器操作、系统性能调优、队列日志分析、EDA 作业优化、同类调度器（Slurm/PBS）的功能对比等等。 重点章节 依照 Part > Chapter > Section > Subsection > Article 的行文结构 Part I 入门介绍篇 chapter1 LSF 介绍 重点： lsf 快速入门章节 chapter2 安装、升级与迁移 Part II 基础操作篇 chapter3 用户操作基础 重点：文件目录，LSF 守护程序与进程，作业生命周期，调度策略 chapter4 管理员操作基础 重点：重要配置文件、服务的启动，资源管理等，日志排错 Part III 作业调度篇 chapter5 作业调度管理 重点：LSF daemons 相关， bsub 命令参数及功能 Part IV 集群运维篇 chapter6 集群维护管理 重点： chapter7 参考文档 重点： Part V 功能拓展篇 chapter8 LSF 拓展 chapter9 最佳实践与建议 Part VI 经验总结篇 chapter10 Linux 操作进阶 重点：常见服务操作、免密、文件服务器、bash脚本编程、vim编辑器等 chapter11 实际实施经验 重点：日志分析，高级调度策略实施等 chapter12 调度器产品对比、行业领域结合等 重点：slurm，PBS等 译作初衷 IBM 旗下的作业调度系统 LSF， 作为一款在 HPC 领域内应用广泛的商业调度器，其 manual 是针对多种商业客户而编写的，文档受众主要是各大中小型企业的集群管理者，其次则为数量更多的集群使用者，与少部分功能开发者。但实际上，因为每个企业 / 非企业级用户的软硬件基础架构，与业务场景会有不同，所以，作为集群的管理者，除了需要熟悉官网中介绍的功能操作外，也有必要结合实际的工作需求，基于所在行业，进行实际经验的总结与梳理等。 故而，本 LSF 中文手册是从集群管理及二次开发者的角度出发，基于 LSF manual，进行的一些翻译与增补，鉴于译者水平精力有限，出现错误纰漏之处在所难免，希望读者不吝批评指正。 版本 基于 版本为 LSF 10.1.0 的 LSF manual。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter1/LSF_introduction.html":{"url":"chapter1/LSF_introduction.html","title":"Chapter 1 LSF 介绍","keywords":"","body":"Chapter 1 LSF 介绍 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 21:54:54 "},"chapter1/section1/brief_introduction.html":{"url":"chapter1/section1/brief_introduction.html","title":"1.1 LSF 简介","keywords":"","body":"1.1 LSF 简介 Spectrum LSF: 高效的集群管理系统 计算机通过执行程序，帮助科研人员进行科学研究。通常，计算机的使用者不关心程序的执行过程，他们只希望更快更有效地获取运算结果。而为了提供强大的计算能力，大量的计算资源以集群的形式出现。集群系统的使用和有效管理都面临着挑战。 LSF（Load Sharing Facility）是一款分布式集群管理系统软件，负责计算资源的管理和批处理作业的调度。它给用户提供统一的集群资源访问接口，让用户透明地访问整个集群资源。同时提供了丰富的功能和可定制的策略。LSF 具有良好的可伸缩性和高可用性，支持几乎所有的主流操作系统。它通常是高性能计算环境中不可或缺的基础软件。 LSF 虽然是一款商业软件，但它同时也提供免费的社区版供大家下载和使用。 简单的使用 LSF 的使用者可以大约分为两类，普通用户和集群系统管理员。普通用户可以通过命令，将计算程序提交给集群执行，获取计算结果。系统管理员可以通过配置文件和管理命令，管理集群以及统计计算资源的使用情况。 图 1. LSF 结构图 普通用户提交可执行程序或脚本给 LSF。LSF 将已提交的程序称为作业。作业在LSF 的队列 (Queue) 里排队 (PEND) ，等待调度。 清单 1. 提交作业 lsfrhel01 # bsub –R \"linux\" sleep 1000 Job is submitted to default queue . lsfrhel01 # bjobs JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME 1 tom PEND normal lsfrhel01 *eep 1000 May 9 15:42 LSF 根据配置的调度策略，把作业分配到最合适的计算节点上执行 (RUN) 。用户可以通过命令行查看，控制作业的执行过程。除此之外，LSF 还为用户提供了作业修改，需求描述，作业控制等多种命令行工具。 清单 2. 查看运行作业 lsfrhel01 # bjobs JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME 1 tom RUN normal lsfrhel01 lsfrhel02 *eep 1000 May 9 15:42 系统管理员通常需要了解整个集群系统中作业和资源的使用状况，LSF 提供的命令帮助管理员快速直观地看到系统概况：系统中队列的状态，机器的状态，作业的资源使用概况，等等。除此之外，LSF 还为管理员提供了丰富的集群配置，控制，管理等功能。 清单 3. 查看 LSF 系统信息 lsfrhel01 # bqueues normal QUEUE_NAME PRIO STATUS MAX JL/U JL/P JL/H NJOBS PEND RUN SUSP normal 30 Open:Active - - - - 1 0 1 0 lsfrhel01 # bhosts HOST_NAME STATUS JL/U MAX NJOBS RUN SSUSP USUSP RSV lsfrhel01 ok - 4 0 0 0 0 0 lsfrhel02 ok - 8 1 1 0 0 0 lsfrhel01 # bacct Accounting information about jobs that are: - submitted by users tom, - accounted on all projects. - completed normally or exited - executed on all hosts. - submitted to all queues. - accounted on all service classes. ------------------------------------------------------------------------------ SUMMARY: ( time unit: second ) Total number of done jobs: 1 Total number of exited jobs: 4 Total CPU time consumed: 4.4 Average CPU time consumed: 0.9 Maximum CPU time of a job: 4.3 Minimum CPU time of a job: 0.0 Total wait time in queues: 276962.0 Average wait time in queue:55392.4 Maximum wait time in queue:276953.0 Minimum wait time in queue: 2.0 Average turnaround time: 60739 (seconds/job) Maximum turnaround time: 276953 Minimum turnaround time: 12 Average hog factor of a job: 0.00 ( cpu time / turnaround time ) Maximum hog factor of a job: 0.00 Minimum hog factor of a job: 0.00 Average expansion factor of a job: 55610.95 ( turnaround time / run time ) Maximum expansion factor of a job: 276953.00 Minimum expansion factor of a job: 1.00 Total Run time consumed: 6981 Average Run time consumed: 1396 Maximum Run time of a job: 6914 Minimum Run time of a job: 0 Total throughput: 409.09 (jobs/hour) during 0.01 hours Beginning time: May 9 15:39 Ending time: May 9 15:40 基本概念 LSF 是资源管理的工具，它管理的主要对象有三个方面：机器（节点），作业和用户。 一般情况下，集群中的机器都是对等的，称为服务节点（Sever Host）。它们既可以提交作业，也可以执行作业。按照职能的不同，服务节点可以有不同的身份。管理作业调度资源的节点称为主节点（Master host），一个集群只有一个主节点。对于一次作业提交来说，提交作业的节点为提交节点（Submission host），被分配并执行作业的节点是执行节点（Execution host）。 图 2. 节点角色 为了便于机器的管理，LSF 提供节点组（Host group）的概念。任意的机器集合可以被作为整体命名，通过名字在集群范围内整体引用。一种典型的用法是将节点按照内存大小进行分类：大内存节点组和小内存节点组。不同的作业可以请求不同的节点组，LSF 按照请求，分配该节点组中的机器来执行作业。节点组还有一个灵活的特性：为方便管理，同一台机器可以定义到不同的节点组。 图 3. 节点分组 作业占用机器资源进行计算。每一个机器被划分成若干个槽位（slot） 。每一个槽位通常可以容纳一个作业运行。 通常情况下，每一个槽位和一个CPU 核心（core）相对应。槽位是一个容易混淆的概念，为便于理解，可以将槽位等同于CPU 核心来看待。对于并行作业来说，比如MPI 作业，每一个都需要占用更多的槽位加速计算。 作业的管理是以队列（Queue）为单位的，调度的策略也是按照队列定制的。作为作业的容器，可以配置多个队列定制不同策略。LSF 按照队列的优先级，从高到低调度每一个队列中的作业，为其分配资源。高优先级队列的作业对资源的使用具有优先权。 图 4. 调度方式 　　 用户是作业提交者，也是资源的真正使用者。对于资源和作业的管理，不少策略都是以用户为单位。为了更好管理用户，LSF 引入用户组（user group）。若干用户集合可以统一命名，并使用该命名统一引用。例如，一个人属于一个部门，一个部门可以作为一个用户组，这种情况下就可以使用部门名字命名和引用。 体系结构 LSF 采用传统的客户机服务器模式，主节点负责整个集群的管理，从节点负责管理运行其上的作业的管理。每一个服务节点包含三个后台进程： Sbatchd 批处理作业管理进程。负责在本节点上执行作业，监控作业状态以及收集其使用的资源。同时根据用户请求或者系统策略触发，控制作业的状态，比如发送SIGSTOP 给作业、挂起作业运行等。 RES 远程执行服务进程。负责执行远程客户请求的任务，主要用于并行作业的远程任务启动、监控以及控制。 LIM 采集本节点的负载信息进程。将收集到的资源负载信息周期上报给主节点上的LIM。主节点的LIM 拥有整个集群资源状态，为其它服务提供集群系统范围内的资源当前快照。 主管理节点在这个基础上，包括两个额外的进程： Mbatchd 集群管理服务进程。它是 LSF 的中心：通过主节点的 LIM 获取机器以及相关资源信息，处理远程用户的作业提交请求，委托 mbschd 将作业调度到相关资源上，发送调度结果到指定机器，并通过和 sbatchd 的交互，监控作业使用的资源，控制作业的执行过程。 Mbschd 调度策略服务进程。从 mbachd 获取作业和资源信息，根据定制策略，为 mbatchd 提供作业调度服务。 图 5. 体系结构 当一个新作业提交的时候，集群管理服务进程检查作业的合法性，并将作业放入到指定的队列中等待调度。经过调度的作业，将获得执行机器上的slot、内存等资源。LSF 负责保留相关资源并将作业指派到已分配机器上执行。作业的状态和实际使用的资源通过批处理作业管理进程报告给集群管理进程。 集群系统构建在分布式网络节点上，节点的失效和网路设备的故障都会导致集群系统的基础环境改变。集群系统的高可用性功能可以保证即使在底层设备故障，LSF 系统仍然可以提供可靠稳定的服务。LSF 采用主备模式实现系统的故障恢复。LSF 的主节点将运行时事件信息写入网络文件系统。当主节点失效后，相关备节点进行选举，选出新的主节点。新的主节点从事件信息文件中恢复作业信息、机器状态，最终获取集群控制权，恢复LSF 状态。 为了更进一步扩展 LSF 的资源管理范围和方式，在单一集群基础上，LSF 还提供多集群互联技术（Multi-Cluster）。多集群通过互联，共享跨集群资源，提供更强大的计算能力。下面是一种典型的多集群架构，集群 1 负责接收作业提交和转发，集群 2 和 集群 3 负责作业执行。 图 6. 多集群结构 资源调度 LSF 收集每一个节点的处理器、内存、交换区、临时存储区等资源信息。主节点掌握全局资源信息。资源的管理和调度以这些信息为基础。 清单 4. 查看节点资源负载信息 lsfrhel01 # lshosts HOST_NAME type model cpuf ncpus maxmem maxswp server RESOURCES lsfrhel01 X86_64 PC6000 116.1 2 1.4G 1.4G Yes (mg) lsfrhel02 X86_64 PC6000 116.1 2 1.4G 1.4G Yes () lsfrhel01 # lsload HOST_NAME status r15s r1m r15m ut pg ls it tmp swp mem lsfrhel01 ok 0.4 0.0 0.0 0% 0.0 1 179 10G 1.4G 1.1G lsfrhel02 ok 1.5 0.3 0.3 1% 0.1 2 1 2391M 1.2G 603M 作业在使用资源的时候，主要考虑三个方面：如何根据作业的资源描述选择合适的执行机器，如何预留机器资源减少运行时的资源竞争，以及如何限制作业对资源的使用避免作业过度消耗资源。 首先是选择执行机。每一个作业会有不同的资源需求。可以通过 LSF 定义的资源描述模式请求资源，运行节点由LSF 根据作业对资源描述来匹配。当一个作业需要一定量内存的时候，\"select[mem>512]\" 表示选择内存大于512M 的机器来运行作业。调度器为其选择拥有合适资源的机器。 其次是确保执行机上的资源分配。既然我们选择了大内存的机器，那么别人的作业也可以选择大内存的机器。如果很多作业都在大内存机器上运行，资源竞争会导致内存短缺，作业最终无法占用到请求的资源。为了更好的确保资源，我们需要在作业运行时保留这些资源不会再分配给别人的作业。\"rusage[mem=512]\" 表示保留 512M 内存给作业，节点当前可用内存将会有 512M 分配给该作业，节点可分配资源将减少512M 的内存。通过 LSF 的策略，可用内存的分配得到控制，已经保留的内存将不会再分配给其它的作业。 最后是保证资源不被过度消耗。资源的保留是通过 LSF 的策略保证，但是作业的进程在运行时，却尚未受 LSF 控制。我们需要在执行节点上，对作业的系统资源设置限制，保证作业（进程）本身不会吃掉过多的内存。通常我们可以设置一个资源上限，防止作业过度消耗资源。比如，内存限制 '1024M'，防止作业使用超过1G 的内存。 清单 5. 提交内存需求的作业 $ bsub -M 1024 -R \"select[mem>512] rusage[mem=512]\" sleep 1000 Job is submitted to default queue . $ bjobs -l 644 Job , User , Project , Status , Queue , Command Wed Dec 28 16:04:00: Submitted from host , CWD , Requested Resources 512] rusage[mem=512]>; MEMLIMIT 1 G Wed Dec 28 16:04:00: Started 1 Task(s) on Host(s) , Allocated 1 Slot (s) on Host(s) , Execution Home , Exe cution CWD ; Wed Dec 28 16:05:00: Resource usage collected. The CPU time used is 4 seconds. MEM: 6 Mbytes; SWAP: 0 Mbytes; NTHREAD: 4 PGID: 23106; PIDs: 23106 23108 23110 SCHEDULING PARAMETERS: r15s r1m r15m ut pg io ls it tmp swp mem loadSched - - - - - - - - - - - loadStop - - - - - - - - - - - RESOURCE REQUIREMENT DETAILS: Combined: select[(mem>512) && (type == local)] order[r15s:pg] rusage[mem=512.0 0] Effective: select[(mem>512) && (type == local)] order[r15s:pg] rusage[mem=512. 00] 对于资源的选择、预留和限制，内存只是一个例子。 LSF 还支持很多种资源，比如 CPU、交换区、临时目录大小等等。虽然这些默认管理的资源始终是有限的，但是 LSF 还提供了资源管理的扩展机制。用户可以统过编写自己的 ELIM 来收集自定义的资源。比如，收集系统的网络带宽以及网络负载，作业可以通过资源描述，选择拥有相应带宽的节点执行作业。资源的种类很多，LSF 提供布尔类型、字符串类型和数字类型来描述多种多样的资源。 定制策略 LSF 提供了非常丰富的调度策略供 LSF 系统管理员选择配置。策略针对作业和资源，从提高资源利用率、优化资源分配、提高用户满意度等各个方面为资源的使用者和管理者提供可配置策略。 默认的策略是先来先服务（FCFS）。顾名思义，先提交的作业先调度，优先获得资源。排在后面的作业必须等待前面的作业运行完成才能开始。后提交作业可能在很长时间得不到机会运行。考虑到资源分配的公平问题，比如部门之间应该平等使用资源，公平共享（Fairshare）策略得以引入。通过配置以部门为单位的用户组平等分享资源，不同用户的作业优先考虑资源所有权。避免了先来先服务导致的资源不平等，从而优化资源分配。 公平共享是从资源分配公平性上考虑问题的，它达到的是一个最终资源使用公平的平衡。但是在使用过程中，如果其他人或者部门没有作业，那么整个集群的资源将会被分配给目前已经提交的作业。作业执行期间，即便新的作业拥有更多的资源优先使用权，也要等待其他作业执行完毕，释放资源后才能执行。这样在短时期内资源使用是不公平的。对于拥有资源使用权却无法执行的情况，资源保障（Resource Guarantee）策略可以为用户保留资源，随时可用。这是在牺牲资源利用率基础上提高用户满意度。 对于并行作业，通常要求很多的 slot，当系统资源紧张的时候，即使等待很久依然无法运行。当系统释放一个 slot 的时候，这个作业因为发现资源不够，便放弃对资源的优先权。排在后面的只需要一个 slot 的作业将获取资源执行。这个过程反复着，并行作业始终无法获取足够资源。为了解决这个问题引入了资源保留策略。虽然当前资源不够运行的，但是这个资源暂时被并行作业占有，等待后面不断释放的资源，直到 slot 满足作业的需求。 但是长时间的等待还是会浪费这些空闲资源，因此又加入回填策略。在不影响并行作业启动时间的前提下，可以将短作业优先调度到已经被保留的 slot 上。 对于特权或者紧急的用户或者应用，当系统资源完全使用的时候。为了尽快执行，抢占（Preemption）策略可以通过抢占已执行作业的资源，执行自己的作业。 除此之外，为了满足用户需求，LSF 提供了资源预留（Advanced Reservation）、SLA 等等。为了提高资源利用率，LSF 提供了NUMA绑定（Affinity）策略等等。对于详尽的策略，可以参考 LSF 管理员手册。LSF 的很多策略都可以自由组合，通过管理员的配置，最终形成丰富的，满足各种需求的定制策略。 即便所有的策略都不能满足你的要求，LSF 的调度策略还实现了插件机制。新的扩展可以通过 LSF 提供的API 实现新的策略。 总结 在高性能计算领域，作业管理系统是一种成熟的系统软件技术。LSF 作为其中的佼佼者，提供了统一的访问接口，丰富的调度策略，灵活的配置和部署。LSF 的体系结构和部署方式让它可以有效管理一定规模的集群系统，目前商业版可以支持多达数千台节点和数百万作业的管理。LSF 的故障恢复机制足以保证集群系统的高可用性。在分布式计算技术不断发展的今天，作为传统的批处理管理软件，依然发挥着重要的作用。 参考资源 下载 IBM Spectrum LSF Community Edition，安装，试用LSF 的基本功能 参考 IBM Spectrum LSF Knowledge Center,了解更多LSF 的使用和集群管理方法 参考 IBM Spectrum LSF 首页,察看更多LSF 产品和技术的最新信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section2/system_requirements_and_compatibility.html":{"url":"chapter1/section2/system_requirements_and_compatibility.html","title":"1.2 LSF 系统要求与兼容性","keywords":"","body":"1.2 LSF 系统要求与兼容性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section2/operating_system_support.html":{"url":"chapter1/section2/operating_system_support.html","title":"操作系统支持","keywords":"","body":"操作系统支持 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section2/master_host_selection.html":{"url":"chapter1/section2/master_host_selection.html","title":"主机选择","keywords":"","body":"主机选择 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section2/server_host_compatibility.html":{"url":"chapter1/section2/server_host_compatibility.html","title":"服务器主机兼容性","keywords":"","body":"服务器主机兼容性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section2/add-on_compatibility.html":{"url":"chapter1/section2/add-on_compatibility.html","title":"附加兼容性","keywords":"","body":"附加兼容性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section2/API_compatibility.html":{"url":"chapter1/section2/API_compatibility.html","title":"API 兼容性","keywords":"","body":"API 兼容性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section3/limitations.html":{"url":"chapter1/section3/limitations.html","title":"1.3 局限性","keywords":"","body":"1.3 局限性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section4/release_notes.html":{"url":"chapter1/section4/release_notes.html","title":"1.4 版本更新说明","keywords":"","body":"1.6 版本更新说明 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter1/section5/LSF_quick_reference.html":{"url":"chapter1/section5/LSF_quick_reference.html","title":"1.5 LSF 快速上手","keywords":"","body":"1.7 LSF 快速上手 本文主要是关于 LSF 命令、守护进程、配置文件、日志文件以及重要的集群配置参数的快速介绍。 Unix 及 Linux 系统下的安装目录示意图 守护进程的错误日志文件 守护进程的错误日志文件，存储在由 LSF_LOGDIR 变量定义的文件目录下面，该变量值在 lsf.conf 文件中指定。 LSF base system daemon log files LSF batch system daemon log files pim.log.host_name mbatchd.log.host_name res.log.host_name sbatchd.log.host_name lim.log.host_name mbschd.log.host_name 如果在 ego.conf 文件中定义了变量 EGO_LOGDIR ，那么 lim.log.host_name 文件则存储在由变量 EGO_LOGDIR 指定的文件目录中。 配置文件 lsf.conf, lsf.shared, 和 lsf.cluster.cluster_name 文件， 位于由 LSF_CONFDIR 变量定义的文件目录下面，该变量值在 lsf.conf 文件中指定。 lsb.params, lsb.queues, lsb.modules, 和 lsb.resources 文件，位于 LSB_CONFDIR/cluster_name/configdir/ 目录下面。 文件 描述 install.config LSF 的安装与配置选项 lsf.conf 描述集群配置和操作的通用环境配置文件 lsf.shared 所有群集共享的定义文件。用于定义群集名称、主机类型、主机型号和站点定义的资源 lsf.cluster.cluster_name 用于定义主机、管理员和站点定义的共享资源的位置的集群配置文件 lsb.applications 定义应用程序配置文件，来指定同类型作业的公共参数 lsb.params 配置 LSF 批处理参数 lsb.queues 批处理队列配置文件 lsb.resources 配置资源分配限制、导出和资源使用限制 lsb.serviceclasses 将LSF集群中的服务级别协议（SLA）定义为服务类，该服务类定义了 SLA 的属性 lsb.users 配置用户组、用户和用户组的分层公平共享，以及用户和用户组的作业槽数限制 lsf.conf 配置文件中的集群配置参数 参数 描述 Unix 默认值 LSF_BINDIR 包含 LSF 用户命令的目录，由相同类型的所有主机共享 LSF_TOP/version/OStype/bin LSF_CONFDIR 所有 LSF 配置文件的目录 LSF_TOP/conf LSF_ENVDIR 包含 lsf.conf 文件的目录。必须由root 用户所拥有。 /etc (if LSF_CONFDIR is not defined) LSF_INCLUDEDIR 包含 LSF API 头文件 lsf.h 和 lsbatch.h的目录 LSF_TOP/version/include LSF_LIBDIR LSF 库，由相同类型的所有主机共享 LSF_TOP/version/OStype/lib LSF_LOGDIR （可选）LSF 守护程序日志的目录。必须由 root 拥有。 /tmp LSF_LOG_MASK 从 LSF 命令记录错误消息的级别 LOG_WARNING LSF_MANDIR 包含 LSF 手册页的目录 LSF_TOP/version/man LSF_MISC 示例C程序和Shell脚本，以及外部LIM（elim）的模板 LSF_TOP/version/misc LSF_SERVERDIR 由 LSF 守护程序启动的所有服务器二进制文件和 Shell 脚本以及外部可执行文件的目录。必须由root拥有，并由相同类型的所有主机共享 LSF_TOP/version/OStype/etc LSF_TOP 顶级安装目录。 LSF_TOP 的路径必须共享，并且集群中的所有主机都可以访问。它不能是根目录（/）。 Not definedRequired for installation LSB_CONFDIR LSF批处理配置目录的目录，包含用户和主机列表，操作参数和批处理队列 LSF_CONFDIR/lsbatch LSF_LIVE_CONFDIR LSF 实时重新配置目录的目录，该目录由 bconf 命令编写。 LSB_SHAREDIR/cluster_name/live_confdir LSF_SHAREDIR 每个集群的 LSF 批处理作业历史记录和记帐日志文件的目录，必须由首要的 LSF 管理员拥有 LSF_TOP/work LSF_LIM_PORT 用于与 lim 守护程序进行通信的 TCP 服务端口 7879 LSF_RES_PORT 用于与 res 守护程序通信的 TCP 服务端口 6878 LSF_MBD_PORT 用于与 mbatchd 守护程序进行通信的 TCP 服务端口 6881 LSF_SBD_PORT 用于与 sbatchd 守护程序进行通信的TCP服务端口 6882 管理命令 注：只有 LSF 管理员和 root 用户可以使用这些命令。 命令 描述 lsadmin LSF 管理员工具，用于控制 LSF 集群中 LIM 和 RES 守护程序的运行，lsadmin help 显示所有子命令 lsfinstall 使用 install.config 输入文件安装 LSF lsfrestart 在本地集群中的所有主机上重新启动 LSF 守护程序 lsfshutdown 关闭本地集群中所有主机上的 LSF 守护程序 lsfstartup 在本地集群中的所有主机上启动 LSF 守护程序 badmin 用于控制 LSF 批处理系统（sbatchd，mbatchd，主机和队列）的 LSF 管理工具 badmin help 显示所有子命令 bconf 更改活动内存中的 LSF 配置 守护进程 进程名 描述 lim Load Information Manager (LIM): 负载信息管理器：收集有关集群中所有服务器主机的负载和资源信息，并通过 LSLIB 为应用程序提供主机选择服务。 LIM 维护有关静态系统资源和动态负载索引的信息 mbatchd Master Batch Daemon (MBD): 主批处理守护程序：接受并保存所有批处理作业。 MBD通过联系 主LIM 定期检查所有服务器主机上的负载索引。 mbschd Master Batch Scheduler Daemon：主批处理调度守护程序：执行LSF的调度功能，并将作业调度决策发送到 MBD 以进行调度。 该服务在 LSF 主服务器主机上运行 sbatchd Slave Batch Daemon (SBD)：从属批处理守护程序（SBD）：接受来自 MBD 的作业执行请求，并监视作业进度。 控制作业执行，强制执行批处理策略，将作业状态报告给 MBD，然后启动 MBD。 pim Process Information Manager (PIM): 进程信息管理器（PIM）：监视提交的作业在运行时所使用的资源。 PIM 用于强制执行资源限制和负载阈值以及公平分配调度。 res Remote Execution Server (RES): 远程执行服务器（RES）：接受来自所有负载共享应用程序的远程执行请求，并处理远程主机上的I / O以进行负载共享过程。 用户命令 查看集群信息的命令 命令 描述 bhosts 显示主机及其静态和动态资源 blimits 显示正在运行的作业的资源分配限制的相关信息 bparams 显示可调批次系统参数的相关信息 bqueues 显示批处理队列的相关信息 busers 显示用户和用户组的相关信息 lshosts 显示主机及其静态资源信息 lsid 显示当前的 LSF 版本号，集群名称和主控主机名 lsinfo 显示负载分担配置信息 lsload 显示主机的动态负载索引 监测作业与任务的命令 命令 描述 bacct 报告已完成的 LSF 作业的会计统计数据 bapp 显示附加到应用程序配置文件的作业的相关信息 bhist 显示作业的相关历史信息 bjobs 显示作业的相关信息 bpeek 显示未完成作业的标准输出和标准错误 bsla 显示服务类配置的相关信息，以用于面向目标的服务级别协议调度 bstatus 读取或设置外部作业状态消息和数据文件 提交与控制作业的命令 命令 描述 bbot 移动正在等待的作业到队列的末尾 bchkpnt 检查点可检查的工作 bkill 向作业发送信号，一般用于结束作业 bmig 迁移可检查点的或可重新运行的作业 bmod 修改作业的提交选项 brequeue 杀死并重新安排作业 bresize 释放槽位并取消挂起的作业调整大小分配请求 brestart 重新启动检查点作业 bresume 恢复暂停的作业 bstop 暂停作业 bsub 提交作业 bswitch 将未完成的作业从一个队列移至另一队列 btop 移动正在等待的作业到队列首部 bsub 命令 bsub [options] command [arguments] 命令中的部分选项 选项 描述 -ar 指定作业可自动调整大小 -H 提交时将工作保持在 PSUSP 状态 **-I\\ -Ip\\ -Is** 提交批处理交互式作业。 -Ip 创建伪终端。 -is 在shell模式下创建一个伪终端。 -K 提交作业并等待作业完成 -r 使作业可重新运行 -x 排他执行 -app application_profile_name 将作业提交到指定的应用程序配置文件 -b begin_time 在[[month：] day：]：minute 格式的指定日期和时间或之后调度作业 -C core_limit 为属于此作业的所有进程设置每个进程（soft）核心文件的大小限制（KB） -c cpu_time[/host_name \\ /host_model] 限制作业可以使用的总CPU时间。 CPU时间的格式为[hour:]minutes -cwd \"current_working_directory\" 指定作业的当前工作目录 -D data_limit 为属于作业的每个进程设置每个进程（soft）数据段的大小限制（KB） -E \"pre_exec_command [arguments]\" 在作业运行之前，在执行主机上运行指定的pre-exec命令 -Ep \"post_exec_command [arguments]\" 作业完成后，在执行主机上运行指定的post-exec命令 -e error_file 将标准错误输出附加到文件 -eo error_file 将作业的标准错误输出覆盖到指定文件 -F file_limit 为属于作业的每个进程设置每个进程（soft）文件大小限制（KB） -f \"local_file op[remote_file]\" ... 在本地（提交）主机和远程（执行）主机之间复制文件。op是>， 之一 -i input_file \\ -is input_file 从指定文件获取作业的标准输入 -J \"job_name[index_list]%job_slot_limit\" 为作业分配指定的名称。 作业数组 index_list 的格式 start [-end [：step]]，而 ％job_slot_limit 是可以同时运行的最大作业数。 -k \"chkpnt_dir [chkpnt_period][method=method_name]\" 使作业可检查，并指定检查点目录，以分钟为单位的时间段和方法 -M mem_limit 设置每个进程（soft）的内存限制（KB） -m \"host_name [@cluster_name][[!] \\ +[pref_level]] \\ host_group[[!] \\ +[pref_level]] \\ compute_unit[[!] \\ +[pref_level]]...\" 在指定的主机之一上运行作业。 主机或组的名称后的加号（+）表示首选项。 可选地有，正整数表示偏好级别。 数字越高表示偏好越大。 -n min_proc[,max_proc] 指定并行作业所需的最小和最大处理器数量 -o output_file 将标准输出附加到文件 -oo output_file 将作业的标准输出覆盖到指定文件 -p process_limit 限制整个作业的进程数量 -q \"queue_name ...\" 将作业提交到指定的队列之一 -R \"res_req\" [-R \"res_req\" ...] 指定主机资源要求 -S stack_limit 为属于作业的每个进程设置每个进程（soft）堆栈段大小限制（KB） -sla service_class_name 指定要在其中运行作业的服务类 -T thread_limit 设置整个作业的并发线程数限制 -t term_time 以 [[month：] day：] hour：minute 的形式指定作业终止的截止日期 -v swap_limit 设置整个作业的总进程虚拟内存限制（KB） -W run_time[/host_name \\ /host_model] 以[hour：] minute形式设置作业的运行时限制 -h 将命令用法打印到 stderr 并退出 -V 将 LSF 发行版本打印到 stderr 并退出 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter2/install_upgrade_and_migrate.html":{"url":"chapter2/install_upgrade_and_migrate.html","title":"Chapter 2 安装、升级与迁移","keywords":"","body":"Chapter 2 安装、升级与迁移 规划您的安装，并安装新的 IBM Spectrum LSF 集群产品，或在 UNIX，Linux 或 Microsoft Windows 主机上升级LSF。 为了使您的集群保证最新状态，建议使用 IBM Fix Central 中的最新修订包。 在 IBM Knowledge Center上的 LSF 安装指南 中可以找到从 Fix Central 应用 Fices 的详细步骤。 在 UNIX 和 Linux 上安装 IBM Spectrum LSF 规划安装，并在 UNIX 或 Linux 主机上安装新的生产版 IBM Spectrum LSF 集群。 在 Windows 上安装 IBM Spectrum LSF 规划安装，并在 Microsoft Windows 主机上安装新的生产版 IBM Spectrum LSF 集群。 使用 IBM Spectrum Cluster Foundation 从裸机安装和部署 IBM Spectrum LSF 使用 IBM Spectrum Cluster Foundation 在受支持的Linux主机上，裸机安装和部署新的生产版 IBM Spectrum LSF 集群。IBM Spectrum Cluster Foundation 是面向技术计算用户的，功能强大的集群管理框架。它提供了一套全面的功能，可帮助从基础架构级别管理硬件和软件。 它使操作系统和软件组件的部署以及复杂的活动（如应用程序集群的创建和系统维护）变得自动化。 升级和迁移 IBM Spectrum LSF 升级 UNIX 或 Linux 集群，或将现有集群迁移到 UNIX，Linux 或 Windows 上的 LSF 10.1版本。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 09:11:45 "},"chapter2/section1/Install on UNIX and Linux.html":{"url":"chapter2/section1/Install on UNIX and Linux.html","title":"2.1 在 UNIX 与 Linux 上安装","keywords":"","body":"2.1 在 UNIX 与 Linux 上安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Example installation directory structure.html":{"url":"chapter2/section1/Example installation directory structure.html","title":"安装目录结构示意","keywords":"","body":"安装目录结构示意 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Planning your installation.html":{"url":"chapter2/section1/Planning your installation.html","title":"规划安装","keywords":"","body":"规划安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/EGO in the LSF cluster.html":{"url":"chapter2/section1/EGO in the LSF cluster.html","title":"LSF 集群中的 EGO","keywords":"","body":"LSF 集群中的 EGO © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Master host selection.html":{"url":"chapter2/section1/Master host selection.html","title":"主节点选择","keywords":"","body":"主节点选择 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Preparing your systems for installation.html":{"url":"chapter2/section1/Preparing your systems for installation.html","title":"准备系统进行安装","keywords":"","body":"准备系统进行安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Installing a new LSF cluster.html":{"url":"chapter2/section1/Installing a new LSF cluster.html","title":"安装新的 LSF 集群 (lsfinstall)","keywords":"","body":"安装新的 LSF 集群 (lsfinstall) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Getting fixes from IBM Fix Central.html":{"url":"chapter2/section1/Getting fixes from IBM Fix Central.html","title":"从 IBM Fix Central 中获取修订","keywords":"","body":"从 IBM Fix Central 中获取修订 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Configuring a cluster.html":{"url":"chapter2/section1/Configuring a cluster.html","title":"配置集群","keywords":"","body":"配置集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/If you install LSF as a non-root user.html":{"url":"chapter2/section1/If you install LSF as a non-root user.html","title":"以非 root 用户安装 LSF","keywords":"","body":"非 root 用户安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Adding hosts to the cluster.html":{"url":"chapter2/section1/Adding hosts to the cluster.html","title":"往集群中添加节点","keywords":"","body":"往集群中添加节点 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/LSF HPC features.html":{"url":"chapter2/section1/LSF HPC features.html","title":"LSF HPC 特征","keywords":"","body":"LSF HPC 特性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Optional LSF HPC features configuration.html":{"url":"chapter2/section1/Optional LSF HPC features configuration.html","title":"可选的LSF HPC 功能配置","keywords":"","body":"可选的LSF HPC 功能配置 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/Registering service ports.html":{"url":"chapter2/section1/Registering service ports.html","title":"注册服务端口","keywords":"","body":"注册服务端口 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/install.config.html":{"url":"chapter2/section1/install.config.html","title":"install.config 文件","keywords":"","body":"install.config 文件 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section1/slave.config.html":{"url":"chapter2/section1/slave.config.html","title":"slave.config 文件","keywords":"","body":"slave.config 文件 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Install on Windows.html":{"url":"chapter2/section2/Install on Windows.html","title":"2.2 在 Windows 上安装","keywords":"","body":"2.2 在 Windows 上安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Example installation directory structures.html":{"url":"chapter2/section2/Example installation directory structures.html","title":"安装目录结构示意","keywords":"","body":"安装目录结构示意 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/EGO in the LSF cluster.html":{"url":"chapter2/section2/EGO in the LSF cluster.html","title":"LSF 集群中的 EGO","keywords":"","body":"LSF 集群中的 EGO © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Planning and preparing your systems for installation.html":{"url":"chapter2/section2/Planning and preparing your systems for installation.html","title":"准备系统进行安装","keywords":"","body":"准备系统进行安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Master host selection.html":{"url":"chapter2/section2/Master host selection.html","title":"主节点选择","keywords":"","body":"主节点选择 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Entitlement files.html":{"url":"chapter2/section2/Entitlement files.html","title":"Entitlement files 文件","keywords":"","body":"Entitlement files 文件 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Installing a new LSF cluster.html":{"url":"chapter2/section2/Installing a new LSF cluster.html","title":"安装新的 LSF 集群","keywords":"","body":"安装新的 LSF 集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section2/Installation parameter quick reference.html":{"url":"chapter2/section2/Installation parameter quick reference.html","title":"安装参数快速参考","keywords":"","body":"安装参数快速参考 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/Install LSF with IBM Spectrum Cluster Foundation.html":{"url":"chapter2/section3/Install LSF with IBM Spectrum Cluster Foundation.html","title":"2.3 使用 IBM Spectrum Cluster Foundation 安装 LSF","keywords":"","body":"2.3 使用 IBM Spectrum Cluster Foundation 安装 LSF © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/Install LSF Suites 10.1.1 with IBM Spectrum Cluster Foundation.html":{"url":"chapter2/section3/Install LSF Suites 10.1.1 with IBM Spectrum Cluster Foundation.html","title":"使用 IBM Spectrum Cluster Foundation安装 LSF Suites 10.1.1","keywords":"","body":"使用 IBM Spectrum Cluster Foundation安装 LSF Suites 10.1.1 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Installation.html":{"url":"chapter2/section3/subsection1/Installation.html","title":"安装","keywords":"","body":"安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Installation planning.html":{"url":"chapter2/section3/subsection1/Installation planning.html","title":"安装规划","keywords":"","body":"安装规划 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Preinstallation roadmap.html":{"url":"chapter2/section3/subsection1/Preinstallation roadmap.html","title":"预安装路线图","keywords":"","body":"预安装路线图 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Installation roadmap.html":{"url":"chapter2/section3/subsection1/Installation roadmap.html","title":"安装路线图","keywords":"","body":"安装路线图 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Preparing to install IBM Spectrum LSF Suite for Workgroups, or IBM Spectrum LSF Suite for HPC.html":{"url":"chapter2/section3/subsection1/Preparing to install IBM Spectrum LSF Suite for Workgroups, or IBM Spectrum LSF Suite for HPC.html","title":"准备安装适用于工作组的IBM Spectrum LSF Suite或适用于 HPC 的 IBM Spectrum LSF Suite","keywords":"","body":"准备安装适用于工作组的IBM Spectrum LSF Suite或适用于HPC的IBM Spectrum LSF Suite © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Requirements.html":{"url":"chapter2/section3/subsection1/Requirements.html","title":"要求","keywords":"","body":"要求 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Configure and test switches.html":{"url":"chapter2/section3/subsection1/Configure and test switches.html","title":"配置和测试开关","keywords":"","body":"配置和测试开关 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Plan your network configuration.html":{"url":"chapter2/section3/subsection1/Plan your network configuration.html","title":"规划您的网络配置","keywords":"","body":"规划您的网络配置 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Installing and verifying the operating system on the management node.html":{"url":"chapter2/section3/subsection1/Installing and verifying the operating system on the management node.html","title":"在管理节点上安装和验证操作系统","keywords":"","body":"在管理节点上安装和验证操作系统 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Performing an installation.html":{"url":"chapter2/section3/subsection1/Performing an installation.html","title":"执行安装","keywords":"","body":"执行安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Comparing installation methods.html":{"url":"chapter2/section3/subsection1/Comparing installation methods.html","title":"安装方法的对比","keywords":"","body":"安装方法的对比 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Interactive installation roadmaps.html":{"url":"chapter2/section3/subsection1/Interactive installation roadmaps.html","title":"交互式安装路线图","keywords":"","body":"交互式安装路线图 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Quick installation roadmap.html":{"url":"chapter2/section3/subsection1/Quick installation roadmap.html","title":"快速安装路线图","keywords":"","body":"快速安装路线图 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Custom installation.html":{"url":"chapter2/section3/subsection1/Custom installation.html","title":"自定义安装","keywords":"","body":"自定义安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Performing an interactive installation using the installer.html":{"url":"chapter2/section3/subsection1/Performing an interactive installation using the installer.html","title":"使用安装程序执行交互式安装","keywords":"","body":"使用安装程序执行交互式安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Performing a silent installation.html":{"url":"chapter2/section3/subsection1/Performing a silent installation.html","title":"执行静默安装","keywords":"","body":"执行静默安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Verifying the installation.html":{"url":"chapter2/section3/subsection1/Verifying the installation.html","title":"验证安装","keywords":"","body":"验证安装 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Taking the first steps after installation.html":{"url":"chapter2/section3/subsection1/Taking the first steps after installation.html","title":"安装后的第一步","keywords":"","body":"安装后的第一步 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Adding compute nodes after installation.html":{"url":"chapter2/section3/subsection1/Adding compute nodes after installation.html","title":"安装后添加计算节点","keywords":"","body":"安装后添加计算节点 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Import compute nodes.html":{"url":"chapter2/section3/subsection1/Import compute nodes.html","title":"导入计算节点","keywords":"","body":"导入计算节点 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Discover compute nodes.html":{"url":"chapter2/section3/subsection1/Discover compute nodes.html","title":"发现计算节点","keywords":"","body":"发现计算节点 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection1/Troubleshooting installation problems.html":{"url":"chapter2/section3/subsection1/Troubleshooting installation problems.html","title":"解决安装问题","keywords":"","body":"解决安装问题 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection2/Cluster deployment.html":{"url":"chapter2/section3/subsection2/Cluster deployment.html","title":"集群部署","keywords":"","body":"集群部署 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection2/Creating an LSF Workgroups cluster after installation.html":{"url":"chapter2/section3/subsection2/Creating an LSF Workgroups cluster after installation.html","title":"安装后创建 LSF 工作组集群","keywords":"","body":"安装后创建 LSF 工作组集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection2/Creating an LSF HPC cluster after installation.html":{"url":"chapter2/section3/subsection2/Creating an LSF HPC cluster after installation.html","title":"安装后创建 LSF HPC 集群","keywords":"","body":"安装后创建 LSF HPC 集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/Setting up a high availability environment.html":{"url":"chapter2/section3/subsection3/Setting up a high availability environment.html","title":"设置高可用性环境","keywords":"","body":"设置高可用性环境 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/High availability requirements.html":{"url":"chapter2/section3/subsection3/High availability requirements.html","title":"高可用性要求","keywords":"","body":"高可用性要求 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/Prepare a shared file system.html":{"url":"chapter2/section3/subsection3/Prepare a shared file system.html","title":"准备共享文件系统","keywords":"","body":"准备共享文件系统 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/Preparing high availability.html":{"url":"chapter2/section3/subsection3/Preparing high availability.html","title":"准备高可用性","keywords":"","body":"准备高可用性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/Enable a high availability environment.html":{"url":"chapter2/section3/subsection3/Enable a high availability environment.html","title":"启用高可用性环境","keywords":"","body":"启用高可用性环境 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/Verifying a high availability environment.html":{"url":"chapter2/section3/subsection3/Verifying a high availability environment.html","title":"验证高可用性环境","keywords":"","body":"验证高可用性环境 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection3/Troubleshooting a high availability environment enablement.html":{"url":"chapter2/section3/subsection3/Troubleshooting a high availability environment enablement.html","title":"对高可用性环境启用进行故障排除","keywords":"","body":"对高可用性环境启用进行故障排除 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/After installation.html":{"url":"chapter2/section3/subsection4/After installation.html","title":"安装之后","keywords":"","body":"安装之后 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Managing a cluster.html":{"url":"chapter2/section3/subsection4/Managing a cluster.html","title":"管理集群","keywords":"","body":"管理集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Add or remove servers.html":{"url":"chapter2/section3/subsection4/Add or remove servers.html","title":"添加或删除服务器","keywords":"","body":"添加或删除服务器 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Synchronizing a cluster.html":{"url":"chapter2/section3/subsection4/Synchronizing a cluster.html","title":"同步集群","keywords":"","body":"同步集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Deleting a cluster.html":{"url":"chapter2/section3/subsection4/Deleting a cluster.html","title":"删除集群","keywords":"","body":"删除集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Maintenance mode.html":{"url":"chapter2/section3/subsection4/Maintenance mode.html","title":"维护模式","keywords":"","body":"维护模式 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Health check.html":{"url":"chapter2/section3/subsection4/Health check.html","title":"健康检查","keywords":"","body":"健康检查 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Upgrading a cluster.html":{"url":"chapter2/section3/subsection4/Upgrading a cluster.html","title":"升级集群","keywords":"","body":"升级集群 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Performing a cluster upgrade.html":{"url":"chapter2/section3/subsection4/Performing a cluster upgrade.html","title":"执行集群升级","keywords":"","body":"执行集群升级 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection4/Rolling or bulk upgrade process overview.html":{"url":"chapter2/section3/subsection4/Rolling or bulk upgrade process overview.html","title":"滚动或批量升级过程概述","keywords":"","body":"滚动或批量升级过程概述 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section3/subsection5/Known issues and limitations.html":{"url":"chapter2/section3/subsection5/Known issues and limitations.html","title":"已知问题和局限性","keywords":"","body":"已知问题和局限性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section4/Upgrade and migrate.html":{"url":"chapter2/section4/Upgrade and migrate.html","title":"2.4 升级和迁移","keywords":"","body":"2.4 升级和迁移 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section4/subsection1/Upgrade on UNIX and Linux.html":{"url":"chapter2/section4/subsection1/Upgrade on UNIX and Linux.html","title":"在UNIX和Linux上升级","keywords":"","body":"在UNIX和Linux上升级 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section4/subsection1/Upgrade LSF on UNIX and Linux.html":{"url":"chapter2/section4/subsection1/Upgrade LSF on UNIX and Linux.html","title":"在 UNIX 和 Linux 上升级 LSF","keywords":"","body":"在 UNIX 和 Linux 上升级 LSF © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section4/subsection1/Getting fixes from IBM Fix Central.html":{"url":"chapter2/section4/subsection1/Getting fixes from IBM Fix Central.html","title":"从IBM Fix Central获取修订","keywords":"","body":"从IBM Fix Central获取修订 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section4/subsection2/Migrate on Windows.html":{"url":"chapter2/section4/subsection2/Migrate on Windows.html","title":"在Windows上迁移","keywords":"","body":"在Windows上迁移 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter2/section4/subsection2/Migrate LSF on Windows.html":{"url":"chapter2/section4/subsection2/Migrate LSF on Windows.html","title":"在Windows上迁移LSF","keywords":"","body":"在Windows上迁移LSF © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter3/user_fundations.html":{"url":"chapter3/user_fundations.html","title":"Chapter 3 用户操作基础","keywords":"","body":"Chapter 3 用户操作基础 概述 IBM Spectrum LSF 的工作负载管理概念和操作。 IBM Spectrum LSF 概述 了解 LSF 如何满足您的作业要求，并找到最佳资源来运行该作业的。 深入 LSF 集群内部 了解在 LSF 主机上运行的各种守护进程，LSF 集群通信路径，以及 LSF 如何容许集群中的主机故障。 深入工作负载管理 了解 LSF 的作业生命周期。 使用 bsub 命令将作业提交到队列，并指定作业的提交选项以修改默认作业行为。 提交的作业在队列中等待，直到将它们调度并调度到主机来执行。 在作业分发时，LSF 会检查哪些主机有资格运行该作业。 启用 EGO 的 LSF 启用具有企业网格协调器（enterprise grid orchestrator EGO）的 LSF 能够提供系统基础结构，来控制和管理集群资源。 资源是应用程序使用的物理和逻辑实体。 LSF资源按照 EGO资源分配计划中的定义进行共享。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter3/section1/LSF_overview.html":{"url":"chapter3/section1/LSF_overview.html","title":"3.1 LSF 概览","keywords":"","body":"3.1 LSF 概览 了解 LSF 是如何满足您的作业要求，并找到最佳资源来运行该作业的。 IBM Spectrum LSF 介绍 IBM Spectrum LSF (\"LSF\", load sharing facility 的简称) 软件是行业领先的企业级软件。LSF 将工作分散在现有的各种 IT 资源中，以创建共享的，可扩展的和容错的基础架构，从而提供更快，更可靠的工作负载性能并降低成本。 LSF 平衡负载和分配资源，并提供对这些资源的访问。 LSF集群组件 LSF 集群管理资源，接受和调度工作负载以及监视所有事件。 用户和管理员可以通过命令行界面，API 或通过IBM Spectrum LSF Application Center (PAC) 访问 LSF。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:28:38 "},"chapter3/section1/LSF_introduction.html":{"url":"chapter3/section1/LSF_introduction.html","title":"LSF 介绍","keywords":"","body":"LSF 介绍 IBM Spectrum LSF (\"LSF\", load sharing facility 的简称) 软件是行业领先的企业级软件。LSF 将工作分散在现有的各种 IT 资源中，以创建共享的，可扩展的和容错的基础架构，从而提供更快，更可靠的工作负载性能并降低成本。 LSF 平衡负载和分配资源，并提供对这些资源的访问。 LSF 提供了一个资源管理框架，可满足您的工作要求，找到最佳资源来运行该工作并监视其进度。 作业始终根据主机负载和站点策略运行。 Cluster（集群） 运行 LSF 的一组计算机（主机），它们作为一个单元一起工作，结合了计算能力，工作量和资源。 集群为计算资源网络提供单系统映像。 可以通过多种方式将主机分组到集群中。 集群可以包含： 单个管理组中的所有主机 子网中的所有主机 Hosts（主机） 集群中的主机执行不同的功能。 Master host （主节点） LSF 服务器主机，充当集群的整体协调器，负责所有作业的调度和分配。 Server host （服务主机） 提交并运行作业的主机。 Client host （客户主机） 仅提交作业和任务的主机。 Execution host （执行主机） 运行作业和任务的主机。 Submission host （提交主机） 从中提交作业和任务的主机。 Job（作业） 作业是在 LSF 系统中运行的工作单元。 它是一个提交给 LSF 来执行的命令。 LSF 则根据配置的策略，来调度，控制和跟踪作业。 作业可以是复杂的问题，模拟方案，大规模计算或任何需要计算力的事物。 Job slot（作业槽位） 作业槽是一个存储区，在 LSF 系统中将单个工作单元分配到该存储区中。 主机可以配置有多个作业槽，并且您可以从队列中分派作业，直到所有作业槽都被填满。 您可以将作业槽与集群中的 CPU 总数相关联。 Queue（队列） 集群范围内的作业容器。 所有作业都在队列中等待，直到将它们调度并分配到主机为止。 队列不对应单个主机； 每个队列都可以使用集群中的所有服务器主机，或服务器主机的已配置子集。 将作业提交到队列时，无需指定执行主机。 LSF 会将作业分派到集群中，最佳可用的执行主机来运行该作业。 队列执行不同的作业调度和控制策略。 Resources（资源） 资源是集群中可用于运行作业的对象。 例如，资源包括但不限于主机，CPU 槽和许可证。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter3/section1/cluster_components.html":{"url":"chapter3/section1/cluster_components.html","title":"集群组件","keywords":"","body":"集群组件 LSF 集群管理资源，接受和调度工作负载，以及监视所有事件。 用户和管理员可以通过命令行界面，API 或通过IBM Spectrum LSF Application Center (PAC web 界面) 访问 LSF。 IBM Spectrum LSF LSF的核心包括守护程序和其他功能，用于调度和运行作业以及管理集群资源。 IBM Spectrum LSF License Scheduler 策略，控制组织中不同用户之间共享软件许可证的方式。 IBM Spectrum LSF License Scheduler 可与 FlexNet™ 和其他产品一起使用，以控制和监视许可证的使用情况。 LSF 文档 IBM Spectrum LSF documentation in IBM Knowledge Center IBM知识中心是 IBM 产品文档以及您访问所有IBM Spectrum LSF信息的访问点。 在 IBM Knowledge Center 中的所有内容中搜索您感兴趣的主题，或者在产品中搜索，或者将搜索范围限制为产品的一个版本。 使用您的 IBMid 登录以充分利用 IBM Knowledge Center 中提供的个性化功能。 同样，可以通过向主题添加评论来与同事和 IBM 进行交流。 在原始版本的IBM Spectrum LSF 10.1之后，会定期更新和重新生成，可通过IBM Knowledge Center获得的文档。 LSF 随附的 IBM Spectrum LSF Application Center（LSF Application Center）Basic Edition中，提供了该文档的脱机版本。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 10:02:50 "},"chapter3/section2/Inside_an_LSF_cluster.html":{"url":"chapter3/section2/Inside_an_LSF_cluster.html","title":"3.2 LSF 细观","keywords":"","body":"3.2 LSF 细观 了解在 LSF 主机上运行的各种守护进程，LSF 集群通信路径，以及 LSF 如何容许集群中的主机故障。 LSF 守护程序和进程 集群中的每个主机上都运行多个 LSF 进程。 正在运行的进程的类型和数量，取决于主机是主节点还是计算节点。 LSF 集群通信路径 了解集群中 LSF daemon 之间的通信路径。 容错和自动主控主机故障转移 LSF 的强大体系结构在设计时考虑了容错能力。 系统中的每个组件，都有一个恢复操作。关键组件由另一个组件监视，并且可以自动从故障中恢复。 安全性 了解 LSF 安全模型，身份验证和用户角色。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 10:45:53 "},"chapter3/section2/LSF_daemons_and_processes.html":{"url":"chapter3/section2/LSF_daemons_and_processes.html","title":"LSF 服务与进程","keywords":"","body":"LSF 服务与进程 集群中的每个主机上都运行多个 LSF 进程。 正在运行的进程的类型和数量，取决于主机是主节点还是计算节点。 主节点守护程序进程 LSF 主机根据它们在集群中的角色，运行各种守护进程。 守护程序 角色 mbatchd 作业请求与分配 mbschd 作业调度 sbatchd 作业执行 res 作业执行 lim 节点信息 pim 作业进程信息 elim 动态负荷指标 mbatchd 在主节点上运行的主批处理守护程序。 负责系统中作业的总体状态。 接收作业提交和信息学查询请求。管理队列中保留的作业。由 mbschd 确定将作业分配给主机。 mbschd 在主节点上运行的主批处理调度守护程序。 与 mbatchd 一起使用。 根据作业要求，策略和资源可用性制定调度决策。 将调度决策发送到 mbatchd sbatchd 在每个服务器主机（包括主主机）上运行的从属批处理守护程序。 从 mbatchd 接收运行作业的请求，并管理作业的本地执行。 负责执行本地策略并维护主机上的作业状态。 sbatchd 会为每个作业分出一个子sbatchd。 子 sbatchd 运行一个 res 实例，以创建作业在其中运行的执行环境。 作业完成后，子sbatchd 退出。 res 在每个服务器主机上运行的远程执行服务器（RES）。 接受远程执行请求，以提供清晰，安全的作业和任务的远程执行。 lim 在每个服务器主机上运行的负载信息管理器（LIM）。 收集主机负载和配置信息，并将其转发到在主节点上运行的主LIM。报告由 lsload 和 lshosts 显示的信息。 当 LIM 启动或 CPU（ncpus）数量更改时，将报告静态索引。 Master LIM 在主节点上运行的 LIM。从集群中的节点上运行的 LIM，接收负载信息。 将负载信息转发到 mbatchd，后者将信息转发到 mbschd 以支持调度决策。如果主 LIM 不可用，则候选主节点上的 LIM 将自动接管。 PIM 在每个服务器主机上运行的进程信息管理器（PIM）。 由 LIM 启动，它会定期检查 PIM 并在 PIM 挂掉后重新启动。 收集有关主机上运行的作业进程的信息，例如作业使用的 CPU 和内存，并将该信息报告给 sbatchd。 ELIM 外部LIM（ELIM）是一个可在站点定义的可执行文件，用于收集和跟踪自定义动态负载索引。 ELIM 可以是 Shell 脚本或编译的二进制程序，它们返回您定义的动态资源的值。 ELIM 可执行文件必须命名为 elim.anything，并且位于 LSF_SERVERDIR 中。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 12:06:10 "},"chapter3/section2/cluster_communication_paths.html":{"url":"chapter3/section2/cluster_communication_paths.html","title":"集群通信方式","keywords":"","body":"集群通信方式 了解集群中 LSF daemon 之间的通信路径。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 09:11:45 "},"chapter3/section2/falut_tolerance.html":{"url":"chapter3/section2/falut_tolerance.html","title":"容错","keywords":"","body":"容错 LSF 的强大体系结构在设计时考虑了容错能力。 系统中的每个组件都具有恢复操作，因此，重要组件可以由另一个组件监视，并可以自动从故障中恢复。 即使集群中的某些主机不可用，LSF 也可以继续运行。 集群中的一个主机充当主节点，但是如果该主节点不可用，则由另一台主机候选节点接管。当集群中有一个主节点候选时，LSF 可用。 LSF 可以容许集群中，任何主机或主机组的故障。当某主机不可用时，在该主机上运行的所有作业，将会重新排队运行或丢失，具体取决于该作业是否被标记为可重新运行。其他挂起或正在运行的作业，则不会受到影响。 故障转移的工作原理 容错能力取决于事件日志文件 lsb.events，该文件保存在主文件服务器上。系统中的每个事件都记录在该文件中，包括所有作业提交以及作业和主机状态更改。如果主节点不可用，则从主节点候选列表中选择一个新的主节点，新的主节点上的 sbatchd 守护程序，将启动一个新的 mbatchd 守护程序。 新的 mbatchd 守护程序，会读取lsb.events 文件以恢复系统状态。 重复事件记录 对于不希望仅依靠中央文件服务器获取恢复信息的站点，可以将 LSF 配置为通过保留 lsb.events 文件的副本来维护重复的事件日志。 副本存储在文件服务器上，并且在主副本不可用时使用。 启用重复事件日志记录后，主事件日志将本地存储在第一个主主机上，并在主机恢复时与复制的副本重新同步。 主机故障转移 LSF 主节点是动态选择的。如果当前的主节点不可用，则另一台主机将自动接管。故障转移主机，是从 lsf.conf 文件（在安装时在 install.config 文件中指定）的 LSF_MASTER_LIST 参数中定义的列表中选择的。列表中的第一个可用节点充当主机。 正在运行的作业由每个服务器主机上的 sbatchd 守护程序管理。 当新的 mbatchd 守护程序启动时，它将轮询每个主机上的 sbatchd 守护程序，并找到其作业状态。如果 sbatchd 守护程序失效，但主机仍在运行，则主机上正在运行的作业不会丢失。 重新启动 sbatchd 守护程序后，它将重新获得对主机上正在运行的所有作业的控制。 作业故障转移 作业可以通过可重新运行的方式来提交，如此一来，它们可以从头开始自动运行，也可以通过可检查点的形式提交，如此一来，如果由于主机故障而挂掉，则可以从另一个主机上的检查点重新开始。 如果集群中的所有主机都关闭，则所有正在运行的作业都将丢失。 当主节点的候选节点，恢复并接管为主节点时，它将读取 lsb.events 文件，以获取所有批处理作业的状态。 除非系统将其标记为可重新运行，否则系统关闭时，正在运行的作业将被认为已退出，并且电子邮件将发送给提交用户。等待的作业则保留在队列中，并在主机可用时，进行调度。 分区集群 如果集群因网络故障而分区，则 master LIM 会接管分区的每一侧，而候选主节点则在分区的每一侧都可用。 当每个主机仍然可以访问 LSF 可执行文件时，交互式负载共享仍然可用。. 分区网络 如果对网络进行了分区，则只有一个分区可以访问 lsb.events 文件，因此 LSF 服务仅在分区的一侧可用。一个锁定文件，用于确保集群中仅运行一个 mbatchd 守护程序。 作业异常处理 您可以配置主机和队列，以便 LSF 在作业运行时检测到异常情况，并自动采取适当的措施。 您可以自定义检测到哪些异常以及相应的操作。 例如，您可以将 LSF 设置为在作业退出并显示特定错误代码时，自动重新启动。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 10:44:54 "},"chapter3/section2/security.html":{"url":"chapter3/section2/security.html","title":"安全","keywords":"","body":"安全 了解 LSF 安全模型，身份验证和用户角色。 LSF 安全模型 默认情况下，LSF 安全模型在内部跟踪用户帐户。 LSF 中定义的用户帐户，包括用于提供身份验证的密码和用于提供授权的已分配角色，例如管理员。 LSF 用户角色 没有启用EGO的 LSF 支持以下用户角色： LSF 用户 有权将作业提交到 LSF 集群，并查看作业和群集的状态。 LSF 主要管理员 有权执行集群范围的操作，更改配置文件，重新配置集群以及控制所有用户提交的作业。lsb.params 和lsb.hosts 等配置文件，可配置 LSF 的各个方面。 LSF 管理员 有权执行影响其他LSF用户的操作。集群管理员可以对集群中的所有作业和队列，执行管理操作。可能没有更改 LSF 配置文件的权限。 队列管理员的管理权限仅限于指定的队列。 主机组的管理员管理权限仅限于指定的主机组。 用户组的管理员管理权限仅限于指定的用户组。 启用 EGO 的 LSF 用户角色 启用 EGO 的 LSF，支持以下角色： 集群管理员 可以管理集群中的任何对象和工作负载。 消费者管理员 可以管理他们有权访问的使用者中的任何对象和工作负载。 消费者用户 可以在他们有权访问的使用者中运行工作负载。 用户帐户是在 EGO 中创建和管理的。 EGO 从其用户数据库授权用户。 LSF 用户组 在可以指定 LSF 用户组的任何位置上，指定 UNIX 或 Linux 用户组，以此来直接使用任何现有的 UNIX 和 Linux 用户组。 外部认证 LSF 为倾向于使用外部或第三方安全机制（例如 Kerberos，LDAP 或 ActiveDirectory）的站点，提供了一个安全插件。 您可以创建自定义的 eauth 可执行文件，以提供用户，主机和守护程序的外部身份验证。 凭证是从外部安全系统传递的。还可以通过自定义的 eauth 可执行文件，来从操作系统或从诸如 Kerberos 的身份验证协议获取凭据。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 10:45:35 "},"chapter3/section3/inside_workload_management.html":{"url":"chapter3/section3/inside_workload_management.html","title":"3.3 作业负载管理","keywords":"","body":"3.3 作业负载管理 了解 LSF 作业生命周期。 使用 bsub 将作业提交到队列，并指定作业提交选项以修改默认作业行为。 提交的作业在队列中等待，直到将它们调度并分配到主机上来执行。 在作业分发时，LSF 会检查哪些主机有资格运行该作业。 作业生命周期 LSF 作业会经历几种状态，从作业提交开始，到分发，执行和最终返回作业结果。 作业提交 使用 bsub 命令在命令行上提交作业。 您可以使用 bsub 命令指定许多选项来修改默认行为。 作业必须提交到队列中。 作业调度和分配 提交的作业在队列中等待，直到将它们调度并分配到主机上来执行。 主机选择 每次 LSF 尝试分派作业时，它都会检查哪些主机有资格运行该作业。 作业执行环境 当 LSF 运行作业时，它将环境从提交主机，复制到执行主机。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:29:33 "},"chapter3/section3/job_lifecycle.html":{"url":"chapter3/section3/job_lifecycle.html","title":"作业生命周期","keywords":"","body":"作业生命周期 LSF 作业经历几种状态，从作业提交开始，到调度，执行和最终返回作业结果。 1. 提交一个作业 您可以使用 bsub 命令从 LSF 客户端或服务器提交作业。 如果在提交作业时未指定队列，则该作业将提交到默认队列。 作业在等待调度时被排在队列中。 等待的作业处于 PEND 状态。 如果在配置文件lsb.params中定义了 MAX_INFO_DIRS 参数，则该作业将保存在 LSF_SHAREDIR/cluster_name/logdir/info/ 目录中的作业文件中，或者在其子目录之一中。 作业 ID 提交作业时，LSF 为每个作业分配唯一的作业 ID。 作业名 您还可以使用 bsub的 -J 选项为作业分配一个任意名称。 与作业 ID 不同，作业名称不一定是唯一的。 2. 调度该作业 1 主批处理守护程序（mbatchd）查看队列中的作业，然后将要调度的作业，发送到主批处理调度程序守护程序（mbschd）。 作业以预设的时间间隔进行调度（由配置文件 lsb.params 中的参数 JOB_SCHEDULING_INTERVAL 定义）。 2 mbschd 根据以下内容评估作业并制定计划决策： 作业优先级 调度策略 可用资源 3 mbschd 选择作业可以运行的最佳主机，并将其决策发送回 mbatchd。资源信息由主负载信息管理器（LIM）以预设的时间间隔，从服务器主机上的 LIM 上收集。 主 LIM 将此信息传达给 mbatchd，后者又将其传达给 mbschd 以支持调度决策。 3. 分配该作业 mbatchd 收到调度决策后，便立即将作业分配给主机。 4. 运行该作业 从属批处理守护程序（sbatchd）具有以下功能： 1 从 mbatchd 接收请求。 2 为作业创建一个子 sbatchd 。 3 创建执行环境。 4 通过使用远程执行服务器（res）启动作业。 LSF 将执行环境从提交主机复制到执行主机： 作业所需的环境变量 作业开始运行的工作目录 其他与系统有关的环境设置 在 UNIX 和 Linux 上，资源限制和 umask 在 Windows，桌面和 Windows 根目录 作业在提交该作业的用户帐户下运行，并且状态为 RUN。 5. 返回结果 作业完成后，如果作业完成没有任何问题，则会被分配为 \"DONE\" 状态。 如果错误导致作业无法完成，则会为该作业分配 \"EXIT\" 状态。 sbatchd 传递作业信息，例如错误信息，并输出到 mbatchd。 6. 向客户发送 email mbatchd 通过电子邮件将作业输出，作业错误和作业信息返回给提交主机。 使用 bsub 的 -o 和 -e 选项将作业输出和错误发送到文件。 作业报告通过电子邮件发送给 LSF 客户端，其中包括以下信息： 作业信息: CPU 使用 内存使用 提交作业的帐户名称 作业输出 错误 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 10:04:29 "},"chapter3/section3/job_submission.html":{"url":"chapter3/section3/job_submission.html","title":"作业提交","keywords":"","body":"作业提交 使用 bsub 命令在命令行上提交作业。 您可以使用 bsub 命令指定许多选项来修改默认行为。 而作业必须提交到队列中。 队列 队列代表一组挂起等待的作业，它们按定义的顺序排列，并等待其使用资源的机会。 队列执行不同的作业调度和控制策略。 队列有以下特征: 优先级 名称 队列限制 (对主机、作业数、用户、组、或者处理器的限制) 标准 UNIX 和 Linux 限制（内存，交换，进程，CPU） 调度策略 管理员 运行条件 负载共享阈值条件 UNIX nice 值 (设置 UNIX 和 Linux 调度程序优先级) 队列优先级 定义搜索队列，以确定要处理的作业的顺序。 LSF 管理员为队列分配了优先级，其中数值越高，优先级越高。 LSF按从高到低的优先级为队列提供服务。 如果多个队列具有相同的优先级，则 LSF 按照先来先服务的顺序，调度这些队列中的所有作业。 自动队列选择 提交作业时，LSF 会考虑作业要求，并自动从候选默认队列列表中，选择合适的队列。 LSF 根据以下约束条件选择合适的队列： 用户访问限制 不允许该用户提交作业的队列，不会予以考虑。 节点限制 如果作业明确指定了可以在其上运行作业的主机节点列表，则必须将所选的队列，配置为作业发送到列表中的主机。 队列状态 不考虑关闭的队列。 排他执行限制 如果作业需要排他执行，则未配置为接受排他作业的队列，将不予考虑。 作业所需的资源 作业请求的资源，必须在所选队列的资源分配限制内。 如果多个队列满足上述要求，则选择满足要求的候选队列中，列出的第一个队列。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 10:04:19 "},"chapter3/section3/job_scheduling_and_dispatch.html":{"url":"chapter3/section3/job_scheduling_and_dispatch.html","title":"作业调度","keywords":"","body":"作业调度与分配 提交的作业在队列中等待，直到将它们调度并分配到主机以执行。 将作业提交给 LSF 时，许多因素控制着作业开始的时间和地点: 队列或主机的活动时间窗口 作业的资源需求 合格主机的可用性 各种作业槽位限制 作业依赖条件 Fairshare 限制（已配置的用户共享策略） 负载条件 调度策略 为了解决各种问题，LSF 允许在同一集群中，使用多种调度策略。 LSF 有几种队列调度策略，例如排他，抢占，公平共享和分层公平共享。 先来先服务（FCFS）调度: 默认情况下，队列中的作业按 FCFS 顺序分派。 这意味着作业将根据其在队列中的顺序进行调度。 服务水平协议（SLA）调度: LSF 中的 SLA 是 “及时” 的调度策略，用于调度 LSF 管理员和 LSF 用户之间约定的服务。 SLA 调度策略定义应从每个 SLA 运行多少作业，以达到配置的目标。 公平共享调度: 如果您为队列指定一个公平共享调度策略，或者如果已配置主机分区，则 LSF 会根据分配的用户份额，资源使用，或其他因素在用户之间调度作业。 抢占式调度: 您可以指定所需的行为，以便当两个或多个作业竞争同一资源时，一个作业优先于另一个作业。 抢占不仅适用于作业槽位，而且还适用于提前预订（为特定作业保留主机节点）和许可证（使用 IBM Platform License Scheduler）。 回填式调度： 允许小型作业在为其他作业保留的作业槽位上运行，前提是，回填作业在保留时间到期，且资源使用到期之前完成。 调度与分配 定期安排作业（默认为5秒）。 一旦安排了作业，就可以立即将其分配给主机。 为了防止任何节点过载，默认情况下，LSF 在将作业分发到同一节点之间，会等待一小段时间。 分配顺序 作业不一定按提交顺序分派。 定义队列时，每个队列都有一个由 LSF 管理员设置的优先级编号。LSF 会尝试首先从优先级最高的队列中，启动作业。 LSF 按以下顺序考虑要分派的作业： 对于每个队列，从最高优先级到最低优先级。 如果多个队列具有相同的优先级，则 LSF 会按照先来先服务（FCFS）的顺序，调度这些队列中的所有作业。 对于队列中的每个作业，根据 FCFS 顺序。 如果有任何主机有资格运行此作业，将在最合格的主机上启动该作业，并标记该主机不具备启动任何其他作业的资格，直到经过 JOB_ACCEPT_INTERVAL 参数所指定的时间段为止。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 10:35:27 "},"chapter3/section3/host_selection.html":{"url":"chapter3/section3/host_selection.html","title":"节点选择","keywords":"","body":"节点选择 每次 LSF 尝试分配作业时，它都会检查哪些主机有资格运行该作业。 许多条件决定了节点是否符合条件: 主机调度窗口 作业的资源需求 队列的资源需求 队列中的节点列表 节点负载水平 节点的作业槽位限制 用户配额与用户限制 只有满足所有条件，主机节点才有资格运行作业。 如果队列中已有一个作业，并且该作业的合格主机可用，则该作业将放置在该主机上。 如果有多个主机符合条件，则根据作业和队列资源要求，在最佳主机上启动作业。 主机负载级别 如果主机的负载索引（例如r1m，pg，mem）的值，在配置的调度阈值之内，则该主机可用。 您可以配置两种调度阈值：主机和队列。 如果主机上的任何负载索引，超过相应的主机阈值或队列阈值，则该主机不符合运行任何作业的条件。 合格的主机 当 LSF 尝试放置作业时，它将获取所有主机的当前负载信息。 将每个主机上的负载级别，与在 lsb.hosts 的 Host 部分中，为该主机配置的调度阈值，以及在 lsb.queues 中配置的按队列调度阈值进行比较。 如果任何负载索引，超过其按队列或按主机调度的阈值，则不会在该主机上启动任何新作业。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 10:44:42 "},"chapter3/section3/job_execution_environment.html":{"url":"chapter3/section3/job_execution_environment.html","title":"作业运行环境","keywords":"","body":"作业运行环境 当 LSF 运行作业时，它将环境，从提交主机复制到执行主机。 执行环境包括以下信息: 作业所需的环境变量 作业开始运行的工作目录 其他与系统有关的环境设置，例如资源使用限制 共享的用户目录 为了提供透明的远程执行，LSF 命令确定用户的当前工作目录，并在远程主机上使用该目录。 可执行文件和 PATH 环境变量 可执行文件的搜索路径（PATH环境变量），未更改地传递到远程执行主机。 注意 在混合集群中，当用户二进制目录，在不同主机类型上具有相同路径名时，LSF 效果最佳。使用相同的路径名，可使 PATH 变量在所有主机上均有效。 为了便于管理，LSF 配置文件存储在共享目录中。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 10:11:23 "},"chapter3/section4/LSF_with_EGO_enabled.html":{"url":"chapter3/section4/LSF_with_EGO_enabled.html","title":"3.4 启用 EGO 的 LSF","keywords":"","body":"3.4 启用 EGO 的 LSF 具有 LSF 的企业网格协调器（enterprise grid orchestrator EGO）能够提供系统基础结构，来控制和管理集群资源。 资源是应用程序使用的物理和逻辑实体。 LSF 资源按照 EGO资源分配计划中的定义进行共享。 EGO组件概述 可以使用 LSF 启用 EGO，以提供系统基础结构来控制和管理群集资源。 资源 资源是应用程序用来运行的物理和逻辑实体。 资源是一个通用术语，可以包含低级内容，例如共享内存段或信号灯。 在 LSF 中，EGO 管理CPU 槽位。. LSF 如何通过 EGO 共享资源 可以通过定义 EGO 资源分配计划，来共享 LSF 资源。 LSF 向 EGO 资源管理器请求资源。 根据资源分配计划中指定的值，资源管理器返回可用槽位数（m）和该槽位所在的主机的名称。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter3/section4/EGO_component_overview.html":{"url":"chapter3/section4/EGO_component_overview.html","title":"EGO 组件概览","keywords":"","body":"EGO 组件概览 可以使用 LSF 启用 EGO，以提供系统基础结构来控制和管理群集资源。 就像在一台计算机上运行的操作系统聚合并虚拟化物理资源，并将其分配给应用程序一样，EGO 可以在分布式环境中执行类似的功能。 EGO 管理逻辑和物理资源，并支持所有形式的应用程序。 EGO 管理资源的供应，使资源可供应用程序使用。 主机可以分为两类：管理节点和计算节点。 管理节点为集群提供专门服务，而计算节点运行用户作业负载。 管理节点 管理节点在集群内提供集群和工作负载管理服务，并且不应为用户运行工作负载。 主节点，所有候选主节点和会话管理器主机必须是管理节点。 其他管理节点，包括运行数据加载器的主机，和用于报告功能的数据清除器。所有管理节点，都在同一操作系统上运行：所有 Windows，所有 UNIX 或所有 Linux。 主节点 主节点是集群中安装的第一台主机。 集群的资源管理器（vemkd）驻留在此主机上。 主节点控制集群中其余的主机，并且是集群客户端的接口。 候选主节点 一次只有一台主机。 如果主节点发生故障，则另一台主机将自动接管主节点角色。 可以充当主节点的主机称为候选主节点。 会话管理节点 一个或多个管理节点运行会话管理器。 管理节点上每个可用插槽都有一个会话管理器。 每个应用程序有一个会话管理器。 计算节点 计算节点，是集群中为消费者提供计算资源的那些主机。 集群可以包含任意数量的计算节点，但必须至少具有一个计算节点。 CPU 槽位 CPU 槽位是用于测量计算资源的单位。 一个 CPU 槽位可以在计算节点上运行一个服务实例，也可以在管理节点上运行一个会话管理器。 守护进程 vemkd 在主节点上运行的 VEM 内核守护程序。 它启动其他守护程序并响应分配请求。 egosc v 服务控制器从 vemkd 守护程序，请求适当的资源并控制服务实例。 pem 进程执行管理器，可用于 vemkd 守护程序，启动，控制和监视活动，以及收集和发送运行时资源使用情况。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter3/section4/resources.html":{"url":"chapter3/section4/resources.html","title":"资源","keywords":"","body":"资源 资源是应用程序用来运行的物理和逻辑实体。 资源是一个通用术语，可以包含低级内容，例如共享内存段，或信号灯。 在 LSF 中，EGO 管理 CPU 槽位。 特定类型的资源具有属性。 例如，计算主机具有内存，CPU 利用率，操作系统类型的属性。 资源组 可以将资源分组为逻辑组，以简化标识，资源分配或用于管理和监视目的。 这些资源组，用于为使用者提供一组类似的主机来运行工作负载。 资源组中的任何主机都可以运行相同的工作负载。 下图显示了两个资源组： 管理节点 计算节点 如果所有主机都相同，则这些资源组可能就足够了。 如果您的应用程序需要特定类型的主机（例如，以最低的处理器速度运行），并且并非所有主机都满足此条件，则可能需要创建资源组以将类似的主机分组在一起。 例如，对资源进行分组的一种简单方法，可能是按操作系统类型对主机进行分组。 EGO 提供了一种通用的资源分组机制。 资源可能来自系统，或经过系统，因此 EGO 支持资源组中的动态成员资格。 可以将主机显式放置到各个资源组中，也可以根据特定条件，使用动态成员资格来定义资源组。 此条件包括操作系统类型，CPU 速度，总内存或交换配置或自定义属性。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter3/section4/LSF_resource_sharing.html":{"url":"chapter3/section4/LSF_resource_sharing.html","title":"LSF 资源共享","keywords":"","body":"LSF 资源共享 可以通过定义 EGO 资源分配计划来共享 LSF 资源。 LSF 向 EGO 资源管理器请求资源。 根据资源分配计划中指定的值，资源管理器返回可用槽数（m）和该槽位所在的主机的名称。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 10:47:01 "},"chapter4/administrator_fundations.html":{"url":"chapter4/administrator_fundations.html","title":"Chapter 4 管理员操作基础","keywords":"","body":"Chapter 4 管理员操作基础 本章内容是 IBM Spectrum LSF 的管理员概述，掌握本章，可以了解如何管理各种类型的工作负载和集群操作。 LSF 集群概览 概述您的集群以及重要的 LSF 目录和配置文件的位置。 使用 LSF 调度 启动和停止 LSF 守护程序，重新配置集群属性。 检查 LSF 状态并提交 LSF 作业。 解决 LSF 问题 解决常见的 LSF 问题并了解 LSF 错误信息。 如果在这里找不到解决问题的方法，请联系 IBM 支持。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 12:01:57 "},"chapter4/section1/cluster_overview.html":{"url":"chapter4/section1/cluster_overview.html","title":"4.1 集群概览","keywords":"","body":"4.1 集群概览 概述您的集群以及重要的 LSF 目录和配置文件的位置。 LSF术语和概念 首次使用 LSF 之前，应先阅读 LSF Foundations Guide，以基本了解作业负载管理和作业提交，以及 Administrator Foundations Guide，以概述集群管理和操作。 集群特征 在安装后查询集群的名称，集群管理员以及定义主机的位置。 文件系统，目录，文件 LSF 设计用于所有主机都具有共享文件系统，且所有主机上文件都同名的网络。 重要目录和配置文件 通过多个配置文件管理 LSF 配置，您可以使用这些文件来修改集群的行为。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 11:31:50 "},"chapter4/section1/terms_and_concepts.html":{"url":"chapter4/section1/terms_and_concepts.html","title":"术语与概念","keywords":"","body":"术语与概念 首次使用 LSF 之前，应先阅读 LSF Foundations Guide，以基本了解作业负载管理和作业提交，以及 Administrator Foundations Guide，以概述集群管理和操作。 作业状态 IBM Spectrum LSF 作业有几种状态。 PEND 在队列中等待调度和分配。 RUN 分派给主机并运行。 DONE 正常完成，退出状态码为 0。 EXIT 以非 0 退出值结束。 PSUSP 作业等待时挂起。 USUSP 被用户暂停。 SSUSP 被 LSF 系统暂停。 POST_DONE 后处理完成，没有错误。 POST_ERR 后处理完成，但有错误。 UNKWN mbatchd 守护程序，与作业运行所在主机上的 sbatchd 守护程序失去联系。 WAIT 对于提交到块作业队列的作业，是等待运行的块作业成员。 ZOMBI 如果杀死不可重新运行的作业，或将可重新运行的作业重新排队时，如果执行主机不可访问，则该作业将变为ZOMBI。 主机节点 LSF 主机是集群中的单个计算机。 每个主机可能有多个处理器。 多处理器主机用于运行并行作业。 具有单个进程队列的多处理器主机被视为一台计算机。 装满处理器的盒子，每个处理器都有自己的处理队列，被视为一组单独的计算机。 Tip 主机的名称应唯一。 它们不能与集群名称或为集群定义的任何队列相同。 作业 LSF 作业是在 LSF 系统中运行的工作单元。 作业是使用 bsub 命令提交给 LSF 以便执行的命令。 LSF 根据配置的策略计划，控制和跟踪作业。 作业可能是复杂的问题，模拟方案，大量的计算，以及任何需要计算能力的事物。 作业文件 将作业提交到队列后，LSF 会将其保存在作业文件中，直到适合运行条件为止。 然后，使用作业文件运行作业。 在 UNIX 上，作业文件是在执行时运行的 Bourne Shell 脚本。 在 Windows 上，作业文件是在执行时处理的批处理文件。 交互式批处理作业 交互式批处理作业，是一个批处理作业，它使您可以与应用程序进行交互，并且仍然利用 LSF 调度策略和容错能力。 所有输入和输出都是通过用于键入作业提交命令的终端进行的。 提交交互式作业时，在作业等待调度时会显示一条消息。 在交互式作业完成或终止之前，无法提交新作业。 交互式任务 交互式任务是没有提交给批处理队列，并由 LSF 调度但立即分派的命令。 LSF 查找任务所需的资源，并在具有所需资源且负载较轻的候选主机中选择最佳主机。 每个命令可以是单个进程，也可以是一组协作进程。 在不使用 LSF 的批处理功能的情况下运行任务，但仍具有资源需求和根据负载选择最佳主机来运行任务的优势。 本地任务 本地任务是没有意义的应用程序或命令，不能远程运行。 例如，UNIX上的 ls 命令。 远程任务 远程任务，是可以在集群中的另一台计算机上运行的应用程序或命令。 主机类型与主机型号 LSF中的主机，由主机类型和主机模型表征。 以下示例是类型为 X86_64 的主机，其主机型号为 Opteron240，Opteron840，Intel_EM64T 等。 主机类型 LSF 主机类型，是操作系统和主机 CPU 体系结构的组合。 在相同计算机体系结构上，运行相同操作系统的所有计算机都属于同一类型。 这些主机彼此二进制兼容。 每种主机类型，通常需要一组不同的 LSF 二进制文件。 主机型号 LSF 主机模型是计算机的主机类型，它确定在负载和放置计算中应用的 CPU 速度缩放因子。 调度作业时，要考虑 CPU 因素。 资源 LSF 资源是 LSF 系统资源中的对象，LSF 使用这些对象，来跟踪作业要求并根据它们在各个主机上的可用性来调度作业。 资源使用 LSF 系统使用内置的和配置的资源，来跟踪资源的可用性和使用情况。 根据各个主机上可用的资源，来调度作业。 通过 LSF 系统提交的作业，在运行时将受到使用的资源的监视。 此信息用于强制执行资源限制，和负载阈值以及公平分配策略。 LSF收集以下类型的信息： 作业中，所有进程消耗的总 CPU 时间 作业中，所有当前正在运行的进程的总常驻内存使用量（KB 为单位） 作业中，所有当前正在运行的进程的总虚拟内存使用量（KB 为单位） 作业中，当前活动的进程组 ID 作业中，当前活跃的进程 在 UNIX 和 Linux 上，通过 PIM 收集作业级资源使用情况。 负载指数 负载指数，衡量集群中主机上动态非共享资源的可用性。 内置在 LIM 中的负载指数，会按固定的时间间隔进行更新。 外部负载指数 由 LSF 管理员定义和配置，并由外部负载信息管理器（ELIM）程序收集。 当收到新值时，ELIM 也会更新 LIM。 静态资源 表示不会随时间变化的主机信息的内置资源，例如，可用于用户进程的最大 RAM 或计算机中的处理器数量。 大多数静态资源由 LIM 在启动时确定。 静态资源，可用于根据二进制体系结构，相对 CPU 速度和系统配置，为特定作业选择适当的主机。 负载阈值 您的 LSF 管理员，可以配置两种类型的负载阈值来调度队列中的作业。 每个负载阈值指定一个负载索引值： loadSched 负载阈值，确定用于调度待处理作业的负载条件。 如果主机的负载超出任何定义的 loadSched，则无法在主机上启动作业。 此阈值还用作恢复挂起作业的条件。 loadStop 负载阈值，确定何时可以暂停正在运行的作业。 要在主机上调度作业，该主机上的负载级别，必须同时满足为该主机配置的阈值，和要从中调度作业的队列的阈值。 负载索引的值，可能随负载而增加或减少，具体取决于特定负载索引的含义。 因此，将主机负载条件与阈值进行比较时，需要根据负载指数使用大于（>）或小于（ 运行时资源使用限制 在作业运行时限制资源的使用。 发出消耗超过指定资源量的作业的信号。 硬性限制和软性限制 在队列级别指定的资源限制是硬限制，而在作业提交中指定的资源限制是软限制。 有关硬限制和软限制的信息，请参见 setrlimit 手册页。 资源分配限制 限制在作业调度期间是必须启动的，用于启动不同类别的作业的资源量，以及限制适用于哪些资源使用者。 如果消耗了所有资源，则在释放某些资源之前，无法启动更多作业。 资源需求 (bsub -R) bsub -R 选项指定作业的资源要求。 资源要求限制了可以在其上运行作业的主机。 符合资源要求的主机，是候选主机。 当 LSF 调度作业时，它将收集所有候选主机的负载索引值，并将它们与调度条件进行比较。 仅当所有负载值均在调度阈值之内时，作业才会调度到主机。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-16 20:28:24 "},"chapter4/section1/cluster_characteristics.html":{"url":"chapter4/section1/cluster_characteristics.html","title":"集群特征","keywords":"","body":"集群特征 在安装后找到集群的名称，集群管理员以及定义主机节点的位置。 集群名称与管理员 根据 lsfinstall -f install.config 命令指定的安装选项，以及在 install.config 文件中选择的选项安装集群。您在安装时指定的集群名称，是 LSF_CONFDIR/lsf.cluster.cluster_name 文件的名称的一部分。 /usr/share/lsf/lsf_10/conf/lsf.cluster.lsf_10 LSF_CONFDIR/lsf.cluster.cluster_name 文件的 ClusterAdmins 部分中列出了集群管理员。 LSF 主机节点 在 LSF_CONFDIR/lsf.cluster.cluster_name 文件的 Hosts 部分中，列出了集群中安装的主机类型。 LSF 主节点，是在 LSF_CONFDIR/lsf.cluster.cluster_name 文件的 Hosts 部分中配置的第一台主机。 集群中定义的 LSF 服务器主机，在 LSF_CONFDIR/lsf.cluster.cluster_name 文件的 Hosts 部分的 “Server” 列中用 1 表示。 在集群中定义的 LSF 仅客户端主机，在 LSF_CONFDIR/lsf.cluster.cluster_name 文件的 Hosts 部分的 “Server” 列中用 0 表示。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 10:29:24 "},"chapter4/section1/filesystems_directories_and_files.html":{"url":"chapter4/section1/filesystems_directories_and_files.html","title":"文件系统、目录和文件","keywords":"","body":"文件系统、目录和文件 LSF 是为所有主机都具有共享文件系统，且所有主机上的文件具有相同名称的网络而设计的。 LSF 支持在批处理作业运行之前将用户数据复制到执行主机，并在作业运行之后将结果复制回来。 在不共享文件系统的网络中，此支持，可用于使远程作业访问本地数据。 支持的文件系统 UNIX 在 UNIX 系统上，LSF 支持以下共享文件系统： Network File System (NFS) NFS 文件系统可以永久安装，也可以使用 automount 命令按需安装。 Andrew File System (AFS) 在 9.1.2 集成的参数下，以及一些已发布的配置参数下按需支持。 支持访问 AFS，AFS 上的JOB_SPOOL_DIR ，以及 AFS 上的作业输出和错误文件的顺序和并行用户作业。 Distributed File System (DCE/DFS) 按需支持。 Windows 在 Windows 上，可以从 Windows 服务器计算机的主机之间，共享包含 LSF 文件的目录。 非共享目录和文件 LSF 用于具有共享文件空间的网络。 当共享文件空间不可用时，LSF 可以在作业运行之前，将所需文件复制到执行主机，并在作业完成后，将结果文件复制回提交主机。 某些网络不在主机之间共享文件。 LSF 仍可以在这些网络上使用，但容错能力却有所降低。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 10:29:02 "},"chapter4/section1/Example directory structures.html":{"url":"chapter4/section1/Example directory structures.html","title":"示例目录结构","keywords":"","body":"示例目录结构 下图显示了在 UNIX 和 Linux 或 Microsoft Windows 上新安装的典型目录结构。 根据您安装的产品和选择的平台，目录结构可能会有所不同。 UNIX and Linux 下图显示了使用 lsfinstall 命令的新 UNIX 或 Linux 安装的典型目录结构。 Microsoft Windows 下图显示了新的 Windows 安装的典型目录结构。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 10:37:30 "},"chapter4/section1/important_directories_and_configuration_files.html":{"url":"chapter4/section1/important_directories_and_configuration_files.html","title":"重要的文件目录与配置文件","keywords":"","body":"重要的文件目录与配置文件 LSF 配置，通过几个配置文件进行管理，您可以使用这些文件来修改集群的行为。 四个重要的 LSF 配置文件 以下是您最常使用的四个最重要的文件： LSF_CONFDIR/lsf.conf LSF_CONFDIR/lsf.cluster.cluster_name LSF_CONFDIR/lsf.shared LSB_CONFDIR/cluster_name/configdir/lsb.queues 这些文件，是在产品安装期间根据您在 install.config 文件中指定的选项创建的。 安装后，您可以更改这些文件中的配置参数，以适合您的站点的需求。 谁拥有这些文件 除了由 root 拥有的 LSF_CONFDIR/lsf.conf 外，所有这些文件均由 LSF 主管理员拥有，并且所有集群用户均可读取。 lsf.conf LSF 中最重要的文件。 它包含配置目录，日志目录，库和其他全局配置信息的路径。 lsf.conf 文件的位置由LSF_ENVDIR 变量定义。 如果 LSF 找不到此文件，则它将无法正常启动。默认情况下，LSF会检查 LSF_ENVDIR 参数定义的目录中的 lsf.conf 文件的位置。 如果 lsf.conf 文件不在 LSF_ENVDIR 中，则 LSF 在 /etc 目录中查找它。 lsf.cluster.cluster_name 定义集群中所有主机的主机名，型号和类型。 它还定义了 LSF 管理员的用户名，以及一个集群的不同共享资源的位置。 lsf.shared 该文件就像一个字典，定义了集群使用的所有关键字。 您可以添加自己的关键字，来指定资源或主机类型的名称。 lsb.queues 为一个集群定义作业负载队列及其参数。 LSF 目录 以下目录归 LSF 主管理员所有，并且所有集群用户均可读取： 目录 描述 示例 LSF_CONFDIR LSF 配置目录 /usr/share/lsf/cluster1/conf/ LSB_CONFDIR 批处理系统配置目录 /usr/share/lsf/cluster1/conf/lsbatch/ LSB_SHAREDIR 作业历史目录 /usr/share/lsf/cluster1/work/ LSF_LOGDIR 服务器守护程序错误日志，每个守护程序一个 /usr/share/lsf/cluster1/log/ 以下目录归 root 拥有，并且所有集群用户均可读取： 目录 描述 示例 LSF_BINDIR LSF 用户命令，由相同类型的所有主机共享 /usr/share/lsf/cluster1/10.1/sparc-sol10/bin/ LSF_INCLUDEDIR 头文件 lsf/lsf.h 和 lsf/lsbatch.h /usr/share/lsf/cluster1/10.1/include/ LSF_LIBDIR LSF 库，由相同类型的所有主机共享 /usr/share/lsf/cluster1/10.1/sparc-sol10/lib/ LSF_MANDIR LSF manual 手册 /usr/share/lsf/cluster1/10.1/man/ LSF_MISC 示例和其他杂项文件 /usr/share/lsf/cluster1/10.1/misc/ LSF_SERVERDIR 服务器守护程序二进制文件，脚本和其他实用程序，由相同类型的所有主机共享 /usr/share/lsf/cluster1/10.1/sparc-sol10/etc/ LSF_TOP 顶级安装目录 /usr/share/lsf/cluster1/ 可以在 LSF_CONFDIR/lsf.conf 文件中指定其他配置目录。 LSF 集群配置文件 以下文件归 LSF 主管理员所有，并且所有集群用户均可读取： 文件描述 示例 全局配置文件，描述集群的配置和操作 /usr/share/lsf/cluster1/conf/ego/cluster1/kernel/ego.conf /usr/share/lsf/cluster1/conf/lsf.conf 所有集群共享的关键字定义文件。 定义集群名称，主机类型，主机模型和特定于站点的资源 /usr/share/lsf/cluster1/conf/lsf.shared 群集配置文件，用于定义主机，管理员和站点定义的共享资源的位置 /usr/share/lsf/cluster1/conf/lsf.cluster.cluster1 任务名称及其默认资源要求的映射文件 /usr/share/lsf/cluster1/conf/lsf.task /usr/share/lsf/cluster1/conf/lsf.task.cluster1 LSF 批处理作业负载系统配置文件 以下文件归 LSF 主管理员所有，并且所有集群用户均可读取： 文件描述 示例 服务器主机及其属性，例如计划负载阈值，调度窗口和作业槽位限制。 如果在此文件中未定义任何主机，则假定LSF_CONFDIR/lsf.cluster.cluster_name中列出的所有 LSF 服务器主机都是 LSF 批处理服务器主机。 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.hosts LSF 调度程序和资源代理插件模块。 如果未配置任何调度程序，或资源代理模块，则 LSF 使用默认调度程序插件模块schmod_default。 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.modules LSF 批处理系统参数文件 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.params 作业队列定义 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.queues 资源分配限制，导出和资源使用限制。 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.resources LSF 用户组，用户和用户组的分层公平共享，以及用户和用户组的作业位置限制。 还用于为 LSF 多集群功能配置帐户映射。 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.users 应用程序概要文件，其中包含相同类型作业的通用参数，包括应用程序的执行要求，所需的资源以及运行和管理方式。 该文件是可选的。 使用 lsb.params 文件中的DEFAULT_APPLICATION 参数，为所有作业指定默认的应用程序配置文件。 LSF 不会自动分配默认的应用程序配置文件。 /usr/share/lsf/cluster1/conf/lsbatch/cluster1/configdir/lsb.applicatons LSF 批处理日志文件 文件描述 示例 批处理事件日志 /usr/share/lsf/cluster1/work/ cluster1/logdir/lsb.events 批处理记帐日志 /usr/share/lsf/cluster1/work/ cluster1/logdir/lsb.acct 守护程序日志文件 LSF 服务器守护程序日志文件，存储在 LSF_CONFDIR/lsf.conf 中由 LSF_LOGDIR 指定的目录中。 文件 示例 Load information manager (lim) /usr/share/lsf/cluster1/log/lim.log.hosta Remote execution server (res) /usr/share/lsf/cluster1/log/res.log.hosta Master batch daemon (mbatchd) /usr/share/lsf/cluster1/log/ mbatchd.log.hosta Master scheduler daemon (mbschd) /usr/share/lsf/cluster1/log/mbschd.log.hosta Slave batch daemon (sbatchd) /usr/share/lsf/cluster1/log/sbatchd.log.hosta Process information manager (pim) /usr/share/lsf/cluster1/log/ pim.log.hosta 注意： 谁拥有，谁应该写给LSF_LOGDIR 确保 LSF 主管理员拥有 LSF 日志目录（LSF_LOGDIR参数），并且 root 可以写入该目录。 如果 LSF 服务器无法写入 LSF_LOGDIR 参数，则在 /tmp 中创建错误日志。. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-16 20:56:10 "},"chapter4/section2/work_with_LSF.html":{"url":"chapter4/section2/work_with_LSF.html","title":"4.2 使用 LSF","keywords":"","body":"4.2 使用 LSF 启动和停止 LSF 守护程序，然后重新配置集群属性。 检查 LSF 状态并提交 LSF 作业。 启动，停止和重新配置LSF 使用 LSF 管理命令 lsadmin 和 badmin 启动和停止 LSF 守护程序，并重新配置集群属性。 检查 LSF 状态 使用LSF管理命令检查集群配置，查看集群状态，以及 LSF 批处理作业负载系统配置和状态。 运行 LSF 作业 使用 bsub 和 lsrun 命令通过 LSF 运行作业。 使用 bjobs 命令查看您的作业状态。 使用 bstop，bresume 和 bkill 命令控制作业执行。 管理用户，主机和队列 使用 cshrc.lsf 和 profile.lsf 使集群对用户可用。 从集群中添加或删除主机和队列。 配置 LSF 启动 使用 lsf.sudoers 文件，以便 LSF 管理员可以启动和停止 LSF 守护程序。 将 LSF 设置为自动启动。 管理软件许可证和其他共享资源 设置 LSF 外部 LIM（ELIM），以将软件许可证作为动态共享资源进行监视。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:57:41 "},"chapter4/section2/subsection1/start_stop_and_reconfigure_LSF.html":{"url":"chapter4/section2/subsection1/start_stop_and_reconfigure_LSF.html","title":"开启、结束与重配置 LSF","keywords":"","body":"开启、结束与重配置 LSF 使用LSF管理命令 lsadmin 和 badmin 启动和停止 LSF 守护程序，并重新配置集群属性。 两个 LSF 管理命令（lsadmin 和 badmin） 注意 只有 LSF 管理员或 root 用户可以运行这些命令。 要启动和停止 LSF，以及在更改任何配置文件后，重新配置 LSF，请使用以下命令： lsadmin 命令控制 lim 和 res 守护程序的操作。 badmin 命令控制 mbatchd 和 sbatchd 守护程序的操作。 如果您以 非root 用户身份安装 LSF 默认情况下，只有 root 可以启动 LSF 守护程序。 如果 lsfinstall 命令检测到您以 非root 用户身份安装，则选择配置多用户集群还是单用户集群： 多用户配置 只有 root 可以启动 LSF 守护程序。 任何用户都可以将作业提交到您的集群。有关更改 lsadmin 和 badmin命令的所有权和权限的信息，请参阅 Troubleshooting LSF problems. 要允许 LSF 管理员启动和停止 LSF 守护程序，请按照 Configure LSF Startup 中的说明设置 /etc/lsf.sudoers 文件。 单用户 您的用户帐户必须是 LSF 主要管理员。 您可以启动 LSF 守护程序，但是只有您的用户帐户,才能将作业提交到集群。 您的用户帐户必须能够读取系统内核信息，例如 /dev/kmem。 使用 cshrc.lsf 和 profile.lsf 设置 LSF 环境 使用 LSF 之前，必须使用 cshrc.lsf 或 profile.lsf 文件设置 LSF 执行环境。 启动集群 使用 lsadmin 和 badmin 命令启动 LSF 守护程序。 停止集群 使用 lsadmin 和 badmin 命令停止 LSF 守护程序。 使用 lsadmin 和 badmin 重新配置群集 更改任何配置文件后，请使用 lsadmin 和 badmin 命令重新配置 LSF。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 09:43:50 "},"chapter4/section2/subsection1/Setting up the LSF environment.html":{"url":"chapter4/section2/subsection1/Setting up the LSF environment.html","title":"设置 LSF 环境","keywords":"","body":"设置 LSF 环境 使用 LSF 之前，必须使用 cshrc.lsf 或 profile.lsf 文件设置 LSF 执行环境。 步骤 登录到 LSF 主机后，使用以下 shell 程序环境文件之一，来设置您的 LSF 环境。 在 csh 或 tcsh shell 中，运行 source 命令： % source /conf/cshrc.lsf 在 sh , ksh, 或 bash shell 中运行以下命令: $ . /conf/profile.lsf 文件 cshrc.lsf 和 profile.lsf 是在安装过程中通过 lsfinstall 命令创建的，以设置 LSF 操作环境。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:03:01 "},"chapter4/section2/subsection1/Starting your cluster.html":{"url":"chapter4/section2/subsection1/Starting your cluster.html","title":"启动集群","keywords":"","body":"启动集群 使用 lsadmin 和 badmin 命令启动 LSF 守护程序。 步骤 以 root 用户身份登录到每个 LSF 服务器主机。 如果您以 非root 用户身份安装了单用户集群，请以 LSF 主管理员身份登录。 从 LSF 主节点开始，然后在所有 LSF 主机上重复这些步骤。 使用以下命令启动LSF集群： # lsadmin limstartup # lsadmin resstartup # badmin hstartup 在使用任何 LSF 命令之前，请等待几分钟，让 lim 守护程序所有主机执行以下操作： 互相联系 选择主节点 交换初始化信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 09:52:52 "},"chapter4/section2/subsection1/Stopping your cluster.html":{"url":"chapter4/section2/subsection1/Stopping your cluster.html","title":"停止集群","keywords":"","body":"停止集群 使用 lsadmin 和 badmin 命令停止 LSF 守护程序。 步骤 以 root 用户身份登录到每个 LSF 服务器主机。 如果您以 非root 用户身份安装了单用户集群，请以 LSF 主管理员身份登录。 使用以下命令停止 LSF 集群：: # badmin hshutdown all # lsadmin resshutdown all # lsadmin limshutdown all © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 09:54:50 "},"chapter4/section2/subsection1/Reconfiguring your cluster.html":{"url":"chapter4/section2/subsection1/Reconfiguring your cluster.html","title":"重新配置集群","keywords":"","body":"重新配置集群 更改任何配置文件后，请使用 lsadmin 和 badmin 重新配置群集 步骤 以 root 用户身份登录到每个 LSF 服务器主机。 如果您以 非root 用户身份安装了单用户集群，请以 LSF 主管理员身份登录。 使用以下命令重新配置 LSF 集群： # 重新加载修改的 LSF 配置文件并重新启动 lim： # lsadmin reconfig # 重新加载修改后的 LSF 批处理配置文件： # badmin reconfig # 重新加载修改后的 LSF 批处理配置文件，然后重新启动 mbatchd：: # badmin mbdrestart 此命令还会读取 LSF_LOGDIR/lsb.events文件，因此如果正在运行许多作业，则可能需要一些时间才能完成。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:02:49 "},"chapter4/section2/subsection2/check_LSF_status.html":{"url":"chapter4/section2/subsection2/check_LSF_status.html","title":"检查 LSF 状态","keywords":"","body":"检查 LSF 状态 使用 LSF 管理命令检查集群配置，查看集群状态，以及 LSF 批处理作业负载系统配置和状态。 命令输出示例 本节中显示的 LSF 命令显示了典型输出的示例。 您看到的输出，可能会根据您的配置而有所不同。 这些命令都是简要描述，以便您可以轻松地使用它们，来验证您的 LSF 安装。 有关完整的用法和命令选项，请参见 LSF Command Reference 或 LSF 手册页。 您可以在任何 LSF 主机上使用这些命令。 如果您从这些命令获得正确的输出，则可以使用集群了。 如果您的输出有错误，请参阅 Troubleshooting LSF problems 来获得帮助。 使用 lsadmin 命令检查集群配置 lsadmin 命令控制 LSF 集群的操作，并管理 LSF 守护程序 lim 和 res。 使用 lsid 和 lsload 命令检查集群状态 lsid 命令告诉您是否正确设置了 LSF 环境。 lsload 命令显示集群的当前负载级别。 使用 badmin 检查 LSF 批处理系统配置 badmin 命令控制和监视 LSF 批处理作业负载系统的操作。 使用 bhosts 和 bqueues 查找批处理系统状态 使用 bhosts 命令查看 LSF 批处理作业负载系统是否正常运行。 bqueues 命令显示可用队列的状态及其配置参数。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:26:48 "},"chapter4/section2/subsection2/Check cluster configuration.html":{"url":"chapter4/section2/subsection2/Check cluster configuration.html","title":"检查集群配置","keywords":"","body":"检查集群配置 lsadmin 命令控制 LSF 集群的操作，并管理 LSF 守护程序 lim 和 res。 使用 lsadmin ckconfig 命令检查 LSF 配置文件。 -v 选项显示有关 LSF 配置的详细信息： 以下输出中显示的消息是 lsadmin ckconfig -v 的典型消息。其他消息可能表明您的 LSF 配置有问题。 % lsadmin ckconfig -v Checking configuration files ... EGO 3.6.0 build 800000, Jul 25 2017 Copyright International Business Machines Corp. 1992, 2016. US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. binary type: linux2.6-glibc2.3-x86_64 Reading configuration from /opt/lsf/conf/lsf.conf Aug 3 13:45:27 2017 20884 6 3.6.0 Lim starting... Aug 3 13:45:27 2017 20884 6 3.6.0 LIM is running in advanced workload execution mode. Aug 3 13:45:27 2017 20884 6 3.6.0 Master LIM is not running in EGO_DISABLE_UNRESOLVABLE_HOST mode. Aug 3 13:45:27 2017 20884 5 3.6.0 /opt/lsf/10.1/linux2.6-glibc2.3-x86_64/etc/lim -C Aug 3 13:45:27 2017 20884 7 3.6.0 Could not construct product entitlement version array Aug 3 13:45:27 2017 20884 Last message repeated 1 time(s). Aug 3 13:45:27 2017 20884 6 3.6.0 initEntitlement: EGO_AUDIT_MAX_SIZE was not set. Default value will be used. Aug 3 13:45:27 2017 20884 6 3.6.0 initEntitlement: EGO_AUDIT_MAX_ROTATE was not set. Default value will be used. Aug 3 13:45:27 2017 20884 6 3.6.0 LIM is running as IBM Spectrum LSF Standard Edition. Aug 3 13:45:27 2017 20884 6 3.6.0 reCheckClass: numhosts 1 so reset exchIntvl to 15.00 Aug 3 13:45:27 2017 20884 6 3.6.0 Checking Done. --------------------------------------------------------- No errors found. 参阅 Troubleshooting LSF problems 或者 LSF Command Reference 以获取一些常见配置错误的帮助。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:32:09 "},"chapter4/section2/subsection2/Check cluster status.html":{"url":"chapter4/section2/subsection2/Check cluster status.html","title":"检查集群状态","keywords":"","body":"检查集群状态 lsid 命令告诉您是否正确设置了 LSF 环境。 lsload 命令显示集群的当前负载级别。 lsid 命令 lsid 命令显示集群的当前 LSF 版本号，集群名称和当前 LSF 主主机的主机名。 lsid 命令显示的 LSF 主名称可以有所不同，但通常是 LSF_CONFDIR/lsf.cluster.cluster_name 文件的 Hosts 部分中配置的第一台主机。 % lsid IBM Spectrum LSF Standard 10.1.0.0, Apr 04 2016 Copyright International Business Machines Corp, 1992-2016. US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. My cluster name is cluster1 My master name is hosta 如果看到如下消息 Cannot open lsf.conf file LSF_ENVDIR 环境变量可能未正确设置。 使用 cshrc.lsf 或 profile.lsf 文件来设置您的环境。 有关更多帮助，请参见 Troubleshooting LSF problems 来寻求帮助。 lsload 命令 lsload命令的输出为集群中的每个主机包含一行。 集群中所有主机的正常状态是 ok。 % lsload HOST_NAME status r15s r1m r15m ut pg ls it tmp swp mem hosta ok 0.0 0.0 0.1 1% 0.0 1 224 43G 67G 3G hostc -ok 0.0 0.0 0.0 3% 0.0 3 0 38G 40G 7G hostf busy *6.2 6.9 9.5 85% 1.1 30 0 5G 400G 385G hosth busy 0.1 0.1 0.3 7% *17 6 0 9G 23G 28G hostv unavail 对于任何负载指数超过其配置阈值的主机，将显示繁忙状态。 星号（*）标记了超出其阈值的负载索引，从而导致主机状态为繁忙。 值 o k前面的减号（-）表示 res 未在该主机上运行。 如果在启动或重新配置 LSF 之后看到以下消息之一，请等待几秒钟，然后再次尝试 lsload 命令，以使所有主机上的 lim 守护程序有时间初始化。 lsid: getentitlementinfo() failed: LIM is down; try later 或者 LSF daemon (LIM) not responding ... still trying 如果问题仍然存在，请参阅 Troubleshooting LSF problems 。 其他有用的命令 bparams 命令显示有关 LSF 批处理系统配置参数的信息。 bhist 命令显示有关作业的历史信息。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:41:23 "},"chapter4/section2/subsection2/Check LSF batch system configuration.html":{"url":"chapter4/section2/subsection2/Check LSF batch system configuration.html","title":"检查LSF批处理系统配置","keywords":"","body":"检查 LSF 批处理系统配置 badmin 命令控制和监视 LSF 批处理工作负载系统的操作。 使用 badmin ckconfig 命令检查 LSF 批处理系统配置文件。 -v 选项显示有关配置的详细信息： 以下输出中的消息是 badmin ckconfig -v 的典型消息。 其他消息可能表明您的 LSF 批处理工作负载系统配置存在问题。 % badmin ckconfig -v Checking configuration files ... Dec 20 12:22:55 2015 20246 9 9.1.3 minit: Trying to call LIM to get cluster name ... Dec 20 12:22:55 2015 20246 9 9.1.3 Batch is enabled Dec 20 12:22:55 2015 4433 9 9.1.3 Checking Done --------------------------------------------------------- No errors found. 请参阅 Troubleshooting LSF problems 或者 LSF Command Reference 以获取一些常见配置错误的帮助。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:43:41 "},"chapter4/section2/subsection2/Find out batch system status.html":{"url":"chapter4/section2/subsection2/Find out batch system status.html","title":"找出批处理系统状态","keywords":"","body":"查看批处理系统状态 使用 bhosts 命令查看 LSF 批处理作业负载系统是否正常运行。 bqueues 命令显示可用队列的状态及其配置参数。 要使用 LSF 批处理命令，集群必须已启动并正在运行。 有关启动 LSF 守护程序的信息，请参见 Starting your cluster 。 bhosts 命令 bhosts 命令显示集群中 LSF 批处理服务器主机的状态，以及有关批处理主机的其他详细信息： 单个用户允许的最大作业槽位数 系统中的作业总数，正在运行的作业，用户暂停的作业以及系统暂停的作业 预留作业槽位总数 集群中所有主机的正常状态都显示正常。 % bhosts HOST_NAME STATUS JL/U MAX NJOBS RUN SSUSP USUSP RSV hosta ok - - 0 0 0 0 0 hostb ok - - 0 0 0 0 0 hostc ok - - 0 0 0 0 0 hostd ok - - 0 0 0 0 0 如果在启动或重新配置 LSF 时看到以下消息，请等待几秒钟，然后再次尝试 bhosts 命令，以使 mbatchd 守护程序有时间进行初始化。 batch system daemon not responding ... still trying 如果问题仍然存在，请参阅 Solving common LSF problems 以寻求帮助。 bqueues 命令 LS F队列组织具有不同优先级，和不同调度策略的作业。 bqueues 命令显示可用队列的状态及其配置参数。 要使队列接受和调度作业，状态必须为 Open:Active。 % bqueues QUEUE_NAME PRIO STATUS MAX JL/U JL/P JL/H NJOBS PEND RUN SUSP owners 43 Open:Active - - - - 0 0 0 0 priority 43 Open:Active - - - - 0 0 0 0 night 40 Open:Inact - - - - 0 0 0 0 chkpnt_rerun_qu 40 Open:Active - - - - 0 0 0 0 short 35 Open:Active - - - - 0 0 0 0 license 33 Open:Active - - - - 0 0 0 0 normal 30 Open:Active - - - - 0 0 0 0 idle 20 Open:Active - - - - 0 0 0 0 要查看更多详细的队列信息，请使用 bqueues -l 命令： % bqueues -l normal QUEUE: normal -- For normal low priority jobs, running only if hosts are lightly loaded. This is the default queue. PARAMETERS/STATISTICS PRIO NICE STATUS MAX JL/U JL/P JL/H NJOBS PEND RUN SSUSP USUSP RSV 30 20 Open:Active - - - - 0 0 0 0 0 0 Interval for a host to accept two jobs is 0 seconds SCHEDULING PARAMETERS r15s r1m r15m ut pg io ls it tmp swp mem loadSched - - - - - - - - - - - loadStop - - - - - - - - - - - SCHEDULING POLICIES: FAIRSHARE NO_INTERACTIVE USER_SHARES: [default, 1] USERS: all HOSTS: all bqueues -l 命令显示有关队列的以下信息： 什么类型的作业要在队列上运行 资源使用限制 能够使用队列的主机和用户 调度阈值： loadSched 是 LSF 停止自动分派作业的阈值 loadStop 是 LSF 自动挂起作业的阈值 其他有用的命令 bparams 命令显示有关 LSF 批处理系统配置参数的信息。 bhist 命令显示有关作业的历史信息。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:55:18 "},"chapter4/section2/subsection3/run_jobs.html":{"url":"chapter4/section2/subsection3/run_jobs.html","title":"运行作业","keywords":"","body":"运行作业 Use the bsub and lsrun commands to run jobs through LSF. Use the bjobs command to see the status of your jobs. Control job execution with the bstop, bresume, and bkill commands. Run LSF jobs with bsub and lsrun Use two basic commands to run jobs through LSF: bsub submits jobs to the LSF batch scheduler. LSF schedules and dispatches jobs to the best available host based on the scheduling policies you configure in your LSF queues. The lsrun command runs an interactive task on the best available host, based on current system load information gathered by the lim daemon. For most jobs, all you need to do is add either the lsrun or bsub command in front of the job commands you normally use. You usually don't need to modify your executable applications or execution scripts. Submit batch jobs with bsub The bsub command submits jobs to LSF batch scheduling queues. Display job status with bjobs Use the bjobs command to see the job ID and other information about your jobs. Control job execution with bstop, bresume, and bkill Use LSF commands to suspend (bstop), resume (bresume), and kill (bkill) jobs. Run interactive tasks with lsrun and lsgrun The lsrun command runs a task on either the current local host or remotely on the best available host, provided it can find the necessary resources and the appropriate host type. The lsgrun command is similar to lsrun, but it runs a task on a group of hosts. Integrate your applications with LSF By integrating your applications with LSF, you can make sure that your users can submit and run their jobs with correct and complete job submission options without making them learn LSF commands. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:05:46 "},"chapter4/section2/subsection3/Submit batch jobs.html":{"url":"chapter4/section2/subsection3/Submit batch jobs.html","title":"提交批处理作业","keywords":"","body":"Submit batch jobs The bsub command submits jobs to LSF batch scheduling queues. The following command submits a sleep job to the default queue (normal): % bsub sleep 60 Job is submitted to default queue . When a job is submitted to LSF, it is assigned a unique job ID, in this case 3616. You can specify a wide range of job options on the bsub command. For example, you can specify a queue, and the job command sleep 60 is the last option: % bsub -q short sleep 60 Job is submitted to queue . What LSF does with job output By default, when the job is finished, LSF sends email with a job report and any output and error messages to the user account from which the job was submitted. You can optionally save standard output and standard error to files with the -o and -e options. The following command appends the standard output and standard error of the job to the files output.3640 and errors.3640 in the jobs subdirectory of the home directory of user1. % bsub -q short -o /home/user1/job/output.%J -e /home/user1/job/errors.%J ls -l Job is submitted to queue . The %J variable is replaced by the job ID when the files are created. Using %J helps you find job output when you run a lot of jobs. Interactive batch jobs with bsub -I To submit an interactive job through LSF, use the -I option: The following command submits a batch interactive job that displays the output of the ls command: % bsub -I ls To submit a batch interactive job by using a pseudo-terminal, use the bsub -Ip option. To submit a batch interactive job and create a pseudo-terminal with shell mode support, use the bsub -Is option. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:31:55 "},"chapter4/section2/subsection3/Display job status.html":{"url":"chapter4/section2/subsection3/Display job status.html","title":"显示作业状态","keywords":"","body":"Display job status Use the bjobs command to see the job ID and other information about your jobs. The status of each LSF job is updated periodically. % bjobs JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME 1266 user1 RUN normal hosta hostb sleep 60 Jun 5 17:39:58 The job that is named sleep 60 runs for 60 seconds. When the job completes, LSF sends email to report the job completion. You can use the job ID to monitor the status of a specific job. If all hosts are busy, the job is not started immediately and the STAT column says PEND. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:32:05 "},"chapter4/section2/subsection3/Control job execution.html":{"url":"chapter4/section2/subsection3/Control job execution.html","title":"控制作业执行","keywords":"","body":"Control job execution Use LSF commands to suspend (bstop), resume (bresume), and kill (bkill) jobs. bstop command To suspend a running job, use the bstop command and specify the job ID: % bstop 1266 Job is being stopped If the job was running when it was stopped, the bjobs command shows USUSP status for job 1266: % bjobs JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME 1266 user1 USUSP normal hosta hostb sleep 60 Jun 5 17:39:58 Job owners can suspend only their own jobs. LSF administrators can suspend any job. bresume command To resume a suspended job, use the bresume command. % bresume 1266 Job is being resumed If the job resumes immediately, the bjobs command shows RUN status for job 1266: % bjobs JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME 1266 user1 RUN normal hosta hostb sleep 60 Jun 5 17:39:58 Job owners can resume only their own jobs. LSF administrators can resume any job. bkill command To kill a job, use the bkill command, which sends a signal to the specified jobs. For example, if the job owner or the LSF administrator runs the following command, job 1266 is killed: % bkill 1266 Job is being terminated © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-16 20:57:04 "},"chapter4/section2/subsection3/Run interactive tasks.html":{"url":"chapter4/section2/subsection3/Run interactive tasks.html","title":"运行交互式任务","keywords":"","body":"Run interactive tasks The lsrun command runs a task on either the current local host or remotely on the best available host, provided it can find the necessary resources and the appropriate host type. The lsgrun command is similar to lsrun, but it runs a task on a group of hosts. The following command runs the ls command. In this case, the command ran through LSF on the local host: % lsrun ls -l /usr/share/lsf/cluster1/conf/ total 742 -rw-r--r-- 1 root lsf 11372 Jul 16 16:23 cshrc.lsf -rw-r--r-- 1 root lsf 365 Oct 25 10:55 hosts drwxr-xr-x 3 lsfadmin lsf 512 Jul 16 15:53 lsbatch -rw-r--r-- 1 lsfadmin lsf 1776 Nov 23 15:13 lsf.conf -rw-r--r-- 1 lsfadmin lsf 8453 Nov 16 17:46 lsf.shared -rw-r--r-- 1 lsfadmin lsf 578 Jul 16 15:53 lsf.task -rw-r--r-- 1 root lsf 10485 Jul 16 17:08 profile.lsf You can also specify a host where you want to run a command. For example, the following command runs the hostname command on the remote host hosta: % lsrun -v -m hosta hostname > hosta The following command runs the hostname command on three remote hosts: % lsgrun -v -m \"hosta hostb hostc\" hostname > hosta > hostb > hostc © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:32:30 "},"chapter4/section2/subsection3/Integrate your applications with LSF.html":{"url":"chapter4/section2/subsection3/Integrate your applications with LSF.html","title":"将应用程序与 LSF 集成","keywords":"","body":"Integrate your applications with LSF By integrating your applications with LSF, you can make sure that your users can submit and run their jobs with correct and complete job submission options without making them learn LSF commands. Integrate applications with LSF three ways: Wrapper shell scripts Wrapper binary executables Modifying existing application source code and interfaces Wrapper shell scripts The easiest integration method is to put the bsub command into an executable file like a shell script. A wrapper script is an executable file for launching your application through LSF. It gives users a simple interface to run their jobs that is easy to deploy and maintain. For example, if your application is called abc, rename abc to abc_real and create a wrapper script that is called abc: #! /bin/sh bsub -R \"rusage[abc_license=1:duration=1]\" abc_real When users run abc, they are actually running a script to submit a job abc_real to LSF that uses 1 shared resource named abc_license. For more information about specifying shared resources by using the resource requirement (rusage) string on the -R option of the bsub command, see Manage software licenses and other shared resources. By adding appropriate options to the script, you can enhance your integration: Requeue jobs based on license availability Copy input and output files to and from the local directory on the execution host Calculate and estimate resource requirements Wrapper binary programs A wrapper binary is similar to a wrapper shell script in the form of a compiled binary executable. Compiled wrapper files usually run faster and more efficiently than shell scripts, and they also have access to the LSF API (LSLIB and LSBLIB). Binary code is also more secure because users cannot modify it without the source code and appropriate libraries, but it is more time consuming to develop wrapper binary programs than wrapper shell scripts. Modifying existing application source code and interfaces LSF is already integrated closely with many commonly used software products. IBM and other software application vendors provide facilities and services for closer integration of LSF and other applications. By modifying existing application user interfaces, you can enable easy job submission, license maximization, parallel execution, and other advanced LSF features. In some cases, you are able to run an LSF job directly from the application user interface. Where to go next Learn more about administering your cluster, described in Manage users, hosts, and queues. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:32:42 "},"chapter4/section2/subsection4/manage_users_hosts_and_queues.html":{"url":"chapter4/section2/subsection4/manage_users_hosts_and_queues.html","title":"管理用户、节点与队列","keywords":"","body":"管理用户、节点与队列 Make your cluster available to users with cshrc.lsf and profile.lsf. Add or remove hosts and queues from your cluster. Making your cluster available to users with cshrc.lsf and profile.lsf Make sure that all LSF users include either the cshrc.lsf or profile.lsf file at the end of their own .cshrc or .profile file, or run one of these two files before you use LSF. Adding a host to your cluster Use the LSF installation script lsfinstall to add new hosts and host types to your cluster. Removing a host from your cluster Removing a host from LSF involves closing a host to prevent any additional jobs from running on the host and removing references to the host from the lsf.cluster.cluster_name file and other configuration files. Adding a queue Edit the lsb.queues file to add the new queue definition. Adding a queue does not affect pending or running jobs. Removing a queue Edit lsb.queues to remove a queue definition. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:05:10 "},"chapter4/section2/subsection4/Making your cluster available to users.html":{"url":"chapter4/section2/subsection4/Making your cluster available to users.html","title":"使您的集群可供用户使用","keywords":"","body":"Making your cluster available to users Make sure that all LSF users include either the cshrc.lsf or profile.lsf file at the end of their own .cshrc or .profile file, or run one of these two files before you use LSF. About this task To set up the LSF environment for your users, use the following two shell files: LSF_CONFDIR/cshrc.lsf Use this file for csh or tcsh shell. LSF_CONFDIR/profile.lsf Use this file for sh, ksh, or bash shell. Procedure For csh or tcsh shell: Add the cshrc.lsf file to the end of the .cshrc file for all users: Copy the contents of the cshrc.lsf file into the .cshrc file. Add a line with the source command to the end of the .cshrc file: For example, if your the LSF_TOP directory for your cluster is /usr/share/lsf/conf, add the following line to the .cshrc file: source /usr/share/lsf/conf/cshrc.lsf For sh, ksh, or bash shell: Add the profile.lsf file to the end of the .profile file for all users: Copy the contents of the profile.lsf file into the .profile file. For example, if your the LSF_TOP directory for your cluster is /usr/share/lsf/conf , add a line similar to the following to the end of the .profile file: . /usr/share/lsf/conf/profile.lsf © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter4/section2/subsection4/Adding a host to your cluster.html":{"url":"chapter4/section2/subsection4/Adding a host to your cluster.html","title":"将主机节点添加到集群","keywords":"","body":"Adding a host to your cluster Use the LSF installation script lsfinstall to add new hosts and host types to your cluster. Before you begin Make sure that you have the LSF distribution files for the host types you want to add. For example, to add a Linux system that runs x86-64 Kernel 2.6 and 3.x to your cluster, get the file lsf10.1_linux2.6-glibc2.3-x86_64.tar.Z. Distribution packages for all supported LSF releases are available for download through IBM Passport Advantage. See LSF System Requirements on IBM developerWorks for a complete list of supported operating systems. The following videos provide more help about downloading LSF through IBM Passport Advantage: YouTube IBM Education Assistant About this task Adding a host to your cluster has the following major steps: Install LSF binary files for the host type. Add host information to the lsf.cluster.cluster_name file. Set up the new host. Procedure Install the binary files for a new host type. Use the lsfinstall command to add new host types to your cluster. If you already have the distribution files for the host types you want to add, you can skip these steps. Log on as root to any host that can access the LSF installation script directory. Change to the installation script directory. # cd /usr/share/lsf/cluster1/10.1/install Edit the install.config file to specify the options you want for new host types. For more information about the install.config file, see the IBM Spectrum LSF Configuration Reference. For information about the lsfinstall command, see Installing IBM Spectrum LSF on UNIX and Linux and the IBM Spectrum LSF Command Reference. Run the ./lsfinstall -f install.config command. Follow the steps for host setup in After Installing LSF in Installing IBM Spectrum LSF on UNIX and Linux (or in the lsf_getting_started.html file that is generated by the lsfinstall script) to set up the new hosts. Add host information to the lsf.cluster.cluster_name file. Log on to the LSF master host as the primary LSF administrator. Edit the LSF_CONFDIR/lsf.cluster.cluster_name file, and add host information for the new host to the Host section. Add the name of the host. Add model or type. If you enter the ! keyword in the model and type columns, the host model is automatically detected by lim running on the host. You might want to use the default values for that host type now, and change them later on when you have more experience or more information. Specify LSF server or client in the server column: 1 (one) indicates an LSF server host. 0 (zero) indicates an LSF client-only host. By default, all hosts are considered LSF server hosts. HOSTNAME model type server r1m mem RESOURCES REXPRI hosta ! SUNSOL 1 1.0 4 () 0 hostb ! LINUX 0 1.0 4 () 0 hostc ! HPPA 1 1.0 4 () 0 End Host Save the changes to LSF_CONFDIR/lsf.cluster.cluster_name. Reconfigure lim to enable the new host in the cluster. % lsadmin reconfig Checking configuration files ... No errors found. Do you really want to restart LIMs on all hosts? [y/n] y Restart LIM on ...... done Restart LIM on ...... done Restart LIM on ...... done The lsadmin reconfig command checks for configuration errors. If no unrecoverable errors are found, you are asked to confirm that you want to restart lim on all hosts and lim is reconfigured. If unrecoverable errors are found, reconfiguration exits. Reconfigure mbatchd. % badmin reconfig Checking configuration files ... No errors found. Do you want to reconfigure? [y/n] y Reconfiguration initiated The badmin reconfig command checks for configuration errors. If no unrecoverable errors are found, you are asked to confirm reconfiguration. If unrecoverable errors are found, reconfiguration exits. (Optional) Use the hostsetup command to set up the new host. Log on as root to any host that can access the LSF installation script directory. Change to the installation script directory. # cd /usr/share/lsf/cluster1/10.1/install Run the hostsetup command to set up the new host. # ./hostsetup --top=\"/usr/share/lsf/lsf_62\" --boot=\"y\" For information about the hostsetup command, see Installing IBM Spectrum LSF on UNIX and Linux and the IBM Spectrum LSF Command Reference. Start LSF on the new host. Run the following commands: # lsadmin limstartup # lsadmin resstartup # badmin hstartup Run the bhosts and lshosts commands to verify your changes. If any host type or host model is UNKNOWN or DEFAULT, see Working with hosts in IBM Spectrum LSF Cluster Management and Operations to fix the problem. Results Use dynamic host configuration to add hosts to the cluster without manually changing the LSF configuration. For more information about adding hosts dynamically, see IBM Spectrum LSF Cluster Management and Operations. If you get errors, see Troubleshooting LSF problems for help with some common configuration errors. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter4/section2/subsection4/Removing a host from your cluster.html":{"url":"chapter4/section2/subsection4/Removing a host from your cluster.html","title":"从集群中移除主机节点","keywords":"","body":"Removing a host from your cluster Removing a host from LSF involves closing a host to prevent any additional jobs from running on the host and removing references to the host from the lsf.cluster.cluster_name file and other configuration files. About this task CAUTION Never remove the master host from LSF. If you want to change your current default master host, change the lsf.cluster.cluster_name file to assign a different default master host. Then remove the host that was formerly the master host. Procedure Log on to the LSF host as root. Run badmin hclose to close the host. Closing the host prevents jobs from being dispatched to the host and allows running jobs to finish. Stop all running daemons manually. Remove any references to the host in the Host section of the LSF_CONFDIR/lsf.cluster.cluster_name file. Remove any other references to the host, if applicable, from the following configuration files: LSF_CONFDIR/lsf.shared LSB_CONFDIR/cluster_name/configdir/lsb.hosts LSB_CONFDIR/cluster_name/configdir/lsb.queues LSB_CONFDIR/cluster_name/configdir/lsb.resources Log off the host to be removed, and log on as root or the primary LSF administrator to any other host in the cluster. Run the lsadmin reconfig command to reconfigure LIM. % lsadmin reconfig Checking configuration files ... No errors found. Do you really want to restart LIMs on all hosts? [y/n] y Restart LIM on ...... done Restart LIM on ...... done The lsadmin reconfig command checks for configuration errors. If no errors are found, you are asked to confirm that you want to restart lim on all hosts and lim is reconfigured. If unrecoverable errors are found, reconfiguration exits. Run the badmin mbdrestart command to restart mbatchd. % badmin reconfig Checking configuration files ... No errors found. Do you want to reconfigure? [y/n] y Reconfiguration initiated The badmin mbdrestart command checks for configuration errors. If no unrecoverable errors are found, you are asked to confirm reconfiguration. If unrecoverable errors are found, reconfiguration exits. If you configured LSF daemons to start automatically at system startup, remove the LSF section from the host’s system startup files. For more information about automatic LSF daemon startup, see Setting up automatic LSF startup If any users of the host use the lstcsh shell as their login shell, change their login shell to tcsh or csh. Remove lstcsh from the /etc/shells file. Results Use dynamic host configuration to remove hosts to the cluster without manually changing the LSF configuration. For more information about removing hosts dynamically, see IBM Platform LSF Cluster Management and Operations. If you get errors, see ../lsf_admin/chap_troubleshooting_lsf.html#v3523448 for help with some common configuration errors. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:34:14 "},"chapter4/section2/subsection4/Adding a queue.html":{"url":"chapter4/section2/subsection4/Adding a queue.html","title":"添加队列","keywords":"","body":"Adding a queue Edit the lsb.queues file to add the new queue definition. Adding a queue does not affect pending or running jobs. Procedure Log in as the administrator on any host in the cluster. Edit the LSB_CONFDIR/cluster_name/configdir/lsb.queues file to add the new queue definition. You can copy another queue definition from this file as a starting point. Remember to change the QUEUE_NAME parameter of the copied queue. Save the changes to the lsb.queues file. When the configuration files are ready, run the badmin ckconfig command to check the new queue definition. If any errors are reported, fix the problem and check the configuration again. Run the badmin reconfig command to reconfigure the cluster. % badmin reconfig Checking configuration files ... No errors found. Do you want to reconfigure? [y/n] y Reconfiguration initiated The badmin reconfig command also checks for configuration errors. If no unrecoverable errors are found, you are asked to confirm reconfiguration. If unrecoverable errors are found, reconfiguration exits. Results If you get errors, see Troubleshooting LSF problems for help with some common configuration errors. For more information about the lsb.queues file, see the Configuration Reference. For more information about the badmin reconfig command, see the Command Reference. Example Begin Queue QUEUE_NAME = normal PRIORITY = 30 STACKLIMIT= 2048 DESCRIPTION = For normal low priority jobs, running only if hosts are lightly loaded. QJOB_LIMIT = 60 # job limit of the queue PJOB_LIMIT = 2 # job limit per processor ut = 0.2 io = 50/240 USERS = all HOSTS = all NICE = 20 End Queue © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:34:28 "},"chapter4/section2/subsection4/Removing a queue.html":{"url":"chapter4/section2/subsection4/Removing a queue.html","title":"移除队列","keywords":"","body":"Removing a queue Edit lsb.queues to remove a queue definition. Before you begin Important Before you remove a queue, make sure that no jobs are running in the queue. Use the bqueues command to view a list of existing queues and the jobs that are running in those queues. If jobs are in the queue that you want to remove, you must switch pending and running jobs to another queue, then remove the queue. If you remove a queue that has pending jobs in it, the jobs are temporarily moved to a lost_and_found queue. The job state does not change. Running jobs continue, and jobs that are pending in the original queue are pending in the lost_and_found queue. Jobs remain pending until the user or the queue administrator uses the bswitch command to switch the jobs into a regular queue. Jobs in other queues are not affected. Procedure Log in as the primary administrator on any host in the cluster. Close the queue to prevent any new jobs from being submitted. badmin qclose night Queue night is closed Switch all pending and running jobs into another queue. For example, the bswitch -q night idle 0 command chooses jobs from the night queue to the idle queue. The job ID number 0 switches all jobs. bjobs -u all -q night JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME 5308 user5 RUN night hostA hostD job5 Nov 21 18:16 5310 user5 PEND night hostA hostC job10 Nov 21 18:17 bswitch -q night idle 0 Job is switched to queue Job is switched to queue Edit the LSB_CONFDIR/cluster_name/configdir/lsb.queues file and remove or comment out the definition for the queue that you want to remove. Save the changes to the lsb.queues file. Run the badmin reconfig command to reconfigure the cluster. % badmin reconfig Checking configuration files ... No errors found. Do you want to reconfigure? [y/n] y Reconfiguration initiated The badmin reconfig command checks for configuration errors. If no unrecoverable errors are found, you are asked to confirm reconfiguration. If unrecoverable errors are found, reconfiguration exits. Results If you get errors, see Troubleshooting LSF problems for help with some common configuration errors. For more information about the lsb.queues file, see the Configuration Reference. For more information about the badmin reconfig command, see the Command Reference. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:34:41 "},"chapter4/section2/subsection5/configure_LSF_startup.html":{"url":"chapter4/section2/subsection5/configure_LSF_startup.html","title":"配置 LSF 启动","keywords":"","body":"配置 LSF 启动 Use the lsf.sudoers file so that LSF administrators can start and stop LSF daemons. Set up LSF to start automatically. Allowing LSF administrators to start LSF daemons with lsf.sudoers To allow LSF administrators to start and stop LSF daemons, configure the /etc/lsf.sudoers file. If the lsf.sudoers file does not exist, only root can start and stop LSF daemons. Setting up automatic LSF startup Configure LSF daemons to start automatically on every LSF server host in the cluster. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:04:34 "},"chapter4/section2/subsection5/Allowing LSF administrators to start LSF daemons.html":{"url":"chapter4/section2/subsection5/Allowing LSF administrators to start LSF daemons.html","title":"允许 LSF 管理员启动 LSF 守护程序","keywords":"","body":"Allowing LSF administrators to start LSF daemons To allow LSF administrators to start and stop LSF daemons, configure the /etc/lsf.sudoers file. If the lsf.sudoers file does not exist, only root can start and stop LSF daemons. About this task Using the lsf.sudoers file requires you to enable the setuid bit. Since this allows LSF administration commands to run with root privileges, do not proceed if you do not want these commands to run with root privileges. Procedure Log on as root to each LSF server host. Start with the LSF master host, and repeat these steps on all LSF hosts. Create an /etc/lsf.sudoers file on each LSF host and specify the LSF_STARTUP_USERS and LSF_STARTUP_PATH parameters. LSF_STARTUP_USERS=\"lsfadmin user1\" LSF_STARTUP_PATH=/usr/share/lsf/cluster1/10.1/sparc-sol2/etc LSF_STARTUP_PATH is normally the path to the LSF_SERVERDIR directory, where the LSF server binary files (lim, res, sbatchd, mbatchd, mbschd, and so on) are installed, as defined in your LSF_CONFDIR/lsf.conf file. The lsf.sudoers file must have file permission mode -rw------- (600) and be readable and writable only by root: # ls -la /etc/lsf.sudoers -rw------- 1 root lsf 95 Nov 22 13:57 lsf.sudoers Run the lsfrestart command to restart the cluster: # lsfrestart © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-06 21:35:19 "},"chapter4/section2/subsection5/Setting up automatic LSF startup.html":{"url":"chapter4/section2/subsection5/Setting up automatic LSF startup.html","title":"设置 LSF 自动启动","keywords":"","body":"Setting up automatic LSF startup Configure LSF daemons to start automatically on every LSF server host in the cluster. Procedure Use the boot=y option of the hostsetup command. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter4/section2/subsection6/manage_software_licenses_and_other_resources.html":{"url":"chapter4/section2/subsection6/manage_software_licenses_and_other_resources.html","title":"管理软件许可证及其他共享资源","keywords":"","body":"管理软件许可证及其他共享资源 设置LSF外部LIM（ELIM），以将软件许可证，作为动态共享资源进行监视。 How LSF uses dynamic shared resources LSF recognizes two main types of resources: Host-based resources are available on all hosts in the cluster, for example, host type and model, or nodelocked software licenses. Shared resources are managed as dynamic load indexes available for a group of hosts in the cluster, for example, networked floating software licenses, shared file systems. Shared resources are shared by a group of LSF hosts. LSF manages shared resources for host selection and batch or interactive job execution. These resources are dynamic resources because the load on the system changes with the availability of the resources. Software licenses as shared resources The most common application of shared resources is to manage software application licenses. You submit jobs that require those licenses and LSF runs the jobs according to their priorities when licenses are available. When licenses are not available, LSF queues the jobs then dispatches them when licenses are free. Configuring application licenses as shared resources ensures optimal use of costly and critical resources. Define dynamic shared resources in an ELIM For LSF to use a shared resource like a software license, you must define the resource in the Resource section of the lsf.shared file. You define the type of resource and how often you want LSF to refresh the value of the resource. For LSF to track the resources correctly over time, you must define them as external load indexes. LSF updates load indexes periodically with a program called an External Load Information Manager (ELIM). An ELIM can be a shell script or a compiled binary program, which returns the values of the shared resources you define. The ELIM must be named elim and located in the LSF_SERVERDIR directory: /usr/share/lsf/lsf/cluser1/10.1/sparc-sol2/etc/elim You can find examples of sample ELIMs in the misc/examples directory. Example of shared licenses In the lsf.shared file, define two dynamic shared resources for software licenses, named license1 and license2: Begin Resource RESOURCENAME TYPE INTERVAL INCREASING RELEASE DESCRIPTION # Keywords license1 Numeric 30 N Y (license1 resource) license2 Numeric 30 N Y (license2 resource) End Resource The TYPE parameter for a shared resource can be one of the following types: Numeric Boolean String In this case, the resource is Numeric. The INTERVAL parameter specifies how often you want the value to be refreshed. In this example, the ELIM updates the value of the shared resources license1 and license2 every 30 seconds. The N in the INCREASING column means that the license resources are decreasing; that is, as more licenses become available, the load becomes lower. The Y in the RELEASE column means that the license resources are released when a job that uses the license is suspended. Map dynamic shared resources to hosts To make LSF aware of where the defined dynamic shared resources license1 and license2 you defined, map them to the hosts where they are located. In the LSF_CONFDIR/lsf.cluster.cluster_name file, configure a ResourceMap section to specify the mapping between shared resources license1 and license2 you defined in the LSF_CONFDIR/lsf.shared file, and the hosts you want to map them to: Begin ResourceMap RESOURCENAME LOCATION license1 [all] license1 [all] End ResourceMap In this resource map, the [all] attribute under the LOCATION parameter means that resources license1 and license2 under the RESOURCENAME parameter are available on all hosts in the cluster. Only one ELIM needs to run on the master host because the two resources are the same for all hosts. If the location of the resources is different on different hosts, a different ELIM must run on every host. Monitor dynamic shared resources For LSF to receive external load indexes correctly, the ELIM must send a count of the available resources to standard output in the following format: number_indexes [index_name index_value] ... The fields in this example contain the following information: 2 license1 3 license2 2 The total number of external load indexes (2) The name of the first external load index (license1) The value of the first load index (3) The name of the second external load index (license2) The value of the second load index (2) Write the ELIM program The ELIM must be an executable program, named elim, located in the LSF_SERVERDIR directory. When the lim daemon is started or restarted, it runs the elim program on the same host and takes the standard output of the external load indexes that are sent by the elim program. In general, you can define any quantifiable resource as an external load index, write an ELIM to report its value, and use it as an LSF resource. The following example ELIM program uses license1 and license2 and assumes that the FLEXlm license server controls them: #!/bin/sh NUMLIC=2 # number of dynamic shared resources while true do TMPLICS='/usr/share/lsf/cluster1/10.1/sparc-sol2/etc/lic -c /usr/share/lsf/cluster1/conf/license.dat -f license1, license2' LICS='echo $TMPLICS | sed -e s/-/_/g' echo $NUMLIC $LICS # $NUMLIC is number of dynamic shared resource sleep 30 # Resource done In the script, the sed command changes the minus sign (-) to underscore (_) in the license feature names because LSF uses the minus sign for calculation, and it is not allowed in resource names. The lic utility is available from IBM Support. You can also use the FLEXlm command lmstat to make your own ELIM. Use the dynamic shared resources To enable the new shared resources in your cluster, restart LSF with the following commands: lsadmin reconfig badmin reconfig If no errors are found, use the lsload -l command to verify the value of your dynamic shared resources: HOST_NAME status r15s r1m r15m ut pg io ls it tmp swp mem license1 license2 hosta ok 0.1 0.3 0.4 8% 0.2 50 73 0 62M 700M 425M 3 0 hostb ok 0.1 0.1 0.4 4% 5.7 3 3 0 79M 204M 64M 3 0 Submit jobs that use shared resources To submit a batch job that uses one license1 resource, use the command following command: % bsub -R 'rusage[license1=1:duration=1]' myjob In the resource requirement (rusage) string, duration=1 means that license1 is reserved for 1 minute to give LSF time to check it out from FLEXlm. You can also specify the resource requirement string at queue level, in the RES_REQ parameter for the queue. In the LSB_CONFDIR/cluster_name/configdir/lsb.queues file, specify the following resource requirement string: Begin Queue QUEUE_NAME = license1 RES_REQ=rusage[license1=1:duration=1] ... End Queue Then, submit a batch job that uses one license1 resource by using the following command: % bsub -q license1 myjob When licenses are available, LSF runs your jobs right away; when all licenses are in use, LSF puts your job in a queue and dispatches them as licenses become available. This way, all of your licenses are used to the best advantage. For more information For more information about the lsf.shared and lsf.cluster.cluster_name files and the parameters for configuring shared resources, see the Configuration Reference. For more information about adding external resources to your cluster and configuring an ELIM to customize resources, see External load indices in Administering IBM Spectrum LSF. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:57:34 "},"chapter4/section3/troubleshooting_LSF_problems.html":{"url":"chapter4/section3/troubleshooting_LSF_problems.html","title":"4.3 LSF 排错","keywords":"","body":"4.3 LSF 排错 Troubleshoot common LSF problems and understand LSF error messages. If you cannot find a solution to your problem here, contact IBM Support. Solving common LSF problems Most problems are due to incorrect installation or configuration. Before you start to troubleshoot LSF problems, always check the error log files first. Log messages often point directly to the problem. LSF error messages The following error messages are logged by the LSF daemons, or displayed by the lsadmin ckconfig and badmin ckconfig commands. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-14 09:25:45 "},"chapter4/section3/solving_common_LSF_problems.html":{"url":"chapter4/section3/solving_common_LSF_problems.html","title":"常见 LSF 问题","keywords":"","body":"常见 LSF 问题 Most problems are due to incorrect installation or configuration. Before you start to troubleshoot LSF problems, always check the error log files first. Log messages often point directly to the problem. Finding LSF error logs When something goes wrong, LSF server daemons log error messages in the LSF log directory (specified by the LSF_LOGDIR parameter in the lsf.conf file). Procedure Make sure that the primary LSF administrator owns LSF_LOGDIR, and that root can write to this directory. If an LSF server is unable to write to LSF_LOGDIR, then the error logs are created in /tmp. LSF logs errors to the following files: lim.log.host_name res.log.host_name pim.log.host_name mbatchd.log.master_host mbschd.log.master_host sbatchd.log.host_name vemkd.log.master_host If these log files contain any error messages that you do not understand, contact IBM Support. Diagnosing and fixing most LSF problems General troubleshooting steps for most LSF problems. Procedure Run the lsadmin ckconfig -v command and note any errors that are shown in the command output. Look for the error in one of the problems described in this section. If none of these troubleshooting steps applies to your situation, contact IBM Support. Use the following commands to restart the LSF cluster: # lsadmin limrestart all # lsadmin resrestart all # badmin hrestart all Run the ps -ef command to see whether the LSF daemons are running. Look for the processes similar to the following command output: root 17426 1 0 13:30:40 ? 0:00 /opt/lsf/cluster1/10.1/sparc-sol10/etc/lim root 17436 1 0 13:31:11 ? 0:00 /opt/lsf/cluster1/10.1/sparc-sol10/etc/sbatchd root 17429 1 0 13:30:56 ? 0:00 /opt/lsf/cluster1/10.1/sparc-sol10/etc/res Check the LSF error logs on the first few hosts that are listed in the Host section of the LSF_CONFDIR/lsf.cluster.cluster_name file. If the LSF_MASTER_LIST parameter is defined in the LSF_CONFDIR/lsf.conf file, check the error logs on the hosts that are listed in this parameter instead. Cannot open lsf.conf file You might see this message when you run the lsid file. The message usually means that the LSF_CONFDIR/lsf.conf file is not accessible to LSF. About this task By default, LSF checks the directory that is defined by the LSF_ENVDIR parameter for the lsf.conf file. If the lsf.conf file is not in LSF_ENVDIR, LSF looks for it in the /etc directory. For more information, see Setting up the LSF environment with cshrc.lsf and profile.lsf. Procedure Make sure that a symbolic link exists from /etc/lsf.conf to lsf.conf Use the csrhc.lsf or profile.lsf script to set up your LSF environment. Make sure that the cshrc.lsf or profile.lsf script is available for users to set the LSF environment variables. LIM dies quietly When the LSF LIM daemon exits unexpectedly, check for errors in the LIM configuration files. Procedure Run the following commands: lsadmin ckconfig -v This command displays most configuration errors. If the command does not report any errors, check in the LIM error log. LIM communication times out Sometimes the LIM is up, but running the lsload command prints the following error message:Communication time out. About this task If the LIM just started, LIM needs time to get initialized by reading configuration files and contacting other LIMs. If the LIM does not become available within one or two minutes, check the LIM error log for the host you are working on. To prevent communication timeouts when the local LIM is starting or restarting, define the parameter LSF_SERVER_HOSTS in the lsf.conf file. The client contacts the LIM on one of the LSF_SERVER_HOSTS and runs the command. At least one of the hosts that are defined in the list must have a LIM that is up and running. When the local LIM is running but the cluster has no master, LSF applications display the following message: Cannot locate master LIM now, try later. Procedure Check the LIM error logs on the first few hosts that are listed in the Host section of the lsf.cluster.cluster_name file. If the LSF_MASTER_LIST parameter is defined in the lsf.conf file, check the LIM error logs on the hosts that are listed in this parameter instead. Master LIM is down Sometimes the master LIM is up, but running the lsload or lshosts command displays the following error message: Master LIM is down; try later. About this task If the /etc/hosts file on the host where the master LIM is running is configured with the host name that is assigned to the loopback IP address (127.0.0.1), LSF client LIMs cannot contact the master LIM. When the master LIM starts up, it sets its official host name and IP address to the loopback address. Any client requests get the master LIM address as 127.0.0.1, and try to connect to it, and in fact tries to access itself. Procedure Check the IP configuration of your master LIM in /etc/hosts. The following example incorrectly sets the master LIM IP address to the loopback address: 127.0.0.1 localhost myhostname The following example correctly sets the master LIM IP address: 127.0.0.1 localhost 192.168.123.123 myhostname For a master LIM running on a host that uses an IPv6 address, the loopback address is ::1 The following example correctly sets the master LIM IP address by using an IPv6 address: ::1 localhost ipv6-localhost ipv6-loopback fe00::0 ipv6-localnet ff00::0 ipv6-mcastprefix ff02::1 ipv6-allnodes ff02::2 ipv6-allrouters ff02::3 ipv6-allhosts User permission denied If the remote host cannot securely determine the user ID of the user that is requesting remote execution, remote execution fails with the following error message: User permission denied.. Procedure Check the RES error log on the remote host for more detailed error message. If you do not want to configure an identification daemon (LSF_AUTH in lsf.conf), all applications that do remote executions must be owned by root with the setuid bit set. Run the following command: chmod 4755 filename If the application binary files are on an NFS-mounted file system, make sure that the file system is not mounted with the nosuid flag. If you are using an identification daemon (the LSF_AUTH parameter in the lsf.conf file), the inetd daemon must be configured. The identification daemon must not be run directly. Inconsistent host names in a name server with /etc/hosts and /etc/hosts.equiv can also cause this problem. If the LSF_USE_HOSTEQUIV parameter is defined in the lsf.conf file, check that the /etc/hosts.equiv file or the HOME/.rhosts file on the destination host has the client host name in it. For Windows hosts, users must register and update their Windows passwords by using the lspasswd command. Passwords must be 3 characters or longer, and 31 characters or less. For Windows password authentication in a non-shared file system environment, you must define the parameter LSF_MASTER_LIST in the lsf.conf file so that jobs run with correct permissions. If you do not define this parameter, LSF assumes that the cluster uses a shared file system environment. Remote execution fails because of non-uniform file name space A non-uniform file name space might cause a command to fail with the following error message: chdir(...) failed: no such file or directory. About this task You are trying to run a command remotely, but either your current working directory does not exist on the remote host, or your current working directory is mapped to a different name on the remote host. If your current working directory does not exist on a remote host, do not run commands remotely on that host. Procedure If the directory exists, but is mapped to a different name on the remote host, you must create symbolic links to make them consistent. LSF can resolve most, but not all, problems by using automount. The automount maps must be managed through NIS. Contact IBM Support if you are running automount and LSF is not able to locate directories on remote hosts. Batch daemons die quietly When the LSF batch daemons sbatchd and mbatchd exit unexpectedly, check for errors in the configuration files. About this task If the mbatchd daemon is running but the sbatchd daemon dies on some hosts, it might be because mbatchd is not configured to use those hosts. Procedure Check the sbatchd and mbatchd daemon error logs. Run the badmin ckconfig command to check the configuration. Check for email in the LSF administrator mailbox. sbatchd starts but mbatchd does not When the sbatchd daemon starts but the mbatchd daemon is not running, it is possible that mbatchd is temporarily unavailable because the master LIM is temporarily unknown. The following error message is displayed: sbatchd: unknown service. Procedure Run the lsid command to check whether LIM is running. If LIM is not running properly, follow the steps in the following topics to fix LIM problems: LIM dies quietly LIM communication times out Master LIM is down Check whether services are registered properly. Avoiding orphaned job processes LSF uses process groups to track all the processes of a job. However, if the application forks a child, the child becomes a new process group. The parent dies immediately, and the child process group is orphaned from the parent process, and cannot be tracked. About this task For more information about process tracking with Linux cgroups, see Memory and swap limit enforcement based on Linux cgroup memory subsystem. Procedure When a job is started, the application runs under the job RES or root process group. If an application creates a new process group, and its parent process ID (PPID) still belongs to the job, PIM can track this new process group as part of the job. The only reliable way to not lose track of a process is to prevent it from using a new process group. Any process that daemonizes itself is lost when child processes are orphaned from the parent process group because it changes its process group right after it is detached. Host not used by LSF The mbatchd daemon allows the sbatchd daemon to run only on the hosts that are listed in the Host section of the lsb.hosts file. If you configure an unknown host in the following configurations, mbatchd logs an error message: HostGroup or HostPartition sections of the lsb.hosts file, or as a HOSTS definition for a queue in the lsb.queues file. About this task If you try to configure a host that is not listed in the Host section of the lsb.hosts file, the mbatchd daemon logs the following message. mbatchd on host: LSB_CONFDIR/cluster1/configdir/file(line #): Host hostname is not used by lsbatch; ignored If you start the sbatchd daemon on a host that is not known by the mbatchd daemon, mbatchd rejects the sbatchd. The sbatchd daemon logs the following message and exits. This host is not used by lsbatch system. Procedure Add the unknown host to the list of hosts in the Host section of the lsb.hosts file. Start the LSF daemons on the new host. Run the following commands to reconfigure the cluster: lsadmin reconfig badmin reconfig UNKNOWN host type or model A model or type UNKNOWN indicates that the host is down or the LIM on the host is down. You need to take immediate action to restart LIM on the UNKNOWN host. Procedure Start the host. Run the lshosts command to see which host has the UNKNOWN host type or model. lshosts HOST_NAME type model cpuf ncpus maxmem maxswp server RESOURCES hostA UNKNOWN Ultra2 20.2 2 256M 710M Yes () Run the lsadmin limstartup command to start LIM on the host. lsadmin limstartup hostA Starting up LIM on .... done If EGO is enabled in the LSF cluster, you can run the following command instead: egosh ego start lim hostA Starting up LIM on .... done You can specify more than one host name to start LIM on multiple hosts. If you do not specify a host name, LIM is started on the host from which the command is submitted. To start LIM remotely on UNIX or Linux, you must be root or listed in the lsf.sudoers file (or the ego.sudoers file if EGO is enabled in the LSF cluster). You must be able to run the rsh command across all hosts without entering a password. Wait a few seconds, then run the lshosts command again. The lshosts command displays a specific model or type for the host or DEFAULT. If you see DEFAULT, it means that automatic detection of host type or model failed, and the host type that is configured in the lsf.shared file cannot be found. LSF works on the host, but a DEFAULT model might be inefficient because of incorrect CPU factors. A DEFAULT type might also cause binary incompatibility because a job from a DEFAULT host type can be migrated to another DEFAULT host type. DEFAULT host type or model If you see DEFAULT in lim -t, it means that automatic detection of host type or model failed, and the host type that is configured in the lsf.shared file cannot be found. LSF works on the host, but a DEFAULT model might be inefficient because of incorrect CPU factors. A DEFAULT type might also cause binary incompatibility because a job from a DEFAULT host type can be migrated to another DEFAULT host type. Procedure Run the lshosts command to see which host has the DEFAULT host model or type. lshosts HOST_NAME type model cpuf ncpus maxmem maxswp server RESOURCES hostA DEFAULT DEFAULT 1 2 256M 710M Yes () If Model or Type are displayed as DEFAULT when you use the lshosts command and automatic host model and type detection is enabled, you can leave it as is or change it. If the host model is DEFAULT, LSF works correctly but the host has a CPU factor of 1, which might not make efficient use of the host model. If the host type is DEFAULT, there might be binary incompatibility. For example, if one host is Linux and another is AIX, but both hosts are set to type DEFAULT, jobs that are running on the Linux host might be migrated to the AIX host and vice versa, which might cause the job to file. Run lim -t on the host whose type is DEFAULT: lim -t Host Type : NTX64 Host Architecture : EM64T_1596 Total NUMA Nodes : 1 Total Processors : 2 Total Cores : 4 Total Threads : 2 Matched Type : NTX64 Matched Architecture : EM64T_3000 Matched Model : Intel_EM64T CPU Factor : 60.0 NoteThe value of HostType and Host Architecture. Edit the lsf.shared file to configure the host type and host model for the host. In the HostType section, enter a new host type. Use the host type name that is detected with the lim -t command. Begin HostType TYPENAME DEFAULT CRAYJ NTX64 ... End HostType In the HostModel section, enter the new host model with architecture and CPU factor. Use the architecture that is detected with the lim -t commmand. Add the host model to the end of the host model list. The limit for host model entries is 127. Lines commented out with # are not counted in the 127-line limit. Begin HostModel MODELNAME CPUFACTOR ARCHITECTURE # keyword Intel_EM64T 20 EM64T_1596 End HostModel Save changes to the lsf.shared file. Run the lsadmin reconfig command to reconfigure LIM. Wait a few seconds, and run the lim -t command again to check the type and model of the host. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-14 09:24:41 "},"chapter4/section3/LSF_error_messages.html":{"url":"chapter4/section3/LSF_error_messages.html","title":"LSF 错误信息","keywords":"","body":"LSF 错误信息 The following error messages are logged by the LSF daemons, or displayed by the lsadmin ckconfig and badmin ckconfig commands. General errors The following messages can be generated by any LSF daemon: can’t open file: error The daemon might not open the named file for the reason that is given by error. This error is usually caused by incorrect file permissions or missing files. All directories in the path to the configuration files must have execute (x) permission for the LSF administrator, and the actual files must have read (r) permission. Missing files might be caused by the following errors: Incorrect path names in the lsf.conf file Running LSF daemons on a host where the configuration files are not installed Having a symbolic link that points to a file or directory that does not exist file(line): malloc failed Memory allocation failed. Either the host does not have enough available memory or swap space, or there is an internal error in the daemon. Check the program load and available swap space on the host. If the swap space is full, you must add more swap space or run fewer (or smaller) programs on that host. auth_user: getservbyname(ident/tcp) failed: error; ident must be registered in services The LSF_AUTH=ident parameter is defined in the lsf.conf file, but the ident/tcp service is not defined in the services database. Add ident/tcp to the services database, or remove the LSF_AUTH=ident parameter from the lsf.conf file and use the setuid root command on the LSF files that require authentication. auth_user: operation(/) failed: error The LSF_AUTH=ident parameter is defined in the lsf.conf file, but the LSF daemon failed to contact the identd daemon on the host. Check that identd is defined in inetd.conf and the identd daemon is running on host. auth_user: Authentication data format error (rbuf=) from / auth_user: Authentication port mismatch (...) from / The LSF_AUTH=ident parameter is defined in the lsf.conf file, but there is a protocol error between LSF and the ident daemon on host. Make sure that the identd daemon on the host is configured correctly. userok: Request from bad port (), denied The LSF_AUTH=ident parameter is not defined, and the LSF daemon received a request that originates from a non-privileged port. The request is not serviced. Set the LSF binary files to be owned by root with the setuid bit set, or define the LSF_AUTH=ident parameter and set up an ident server on all hosts in the cluster. If the files are on an NFS-mounted file system, make sure that the file system is not mounted with the nosuid flag. userok: Forged username suspected from /: / The service request claimed to come from user claimed_user but ident authentication returned that the user was actual_user. The request was not serviced. userok: ruserok(,) failed The LSF_USE_HOSTEQUIV parameter is defined in the lsf.conf file, but host is not set up as an equivalent host in /etc/host.equiv, and user uid is not set up in a .rhosts file. init_AcceptSock: RES service(res) not registered, exiting init_AcceptSock: res/tcp: unknown service, exiting initSock: LIM service not registered. initSock: Service lim/udp is unknown. Read LSF Guide for help get_ports: service not registered The LSF services are not registered. init_AcceptSock: Can’t bind daemon socket to port : error, exiting init_ServSock: Could not bind socket to port : error These error messages can occur if you try to start a second LSF daemon (for example, RES is already running, and you run RES again). If so, and you want to start the new daemon, kill the running daemon or use the lsadmin or badmin commands to shut down or restart the daemon. Configuration errors The following messages are caused by problems in the LSF configuration files. General errors are listed first, and then errors from specific files. file(line): Section name expected after Begin; ignoring section file(line): Invalid section name name; ignoring section The keyword Begin at the specified line is not followed by a section name, or is followed by an unrecognized section name. file(line): section section: Premature EOF The end of file was reached before reading the End section line for the named section. file(line): keyword line format error for section section; Ignore this section The first line of the section must contain a list of keywords. This error is logged when the keyword line is incorrect or contains an unrecognized keyword. file(line): values do not match keys for section section; Ignoring line The number of fields on a line in a configuration section does not match the number of keywords. This error can be caused by not putting () in a column to represent the default value. file: HostModel section missing or invalid file: Resource section missing or invalid file: HostType section missing or invalid The HostModel, Resource, or HostType section in the lsf.shared file is either missing or contains an unrecoverable error. file(line): Name name reserved or previously defined. Ignoring index The name that is assigned to an external load index must not be the same as any built-in or previously defined resource or load index. file(line): Duplicate clustername name in section cluster. Ignoring current line A cluster name is defined twice in the same lsf.shared file. The second definition is ignored. file(line): Bad cpuFactor for host model model. Ignoring line The CPU factor declared for the named host model in the lsf.shared file is not a valid number. file(line): Too many host models, ignoring model name You can declare a maximum of 127 host models in the lsf.shared file. file(line): Resource name name too long in section resource. Should be less than 40 characters. Ignoring line The maximum length of a resource name is 39 characters. Choose a shorter name for the resource. file(line): Resource name name reserved or previously defined. Ignoring line. You attempted to define a resource name that is reserved by LSF or already defined in the lsf.shared file. Choose another name for the resource. file(line): illegal character in resource name: name, section resource. Line ignored. Resource names must begin with a letter in the set [a-zA-Z], followed by letters, digits, or underscores [a-zA-Z0-9_]. LIM messages The following messages are logged by the LIM: findHostbyAddr/: Host / is unknown by function: Gethostbyaddr_(/) failed: error main: Request from unknown host /: error function: Received request from non-LSF host / The daemon does not recognize host. The request is not serviced. These messages can occur if host was added to the configuration files, but not all the daemons were reconfigured to read the new information. If the problem still occurs after reconfiguring all the daemons, check whether the host is a multi-addressed host. rcvLoadVector: Sender (/) may have different config? MasterRegister: Sender (host) may have different config? LIM detected inconsistent configuration information with the sending LIM. Run the following command so that all the LIMs have the same configuration information. lsadmin reconfig Note any hosts that failed to be contacted. rcvLoadVector: Got load from client-only host /. Kill LIM on / A LIM is running on a client host. Run the following command, or go to the client host and kill the LIM daemon. lsadmin limshutdown host saveIndx: Unknown index name from ELIM LIM received an external load index name that is not defined in the lsf.shared file. If name is defined in lsf.shared, reconfigure the LIM. Otherwise, add name to the lsf.shared file and reconfigure all the LIMs. saveIndx: ELIM over-riding value of index This warning message is logged when the ELIM sent a value for one of the built-in index names. LIM uses the value from ELIM in place of the value that is obtained from the kernel. getusr: Protocol error numIndx not read (cc=num): error getusr: Protocol error on index number (cc=num): error Protocol error between ELIM and LIM. RES messages The following messages are logged by the RES: doacceptconn: getpwnam(@/) failed: error doacceptconn: User has uid on client host /, uid on RES host; assume bad user authRequest: username/uid /@/ does not exist authRequest: Submitter’s name @ is different from name on this host RES assumes that a user has the same user ID and user name on all the LSF hosts. These messages occur if this assumption is violated. If the user is allowed to use LSF for interactive remote execution, make sure the user’s account has the same user ID and user name on all LSF hosts. doacceptconn: root remote execution permission denied authRequest: root job submission rejected Root tried to run or submit a job but LSF_ROOT_REX is not defined in the lsf.conf file. resControl: operation permission denied, uid = The user with user ID uid is not allowed to make RES control requests. Only the LSF administrator can make RES control requests. If the LSF_ROOT_REX parameter is defined in the lsf.conffile, can also make RES control requests. resControl: access(respath, X_OK): error The RES received a restart request, but failed to find the file respath to re-execute itself. Make sure respath contains the RES binary, and it has execution permission. mbatchd and sbatchd messages The following messages are logged by the mbatchd and sbatchd daemons: renewJob: Job : rename(,) failed: error mbatchd failed in trying to resubmit a rerunnable job. Check that the file from exists and that the LSF administrator can rename the file. If from is in an AFS directory, check that the LSF administrator’s token processing is properly setup. logJobInfo_: fopen() failed: error logJobInfo_: write failed: error logJobInfo_: seek failed: error logJobInfo_: write xdrpos failed: error logJobInfo_: write xdr buf len failed: error logJobInfo_: close() failed: error rmLogJobInfo: Job : can’t unlink(): error rmLogJobInfo_: Job : can’t stat(): error readLogJobInfo: Job can’t open(): error start_job: Job : readLogJobInfo failed: error readLogJobInfo: Job : can’t read() size size: error initLog: mkdir() failed: error : fopen( failed: error getElogLock: Can’t open existing lock file : error getElogLock: Error in opening lock file : error releaseElogLock: unlink() failed: error touchElogLock: Failed to open lock file : error touchElogLock: close failed: error mbatchd failed to create, remove, read, or write the log directory or a file in the log directory, for the reason that is given in error. Check that the LSF administrator has read, write, and execute permissions on the logdir directory. replay_newjob: File at line : Queue not found, saving to queue replay_switchjob: File at line : Destination queue not found, switching to queue When the mbatchd daemon was reconfigured, jobs were found in queue but that queue is no longer in the configuration. replay_startjob: JobId : exec host not found, saving to host When the mbatchd daemon was reconfigured, the event log contained jobs that are dispatched to host, but that host is no longer configured to be used by LSF. do_restartReq: Failed to get hData of host / mbatchd received a request from sbatchd on host host_name, but that host is not known to mbatchd. Either the configuration file has changed but mbatchd was not reconfigured to pick up the new configuration, or host_name is a client host but the sbatchd daemon is running on that host. Run the following command to reconfigure the mbatchd daemon or kill the sbatchd daemon on host_name. badmin reconfig LSF command messages LSF daemon (LIM) not responding ... still trying During LIM restart, LSF commands might fail and display this error message. User programs that are linked to the LIM API also fail for the same reason. This message is displayed when LIM running on the master host list or server host list is restarted after configuration changes, such as adding new resources, or binary upgrade. Use the LSF_LIM_API_NTRIES parameter in the lsf.conf file or as an environment variable to define how many times LSF commands retry to communicate with the LIM API while LIM is not available. The LSF_LIM_API_NTRIES parameter is ignored by LSF and EGO daemons and all EGO commands. When the LSB_API_VERBOSE=Y parameter is set in the lsf.conf file, LSF batch commands display the not responding retry error message to stderr when LIM is not available. When the LSB_API_VERBOSE=N parameter is set in the lsf.conf file, LSF batch commands do not display the retry error message when LIM is not available. Batch command client messages LSF displays error messages when a batch command cannot communicate with the mbatchd daemon. The following table provides a list of possible error reasons and the associated error message output. Point of failure Possible reason Error message output Establishing a connection with the mbatchd daemon The mbatchd daemon is too busy to accept new connections. The connect() system call times out. LSF is processing your request. Please wait… The mbatchd daemon is down or no process is listening at either the LSB_MBD_PORT or the LSB_QUERY_PORT LSF is down. Please wait… The mbatchd daemon is down and the LSB_QUERY_PORT is busy bhosts displays LSF is down. Please wait. . .bjobs displays Cannot connect to LSF. Please wait… Socket error on the client side Cannot connect to LSF. Please wait… connect() system call fails Cannot connect to LSF. Please wait… Internal library error Cannot connect to LSF. Please wait… Send/receive handshake message to/from the mbatchd daemon The mbatchd daemon is busy. Client times out when LSF is waiting to receive a message from mbatchd. LSF is processing your request. Please wait… Socket read()/write() fails Cannot connect to LSF. Please wait… Internal library error Cannot connect to LSF. Please wait… EGO command messages You cannot run the egosh command because the administrator has chosen not to enable EGO in lsf.conf: LSF_ENABLE_EGO=N. If EGO is not enabled, the egosh command cannot find the ego.conf file or cannot contact the vemkd daemon (likely because it is not started). © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:04:05 "},"chapter5/run_jobs.html":{"url":"chapter5/run_jobs.html","title":"Chapter 5 作业调度管理","keywords":"","body":"Chapter 5 作业调度管理 运行，监视和控制提交给 LSF 的作业。 关于IBM Spectrum LSF 作业运行 作业监控 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-22 09:59:37 "},"chapter5/section1/about_IBM_Spectrum_LSF.html":{"url":"chapter5/section1/about_IBM_Spectrum_LSF.html","title":"5.1 关于 IBM Spectrum LSF","keywords":"","body":"5.1 关于 IBM Spectrum LSF Clusters, jobs, and queues The IBM Spectrum LSF (\"LSF\", short for load sharing facility) software is industry-leading enterprise-class software that distributes work across existing heterogeneous IT resources to create a shared, scalable, and fault-tolerant infrastructure, that delivers faster, balanced, more reliable workload performance and reduces cost. Hosts LSF daemons Batch jobs and tasks Host types and host models Users and administrators Resources Job lifecycle © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:27:32 "},"chapter5/section1/LSF_clusters_jobs_and_queues.html":{"url":"chapter5/section1/LSF_clusters_jobs_and_queues.html","title":"LSF 集群，作业与队列","keywords":"","body":"LSF 集群，作业与队列 The IBM Spectrum LSF (\"LSF\", short for load sharing facility) software is industry-leading enterprise-class software that distributes work across existing heterogeneous IT resources to create a shared, scalable, and fault-tolerant infrastructure, that delivers faster, balanced, more reliable workload performance and reduces cost. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:27:35 "},"chapter5/section1/hosts.html":{"url":"chapter5/section1/hosts.html","title":"节点","keywords":"","body":"节点 A host is an individual computer in the cluster. Each host may have more than one processor. Multiprocessor hosts are used to run parallel jobs. A multiprocessor host with a single process queue is considered a single machine, while a box full of processors that each have their own process queue is treated as a group of separate machines. Commands lsload — View load on hosts lshosts — View configuration information about hosts in the cluster including number of CPUS, model, type, and whether the host is a client or server bhosts — View batch server hosts in the cluster TipThe names of your hosts should be unique. They should not be the same as the cluster name or any queue defined for the cluster. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:27:47 "},"chapter5/section1/LSF_daemons.html":{"url":"chapter5/section1/LSF_daemons.html","title":"LSF 守护程序","keywords":"","body":"LSF daemons LSF daemon Role mbatchd Job requests and dispatch mbschd Job scheduling sbatchd**res** Job execution Parent topic: About IBM Spectrum LSF mbatchd Master Batch Daemon running on the master host. Started by sbatchd. Responsible for the overall state of jobs in the system. Receives job submission, and information query requests. Manages jobs that are held in queues. Dispatches jobs to hosts as determined by mbschd. Configuration Port number is defined in lsf.conf. mbschd Master Batch Scheduler Daemon running on the master host. Works with mbatchd. Started by mbatchd. Makes scheduling decisions based on job requirements, and policies, and resource availability. Sends scheduling decisions to mbatchd. sbatchd Slave Batch Daemon running on each server host. Receives the request to run the job from mbatchd and manages local execution of the job. Responsible for enforcing local policies and maintaining the state of jobs on the host. The sbatchd forks a child sbatchd for every job. The child sbatchd runs an instance of res to create the execution environment in which the job runs. The child sbatchd exits when the job is complete. Commands badmin hstartup — Starts sbatchd badmin hshutdown — Shuts down sbatchd badmin hrestart — Restarts sbatchd Configuration Port number is defined in lsf.conf res Remote Execution Server (res) running on each server host. Accepts remote execution requests to provide transparent and secure remote execution of jobs and tasks. Commands lsadmin resstartup — Starts res lsadmin resshutdown — Shuts down res lsadmin resrestart — Restarts res Configuration Port number is defined in lsf.conf. lim Load Information Manager (LIM) running on each server host. Collects host load and configuration information and forwards it to the master LIM running on the master host. Reports the information that is displayed by lsload and lshosts. Static indices are reported when the LIM starts up or when the number of CPUs (ncpus) change. Static indices are: Number of CPUs (ncpus) Number of disks (ndisks) Total available memory (maxmem) Total available swap (maxswp) Total available temp (maxtmp) Dynamic indices for host load collected at regular intervals are: Hosts status (status) 15 second, 1 minute, and 15 minute run queue lengths (r15s, r1m, and r15m) CPU utilization (ut) Paging rate (pg) Number of login sessions (ls) Interactive idle time (it) Available swap space (swp) Available memory (mem) Available temp space (tmp) Disk IO rate (io) Commands lsadmin limstartup — Starts LIM lsadmin limshutdown — Shuts down LIM lsadmin limrestart — Restarts LIM lsload — View dynamic load values lshosts — View static host load values Configuration Port number is defined in lsf.conf. Master LIM The LIM running on the master host. Receives load information from the LIMs running on hosts in the cluster. Forwards load information to mbatchd, which forwards this information to mbschd to support scheduling decisions. If the master LIM becomes unavailable, a LIM on another host automatically takes over. Commands lsadmin limstartup — Starts LIM lsadmin limshutdown — Shuts down LIM lsadmin limrestart — Restarts LIM lsload — View dynamic load values lshosts — View static host load values Configuration Port number is defined in lsf.conf. ELIM External LIM (ELIM) is a site-definable executable that collects and tracks custom dynamic load indices. An ELIM can be a shell script or a compiled binary program, which returns the values of the dynamic resources you define. The ELIM executable must be named elim and located in LSF_SERVERDIR. pim Process Information Manager (PIM) running on each server host. Started by LIM, which periodically checks on pim and restarts it if it dies. Collects information about job processes running on the host such as CPU and memory that is used by the job, and reports the information to sbatchd. Commands bjobs — View job information © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:28:04 "},"chapter5/section1/Batch_jobs_and_tasks.html":{"url":"chapter5/section1/Batch_jobs_and_tasks.html","title":"批处理作业和任务","keywords":"","body":"Batch jobs and tasks You can either run jobs through the batch system where jobs are held in queues, or you can interactively run tasks without going through the batch system, such as tests. Parent topic: About IBM Spectrum LSF Job A unit of work that is run in the LSF system. A job is a command that is submitted to LSF for execution, using the bsub command. LSF schedules, controls, and tracks the job according to configured policies. Jobs can be complex problems, simulation scenarios, extensive calculations, anything that needs compute power. Commands bjobs — View jobs in the system bsub — Submit jobs Interactive batch job A batch job that allows you to interact with the application and still take advantage of LSF scheduling policies and fault tolerance. All input and output are through the terminal that you used to type the job submission command. When you submit an interactive job, a message is displayed while the job is awaiting scheduling. A new job cannot be submitted until the interactive job is completed or terminated. The bsub command stops display of output from the shell until the job completes, and no mail is sent to you by default. Use Ctrl-C at any time to terminate the job. Commands bsub -I — Submit an interactive job Interactive task A command that is not submitted to a batch queue and scheduled by LSF, but is dispatched immediately. LSF locates the resources that are needed by the task and chooses the best host among the candidate hosts that has the required resources and is lightly loaded. Each command can be a single process, or it can be a group of cooperating processes. Tasks are run without using the batch processing features of LSF but still with the advantage of resource requirements and selection of the best host to run the task based on load. Commands lsrun — Submit an interactive task lsgrun — Submit an interactive task to a group of hosts See also LSF utilities such as ch, lsacct, lsacctmrg, lslogin, lsplace, lsload, lsloadadj, lseligible, lsmon, lstcsh. Local task An application or command that does not make sense to run remotely. For example, the ls command on UNIX. Commands lsltasks — View and add tasks Configuration lsf.task— Configure system-wide resource requirements for tasks lsf.task.cluster — Configure cluster-wide resource requirements for tasks .lsftasks — Configure user-specific tasks Remote task An application or command that can be run on another machine in the cluster. Commands lsrtasks — View and add tasks Configuration lsf.task — Configure system-wide resource requirements for tasks lsf.task.cluster — Configure cluster-wide resource requirements for tasks .lsftasks — Configure user-specific tasks © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:28:20 "},"chapter5/section1/Host_types_and_host_models.html":{"url":"chapter5/section1/Host_types_and_host_models.html","title":"主机类型和主机型号","keywords":"","body":"Host types and host models Hosts in LSF are characterized by host type and host model. The following example has a host type of X86_64. Host models are Opteron240, Opteron840, Intel_EM64T, Intel_IA64. Host type The combination of operating system version and host CPU architecture. All computers that run the same operating system on the same computer architecture are of the same type — in other words, binary-compatible with each other. Each host type usually requires a different set of LSF binary files. Commands: lsinfo -t — View all host types that are defined in lsf.shared Configuration: Defined in lsf.shared Mapped to hosts in lsf.cluster.cluster_name Host model The combination of host type and CPU speed (CPU factor) of the computer. All hosts of the same relative speed are assigned the same host model. The CPU factor is taken into consideration when jobs are being dispatched. Commands: lsinfo -m — View a list of currently running models lsinfo -M — View all models that are defined in lsf.shared Configuration: Defined in lsf.shared Mapped to hosts in lsf.cluster.cluster_name © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:28:31 "},"chapter5/section1/Users_and_administrators.html":{"url":"chapter5/section1/Users_and_administrators.html","title":"用户和管理员","keywords":"","body":"Users and administrators LSF user A user account that has permission to submit jobs to the LSF cluster. LSF administrator In general, you must be an LSF administrator to perform operations that will affect other LSF users. Each cluster has one primary LSF administrator, specified during LSF installation. You can also configure additional administrators at the cluster level and at the queue level. Primary LSF administrator The first cluster administrator specified during installation and first administrator listed in lsf.cluster.cluster_name. The primary LSF administrator account owns the configuration and log files. The primary LSF administrator has permission to perform clusterwide operations, change configuration files, reconfigure the cluster, and control jobs submitted by all users. Cluster administrator May be specified during LSF installation or configured after installation. Cluster administrators can perform administrative operations on all jobs and queues in the cluster. Cluster administrators have the same cluster-wide operational privileges as the primary LSF administrator except that they do not necessarily have permission to change LSF configuration files. For example, a cluster administrator can create an LSF host group, submit a job to any queue, or terminate another user’s job. Queue administrator An LSF administrator user account that has administrative permissions limited to a specified queue. For example, an LSF queue administrator can perform administrative operations on the specified queue, or on jobs running in the specified queue, but cannot change LSF configuration or operate on LSF daemons. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:28:47 "},"chapter5/section1/Resources.html":{"url":"chapter5/section1/Resources.html","title":"资源","keywords":"","body":"Resources Resource usage The LSF system uses built-in and configured resources to track resource availability and usage. Jobs are scheduled according to the resources available on individual hosts. Jobs that are submitted through the LSF system will have the resources that they use monitored while they are running. This information is used to enforce resource limits and load thresholds as well as fairshare scheduling. LSF collects information such as: Total CPU time consumed by all processes in the job Total resident memory usage in KB of all currently running processes in a job Total virtual memory usage in KB of all currently running processes in a job Currently active process group ID in a job Currently active processes in a job On UNIX, job-level resource usage is collected through PIM. Commands lsinfo — View the resources available in your cluster bjobs -l — View current resource usage of a job Configuration SBD_SLEEP_TIME in lsb.params — Configures how often resource usage information is sampled by PIM, collected by sbatchd, and sent to mbatchd Load indices Load indices measure the availability of dynamic, non-shared resources on hosts in the cluster. Load indices that are built into the LIM are updated at fixed time intervals. Commands lsload -l — View all load indices bhosts -l — View load levels on a host External load indices Defined and configured by the LSF administrator and collected by an External Load Information Manager (ELIM) program. The ELIM also updates LIM when new values are received. Commands lsinfo — View external load indices Static resources Built-in resources that represent host information that does not change over time, such as the maximum RAM available to user processes or the number of processors in a machine. Most static resources are determined by the LIM at startup. Static resources can be used to select appropriate hosts for particular jobs based on binary architecture, relative CPU speed, and system configuration. Load thresholds Two types of load thresholds can be configured by your LSF administrator to schedule jobs in queues. Each load threshold specifies a load index value: loadSched determines the load condition for dispatching pending jobs. If a host’s load is beyond any defined loadSched, a job will not be started on the host. This threshold is also used as the condition for resuming suspended jobs. loadStop determines when running jobs should be suspended. To schedule a job on a host, the load levels on that host must satisfy both the thresholds that are configured for that host and the thresholds for the queue from which the job is being dispatched. The value of a load index may either increase or decrease with load, depending on the meaning of the specific load index. Therefore, when comparing the host load conditions with the threshold values, you need to use either greater than (>) or less than ( Commands bhosts -l — View suspending conditions for hosts bqueues -l — View suspending conditions for queues bjobs -l — View suspending conditions for a particular job and the scheduling thresholds that control when a job is resumed Configuration lsb.hosts — Configure thresholds for hosts lsb.queues — Configure thresholds for queues Runtime resource usage limits Limit the use of resources while a job is running. Jobs that consume more than the specified amount of a resource are signaled or have their priority lowered. Configuration lsb.queues — Configure resource usage limits for queues Hard and soft limits Resource limits that are specified at the queue level are hard limits while those specified with job submission are soft limits. See setrlimit(2) man page for concepts of hard and soft limits. Resource allocation limits Restrict the amount of a given resource that must be available during job scheduling for different classes of jobs to start, and which resource consumers the limits apply to. If all of the resource has been consumed, no more jobs can be started until some of the resource is released. Configuration lsb.resources — Configure queue-level resource allocation limits for hosts, users, queues, and projects Resource requirements (bsub -R) Restrict which hosts the job can run on. Hosts that match the resource requirements are the candidate hosts. When LSF schedules a job, it collects the load index values of all the candidate hosts and compares them to the scheduling conditions. Jobs are only dispatched to a host if all load values are within the scheduling thresholds. Commands bsub -R — Specify resource requirement string for a job Configuration lsb.queues — Configure resource requirements for queues © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:29:02 "},"chapter5/section1/Job_lifecycle.html":{"url":"chapter5/section1/Job_lifecycle.html","title":"作业生命周期","keywords":"","body":"Job lifecycle Parent topic: About IBM Spectrum LSF 1 Submit a job You submit a job from an LSF client or server with the bsub command. If you do not specify a queue when submitting the job, the job is submitted to the default queue. Jobs are held in a queue waiting to be scheduled and have the PEND state. The job is held in a job file in the LSF_SHAREDIR/cluster_name/logdir/info/ directory. Job ID LSF assigns each job a unique job ID when you submit the job. Job name You can also assign a name to the job with the -J option of bsub. Unlike the job ID, the job name is not necessarily unique. 2 Schedule job mbatchd looks at jobs in the queue and sends the jobs for scheduling to mbschd at a preset time interval (defined by the parameter JOB_SCHEDULING_INTERVAL in lsb.params). mbschd evaluates jobs and makes scheduling decisions based on the following: Job priority Scheduling policies Available resources mbschd selects the best hosts where the job can run and sends its decisions back to mbatchd. Resource information is collected at preset time intervals by the master LIM from LIMs on server hosts. The master LIM communicates this information to mbatchd, which in turn communicates it to mbschd to support scheduling decisions. 3 Dispatch job As soon as mbatchd receives scheduling decisions, it immediately dispatches the jobs to hosts. 4 Run job sbatchd handles job execution. It does the following: Receives the request from mbatchd Creates a child sbatchd for the job Creates the execution environment Starts the job using res The execution environment is copied from the submission host to the execution host and includes the following: Environment variables that are needed by the job Working directory where the job begins running Other system-dependent environment settings; for example: On UNIX and Linux, resource limits and umask On Windows, desktop and Windows root directory The job runs under the user account that submitted the job and has the status RUN. 5 Return output When a job is completed, it is assigned the DONE status if the job was completed without any problems. The job is assigned the EXIT status if errors prevented the job from completing. sbatchd communicates job information including errors and output to mbatchd. 6 Send email to client mbatchd returns the job output, job error, and job information to the submission host through email. Use the -o and -e options of bsub to send job output and errors to a file. Job report A job report is sent by email to the LSF client and includes the following information: Job information such as the following: CPU use Memory use Name of the account that submitted the job Job output Errors © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-08 09:29:20 "},"chapter5/section2/working_with_jobs.html":{"url":"chapter5/section2/working_with_jobs.html","title":"5.2 作业运行","keywords":"","body":"5.2 作业运行 Submitting jobs (bsub) Modify pending jobs (bmod) Modify running jobs About controlling jobs LSF controls jobs dispatched to a host to enforce scheduling policies or in response to user requests. Using LSF with non-shared file space About resource reservation Set pending time limits You can specify pending time limits and eligible pending time limits for jobs to ensure that jobs do not remain pending in LSF for too long. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section2/subsection1/submitting_jobs_using_bsub.html":{"url":"chapter5/section2/subsection1/submitting_jobs_using_bsub.html","title":"bsub 提交作业","keywords":"","body":"bsub 提交作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/About submitting a job to a specific queue.html":{"url":"chapter5/section2/subsection1/About submitting a job to a specific queue.html","title":"将作业提交到特定队列","keywords":"","body":"将作业提交到特定队列 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/View available queues.html":{"url":"chapter5/section2/subsection1/View available queues.html","title":"查看可用队列","keywords":"","body":"查看可用队列 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job to a queue.html":{"url":"chapter5/section2/subsection1/Submit a job to a queue.html","title":"将作业提交到队列","keywords":"","body":"将作业提交到队列 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job associated with a project.html":{"url":"chapter5/section2/subsection1/Submit a job associated with a project.html","title":"提交与项目关联的作业 (bsub -P)","keywords":"","body":"提交与项目关联的作业 (bsub -P) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job associated with a user group.html":{"url":"chapter5/section2/subsection1/Submit a job associated with a user group.html","title":"提交与用户组关联的作业 (bsub -G)","keywords":"","body":"提交与用户组关联的作业 (bsub -G) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job with a job name.html":{"url":"chapter5/section2/subsection1/Submit a job with a job name.html","title":"提交有作业名的作业 (bsub -J)","keywords":"","body":"提交有作业名的作业 (bsub -J) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job to a service class.html":{"url":"chapter5/section2/subsection1/Submit a job to a service class.html","title":"提交作业到服务类 (bsub -sla)","keywords":"","body":"提交作业到服务类 (bsub -sla) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job under a job group.html":{"url":"chapter5/section2/subsection1/Submit a job under a job group.html","title":"在作业组下提交作业 (bsub -g)","keywords":"","body":"在作业组下提交作业 (bsub -g) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job with a JSON file.html":{"url":"chapter5/section2/subsection1/Submit a job with a JSON file.html","title":"提交带有 JSON 文件的作业 (bsub -json)","keywords":"","body":"提交带有 JSON 文件的作业 (bsub -json) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job with a YAML file.html":{"url":"chapter5/section2/subsection1/Submit a job with a YAML file.html","title":"提交带有 YAML 文件的作业 (bsub -yaml)","keywords":"","body":"提交带有 YAML 文件的作业 (bsub -yaml) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection1/Submit a job with a JSDL file.html":{"url":"chapter5/section2/subsection1/Submit a job with a JSDL file.html","title":"提交带有 JSDL 文件的作业 (bsub -jsdl)","keywords":"","body":"提交带有 JSDL 文件的作业 (bsub -jsdl) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection2/Modify pending jobs.html":{"url":"chapter5/section2/subsection2/Modify pending jobs.html","title":"修改正在等待的作业 (bmod)","keywords":"","body":"修改正在等待的作业 (bmod) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection3/Modify running jobs.html":{"url":"chapter5/section2/subsection3/Modify running jobs.html","title":"修改正在运行的作业","keywords":"","body":"修改正在运行的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/About controlling jobs.html":{"url":"chapter5/section2/subsection4/About controlling jobs.html","title":"关于控制作业","keywords":"","body":"关于控制作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Kill a job.html":{"url":"chapter5/section2/subsection4/Kill a job.html","title":"刹掉作业 (bkill)","keywords":"","body":"刹掉作业 (bkill) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/About suspending and resuming jobs.html":{"url":"chapter5/section2/subsection4/About suspending and resuming jobs.html","title":"关于暂停和恢复作业 (bstop and bresume)","keywords":"","body":"关于暂停和恢复作业 (bstop and bresume) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Move a job to the bottom of a queue.html":{"url":"chapter5/section2/subsection4/Move a job to the bottom of a queue.html","title":"将作业移到队列底部 (bbot)","keywords":"","body":"将作业移到队列底部 (bbot) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Move a job to the top of a queue.html":{"url":"chapter5/section2/subsection4/Move a job to the top of a queue.html","title":"将作业移到队列顶部 (btop)","keywords":"","body":"将作业移到队列顶部 (btop) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Control jobs in job groups.html":{"url":"chapter5/section2/subsection4/Control jobs in job groups.html","title":"控制作业组中的作业","keywords":"","body":"控制作业组中的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Submit a job to specific hosts.html":{"url":"chapter5/section2/subsection4/Submit a job to specific hosts.html","title":"将作业提交给特定主机","keywords":"","body":"将作业提交给特定主机 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Submit a job with specific resources.html":{"url":"chapter5/section2/subsection4/Submit a job with specific resources.html","title":"提交具有特定资源的作业","keywords":"","body":"提交具有特定资源的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Queues and host preference.html":{"url":"chapter5/section2/subsection4/Queues and host preference.html","title":"队列和主机首选项","keywords":"","body":"队列和主机首选项 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Specify different levels of host preference.html":{"url":"chapter5/section2/subsection4/Specify different levels of host preference.html","title":"指定不同级别的主机首选项","keywords":"","body":"指定不同级别的主机首选项 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Submit a job with resource requirements.html":{"url":"chapter5/section2/subsection4/Submit a job with resource requirements.html","title":"提交具有资源需求的作业","keywords":"","body":"提交具有资源需求的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection4/Submit a job with SSH X11 forwarding.html":{"url":"chapter5/section2/subsection4/Submit a job with SSH X11 forwarding.html","title":"通过 SSH X11 转发提交作业","keywords":"","body":"通过 SSH X11 转发提交作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection5/Using LSF with non-shared file space.html":{"url":"chapter5/section2/subsection5/Using LSF with non-shared file space.html","title":"将 LSF 与非共享文件空间一起使用","keywords":"","body":"将 LSF 与非共享文件空间一起使用 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection5/Operator.html":{"url":"chapter5/section2/subsection5/Operator.html","title":"操作符","keywords":"","body":"操作符 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection6/About resource reservation.html":{"url":"chapter5/section2/subsection6/About resource reservation.html","title":"关于资源预约","keywords":"","body":"关于资源预约 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection6/View resource information.html":{"url":"chapter5/section2/subsection6/View resource information.html","title":"查看资源信息","keywords":"","body":"查看资源信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection6/Submit a job with resource requirements.html":{"url":"chapter5/section2/subsection6/Submit a job with resource requirements.html","title":"提交具有资源需求的作业","keywords":"","body":"提交具有资源需求的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection6/Submit a job with start or termination times.html":{"url":"chapter5/section2/subsection6/Submit a job with start or termination times.html","title":"提交有开始或终止时间的作业","keywords":"","body":"提交有开始或终止时间的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection6/Submit a job with compute unit resource requirements.html":{"url":"chapter5/section2/subsection6/Submit a job with compute unit resource requirements.html","title":"提交具有计算单元资源要求的作业","keywords":"","body":"提交具有计算单元资源要求的作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section2/subsection7/Set pending time limits.html":{"url":"chapter5/section2/subsection7/Set pending time limits.html","title":"设置等待时间限制","keywords":"","body":"设置等待时间限制 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 14:24:04 "},"chapter5/section3/monitoring_jobs.html":{"url":"chapter5/section3/monitoring_jobs.html","title":"5.3 作业监控","keywords":"","body":"5.3 作业监控 View information about jobs Display resource allocation limits Use the blimits command to display resource allocation limits. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View information about jobs.html":{"url":"chapter5/section3/subsection1/View information about jobs.html","title":"查看有关作业的信息","keywords":"","body":"查看有关作业的信息 Procedure Use the bjobs and bhist commands to view information about jobs: bjobs reports the status of jobs and the various options allow you to display specific information. bhist reports the history of one or more jobs in the system. You can also find jobs on specific queues or hosts, find jobs that are submitted by specific projects, and check the status of specific jobs by using their job IDs or names. View unfinished jobs View summary information of unfinished jobs View all jobs View running jobs View pending reasons for jobs When you submit a job, it can be held in the queue before it starts running and it might be suspended while it is running. You can find out why jobs are pending or in suspension with the bjobs -p option. View job suspending reasons When you submit a job, it may be held in the queue before it starts running and it may be suspended while running. View detailed job information View job group information You can view information about jobs in job groups or view jobs by job group. Monitor SLA progress View job output View chronological history of jobs View history of jobs not listed in active event log View job history View the job submission environment Use the bjobs -env command option to view a job's environment variables or the bjobs -script command option to view the job script file. Update interval Job-level information © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View unfinished jobs.html":{"url":"chapter5/section3/subsection1/View unfinished jobs.html","title":"查看未完成的工作","keywords":"","body":"查看未完成的工作 Procedure Run bjobs to view the status of LSF jobs. When no options are specified, bjobs displays information about jobs in the PEND, RUN, USUSP, PSUSP, and SSUSP states for the current user. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View summary information of unfinished jobs.html":{"url":"chapter5/section3/subsection1/View summary information of unfinished jobs.html","title":"查看未完成的作业的摘要信息","keywords":"","body":"查看未完成的作业的摘要信息 Procedure Run bjobs -sum to view summary information on the status of LSF jobs. When no other options are specified, bjobs -sum displays the count of unfinished tasks for jobs in the following states: running (RUN), system suspended (SSUSP), user suspended (USUSP), pending (PEND), forwarded to remote clusters and pending (FWD_PEND), and UNKNOWN. Use bjobs -sum with other options (such as -m, -P, -q, and -u) to filter the results. For example, bjobs -sum -u user1 displays task counts just for user user1. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View all jobs.html":{"url":"chapter5/section3/subsection1/View all jobs.html","title":"查看所有作业","keywords":"","body":"查看所有作业 About this task You can display information about jobs that are both running and those recently finished (PEND, RUN, USUSP, PSUSP, SSUSP, DONE, and EXIT statuses). Procedure Run bjobs -a . All your jobs that are still in the system and jobs that have recently finished are displayed. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View running jobs.html":{"url":"chapter5/section3/subsection1/View running jobs.html","title":"查看正在运行的作业","keywords":"","body":"查看正在运行的作业 About this task You can display information about only jobs that are running (RUN status). Procedure Run bjobs -r. All your running jobs are displayed. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View pending reasons for jobs.html":{"url":"chapter5/section3/subsection1/View pending reasons for jobs.html","title":"查看在等待作业的原因","keywords":"","body":"查看在等待作业的原因 When you submit a job, it can be held in the queue before it starts running and it might be suspended while it is running. You can find out why jobs are pending or in suspension with the bjobs -p option. Procedure Run bjobs -p. Displays information for pending jobs (PEND state) and their reasons. There can be more than one reason why the job is pending. The pending reasons also display the number of hosts for each condition. To get specific host names along with pending reasons, run bjobs -lp. To view the pending reasons for all users, run bjobs -p -u all. Run bjobs -psum to display the summarized number of jobs, hosts, and occurrences for each pending reason. Run busers -w all to see the maximum pending job threshold for all users. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View job suspending reasons.html":{"url":"chapter5/section3/subsection1/View job suspending reasons.html","title":"查看作业暂停原因","keywords":"","body":"查看作业暂停原因 When you submit a job, it may be held in the queue before it starts running and it may be suspended while running. Procedure Run the bjobs -s command. Displays information for suspended jobs (SUSP state) and their reasons. There can be more than one reason why the job is suspended. The pending reasons also display the number of hosts for each condition. Run bjobs -ls to see detailed information about suspended jobs, including specific host names along with the suspend reason. The load threshold that caused LSF to suspend a job, together with the scheduling parameters, is displayed. NoteThe STOP_COND parameter affects the suspending reasons as displayed by the bjobs command. If theSTOP_COND parameter is specified in the queue and the loadStop thresholds are not specified, the suspending reasons for each individual load index are not displayed. To view the suspend reasons for all users, run bjobs -s -u all. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View detailed job information.html":{"url":"chapter5/section3/subsection1/View detailed job information.html","title":"查看详细的作业信息","keywords":"","body":"查看详细的作业信息 About this task The -l option of bjobs displays detailed information about job status and parameters, such as the job’s current working directory, parameters that are specified when the job was submitted, and the time when the job started running. bjobs -l with a job ID displays all the information about a job, including: Submission parameters Execution environment Resource usage Procedure Run bjobs -l. bjobs -l 7678 Job Id , User , Project , Status , Queue , Command Mon Oct 28 13:08:11 2009: Submitted from host ,CWD , Requested Resources 35>; PENDING REASONS: Queue’s resource requirements not satisfied:3 hosts; Unable to reach slave lsbatch server: 1 host; Not enough job slots: 1 host; SCHEDULING PARAMETERS: r15s r1m r15m ut pg io ls it tmp swp mem loadSched - 0.7 1.0 - 4.0 - - - - - - loadStop - 1.5 2.5 - 8.0 - - - - - - © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View job group information.html":{"url":"chapter5/section3/subsection1/View job group information.html","title":"查看作业组信息","keywords":"","body":"查看作业组信息 You can view information about jobs in job groups or view jobs by job group. Before you begin Procedure To see all job groups, run bjgroup. To see jobs by job group, run bjobs -g /group_name. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/Monitor SLA progress.html":{"url":"chapter5/section3/subsection1/Monitor SLA progress.html","title":"监测 SLA 进程","keywords":"","body":"监测 SLA 进程 About this task You can display the properties of service classes that are configured in lsb.serviceclasses and the dynamic state information for each service class. Procedure Run bsla Run bacct -sla to display historical performance of a service class. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View job output.html":{"url":"chapter5/section3/subsection1/View job output.html","title":"查看作业输出","keywords":"","body":"查看作业输出 Before you begin You must be logged on as the job owner. About this task The output from a job is normally not available until the job is finished. However, LSF provides the bpeek command for you to look at the output the job has produced so far. By default, bpeek shows the output from the most recently submitted job. You can also select the job by queue or execution host, or specify the job ID or job name on the command line. To save time, you can use this command to check whether your job is behaving as you expected and kill the job if it is running away or producing unusable results. Procedure Run bpeek job_id. Example For example: bpeek 1234 > Starting phase 1 Phase 1 done Calculating new parameters ... © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View chronological history of jobs.html":{"url":"chapter5/section3/subsection1/View chronological history of jobs.html","title":"查看作业的时间顺序历史","keywords":"","body":"查看作业的时间顺序历史 About this task By default, the bhist command displays information from the job event history file, lsb.events, on a per job basis. Procedure Use the -t option of bhist to display the events chronologically instead of grouping all events for each job. Use the -T option to select only those events within a given time range. Example For example, the following displays all events that occurred between 14:00 and 14:30 on a given day: bhist -t -T 14:00,14:30 Wed Oct 22 14:01:25 2009: Job done successfully; Wed Oct 22 14:03:09 2009: Job submitted from host to Queue , CWD , User , Project , Command , Requested Resources ; Wed Oct 22 14:03:18 2009: Job dispatched to ; Wed Oct 22 14:03:18 2009: Job starting (Pid 210); Wed Oct 22 14:03:18 2009: Job running with execution home , Execution CWD , Execution Pid ; Wed Oct 22 14:05:06 2009: Job submitted from host to Queue, CWD , User , Project , Command , Requested Resources ; Wed Oct 22 14:05:11 2009: Job dispatched to ; Wed Oct 22 14:05:11 2009: Job starting (Pid 429); Wed Oct 22 14:05:12 2009: Job running with execution home, Execution CWD , Execution Pid ; Wed Oct 22 14:08:26 2009: Job submitted from host to Queue, CWD , User , Project , Command; Wed Oct 22 14:10:55 2009: Job done successfully; Wed Oct 22 14:16:55 2009: Job exited; Wed Oct 22 14:17:04 2009: Job done successfully; © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View history of jobs not listed in active event log.html":{"url":"chapter5/section3/subsection1/View history of jobs not listed in active event log.html","title":"查看未在活动事件日志中列出的作业历史","keywords":"","body":"查看未在活动事件日志中列出的作业历史 About this task LSF periodically backs up and prunes the job history log. By default, bhist only displays job history from the current event log file. You can display the history for jobs that completed some time ago and are no longer listed in the active event log. The -n num_logfiles option tells the bhist command to search through the specified number of log files instead of only searching the current log file. Log files are searched in reverse time order. For example, the command bhist -n 3 searches the current event log file and then the two most recent backup files. Procedure Run bhist -n num_logfiles. Example bhist -n 1 ![复制代码](https://www.ibm.com/support/knowledgecenter/images/icons/copy.png) Searches the current event log file lsb.events bhist -n 2 ![复制代码](https://www.ibm.com/support/knowledgecenter/images/icons/copy.png) Searches lsb.events and lsb.events.1 bhist -n 3 ![复制代码](https://www.ibm.com/support/knowledgecenter/images/icons/copy.png) Searches lsb.events, lsb.events.1, lsb.events.2 bhist -n 0 ![复制代码](https://www.ibm.com/support/knowledgecenter/images/icons/copy.png) Searches all event log files in LSB_SHAREDIR © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View job history.html":{"url":"chapter5/section3/subsection1/View job history.html","title":"查看作业历史记录","keywords":"","body":"查看作业历史记录 About this task You can check on the status of your job since it was submitted. The bhist command displays a summary of the pending, suspended, and running time of jobs for the user who invoked the command. Procedure Run bhist. Run bhist -l to display the time information and a complete history of scheduling events for each job. Use bhist -u all to display a summary for all users in the cluster. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/View the job submission environment.html":{"url":"chapter5/section3/subsection1/View the job submission environment.html","title":"查看作业提交环境","keywords":"","body":"查看作业提交环境 Use the bjobs -env command option to view a job's environment variables or the bjobs -script command option to view the job script file. About this task You cannot specify the options with the-envor-scriptoptions. Procedure To view the environment variables for a specified job, run the bjobs -env command option. bjobs -env job_id You must specify a single job ID or job array element when using the -env command option. Multiple job IDs are not supported. To view the specified job's job script file, run the bjobs -script command option. bjobs -script job_id You must specify a single job ID or job array element when using the -script command option. Job arrays and multiple job IDs are not supported. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/Update interval.html":{"url":"chapter5/section3/subsection1/Update interval.html","title":"更新间隔","keywords":"","body":"更新间隔 The job-level resource usage information is updated at a maximum frequency of every SBD_SLEEP_TIME second. The update is done only if the value for the CPU time, resident memory usage, or virtual memory usage has changed by more than 10 percent from the previous update or if a new process or process group has been created. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection1/Job-level information.html":{"url":"chapter5/section3/subsection1/Job-level information.html","title":"作业级别信息","keywords":"","body":"作业级别信息 Job-level information includes: Total CPU time consumed by all processes of a job Total resident memory usage in KB of all currently running processes of a job Total virtual memory usage in KB of all currently running processes of a job Currently active process group ID of a job Currently active processes of a job © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection2/Display resource allocation limits.html":{"url":"chapter5/section3/subsection2/Display resource allocation limits.html","title":"显示资源分配限制","keywords":"","body":"显示资源分配限制 Use the blimits command to display resource allocation limits. The Configured policy name and information for limits that are being applied to running jobs. Configured policy name and information for all limits, even if they are not being applied to running jobs (-a option). Users (-u option) Queues (-q option) Hosts (-m option) Project names (-P option) All resource configurations in lsb.resources (-c option). This option is the same as bresources with no options. Resources that have no configured limits or no limit usage are indicated by a dash (-). Limits are displayed in a USED/LIMIT format. For example, if a limit of 10 slots is configured and 3 slots are in use, then blimits displays the limit for SLOTS as 3/10. If limits MEM, SWP, or TMP are configured as percentages, both the limit and the amount that is used are displayed in MB. For example, lshosts displays maximum memory (maxmem) of 249 MB, and MEM is limited to 10% of available memory. If 10 MB out of are used, blimits displays the limit for MEM as 10/25 (10 MB USED from a 25 MB LIMIT). Configured limits and resource usage for built-in resources (slots, mem, tmp, and swp load indices) are displayed as INTERNAL RESOURCE LIMITS separately from custom external resources, which are shown as EXTERNAL RESOURCE LIMITS. Limits are displayed for both the vertical tabular format and the horizontal format for Limit sections. If a vertical format Limit section has no name, blimits displays NONAMEnnn under the NAME column for these limits, where the unnamed limits are numbered in the order the vertical-format Limit sections appear in the lsb.resources file. If a resource consumer is configured as all, the limit usage for that consumer is indicated by a dash (-). PER_HOST slot limits are not displayed. The bhosts command displays these limits as MXJ limits. In MultiCluster, blimits returns the information about all limits in the local cluster. View information about resource allocation limits © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter5/section3/subsection2/View information about resource allocation limits.html":{"url":"chapter5/section3/subsection2/View information about resource allocation limits.html","title":"查看有关资源分配限制的信息","keywords":"","body":"查看有关资源分配限制的信息 About this task Your job may be pending because some configured resource allocation limit has been reached. You can display the dynamic counters of resource allocation limits configured in the Limit sections in lsb.resources. Procedure Run blimits to display the current resource usage, including any limits that may be blocking your job. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/Administer_LSF.html":{"url":"chapter6/Administer_LSF.html","title":"Chapter 6 LSF 集群维护管理","keywords":"","body":"Chapter 6 LSF 集群维护管理 了解如何管理 IBM Spectrum LSF 集群，如何控制守护程序，更改集群配置以及如何使用主机和队列。管理您的LSF 作业和作业调度策略。查看工作信息并控制工作。 了解如何为 LSF 作业配置和分配资源。 了解如何在 LSF 群集中提交，监视和控制高吞吐量和并行工作负载。 了解有关 LSF 错误和事件日志记录，以及 LSF 如何处理作业异常的信息。 调整 LSF 集群的性能和可伸缩性。 IBM Spectrum LSF 集群管理要点 了解如何管理 LSF 集群，控制守护程序，更改集群配置以及使用主机，队列和用户。 监视 IBM Spectrum LSF 集群操作和运行状况 了解如何监视集群性能，作业资源使用情况以及有关队列，作业和用户的其他信息。 管理 IBM Spectrum LSF 作业执行 了解如何管理 LSF 作业和作业调度策略。 查看作业信息，控制作业，并管理作业相关性，作业优先级，作业阵列，交互式作业，作业预处理和后处理，以及作业启动器。 配置和共享 IBM Spectrum LSF 作业资源 了解如何为 LSF 作业配置和分配资源。 在用户和项目之间公平地共享计算资源。 将资源分配限制应用于作业，管理主机和用户组，保留资源并指定作业的资源要求。 GPU 资源 了解如何为 LSF 作业配置和使用 GPU 资源。 使用 LSF 配置容器 为容器配置和使用 LSF 集成。 管理 IBM Spectrum LSF 的高吞吐量工作负载 了解如何在 LSF 集群中提交，监视和控制高吞吐量工作负载。 配置调度策略，以实现对短期作业的有效排队，调度和执行。 管理 IBM Spectrum LSF 并行工作负载 了解如何在 LSF 集群中提交，监视和控制并行工作负载。 配置保留资源的调度策略，以保证大型并行作业高效执行。 IBM Spectrum LSF 安全性 了解如何优化 LSF 集群的安全性。 IBM Spectrum LSF 高级配置 了解关于 LSF 错误和事件日志记录以及 LSF 如何处理作业异常的信息。 配置高级 LSF 功能。 IBM Spectrum LSF 性能调优 调整 LSF 集群的性能和可伸缩性。 IBM Spectrum LSF 能源感知调度 在大规模 LSF 安装中配置，管理和使用 IBM Spectrum LSF 能源感知调度功能，其中运行大型系统的能源需求，已成为这些系统总体成本的重要因素。 IBM Spectrum LSF 多集群功能 了解如何使用和管理 IBM Spectrum LSF 多集群功能，来实现跨 LSF 集群之间的资源共享。 IBM Spectrum LSF 高级版 配置和使用 IBM Spectrum LSF 高级版本（LSF Advanced Edition）。 学习使用专为具有高性能工作负载要求的大型集群，而设计的 LSF 的高级功能。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section1/Cluster management essentials.html":{"url":"chapter6/section1/Cluster management essentials.html","title":"6.1 集群管理要点","keywords":"","body":"6.1 Cluster management essentials © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section1/subsection1/Work with your cluster.html":{"url":"chapter6/section1/subsection1/Work with your cluster.html","title":"集群的使用","keywords":"","body":"集群的使用 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section1/subsection2/Working with hosts.html":{"url":"chapter6/section1/subsection2/Working with hosts.html","title":"主机节点的使用","keywords":"","body":"主机节点的使用 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section1/subsection3/Job directories and data.html":{"url":"chapter6/section1/subsection3/Job directories and data.html","title":"作业目录与数据","keywords":"","body":"作业目录与数据 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section1/subsection4/Job notification.html":{"url":"chapter6/section1/subsection4/Job notification.html","title":"作业通知","keywords":"","body":"作业通知 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section2/Monitoring cluster operations and health.html":{"url":"chapter6/section2/Monitoring cluster operations and health.html","title":"6.2 监视集群操作和运行状况","keywords":"","body":"6.2 Monitoring cluster operations and health © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section2/subsection1/Monitor cluster performance.html":{"url":"chapter6/section2/subsection1/Monitor cluster performance.html","title":"监控集群性能","keywords":"","body":"监控集群性能 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section2/subsection2/Monitor job information.html":{"url":"chapter6/section2/subsection2/Monitor job information.html","title":"监控作业信息","keywords":"","body":"监控作业信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section2/subsection3/Monitor applications by using external scripts.html":{"url":"chapter6/section2/subsection3/Monitor applications by using external scripts.html","title":"使用外部脚本监控应用","keywords":"","body":"使用外部脚本监控应用 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section2/subsection4/View resource information.html":{"url":"chapter6/section2/subsection4/View resource information.html","title":"查看资源信息","keywords":"","body":"查看资源信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section2/subsection5/View user and user group information.html":{"url":"chapter6/section2/subsection5/View user and user group information.html","title":"查看用户和用户组的信息","keywords":"","body":"查看用户和用户组的信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section2/subsection6/View queue information.html":{"url":"chapter6/section2/subsection6/View queue information.html","title":"查看队列信息","keywords":"","body":"查看队列信息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section3/Managing job execution.html":{"url":"chapter6/section3/Managing job execution.html","title":"6.3 管理作业执行","keywords":"","body":"6.3 Managing job execution © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section3/subsection1/Managing job execution.html":{"url":"chapter6/section3/subsection1/Managing job execution.html","title":"管理作业执行","keywords":"","body":"管理作业执行 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section3/subsection2/Job file spooling.html":{"url":"chapter6/section3/subsection2/Job file spooling.html","title":"作业文件假脱机","keywords":"","body":"作业文件假脱机 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section3/subsection3/Job data management.html":{"url":"chapter6/section3/subsection3/Job data management.html","title":"作业数据管理","keywords":"","body":"作业数据管理 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section3/subsection4/Job scheduling and dispatch.html":{"url":"chapter6/section3/subsection4/Job scheduling and dispatch.html","title":"作业调度与分配","keywords":"","body":"作业调度与分配 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section3/subsection5/Control job execution.html":{"url":"chapter6/section3/subsection5/Control job execution.html","title":"控制作业执行","keywords":"","body":"控制作业执行 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section3/subsection6/Interactive jobs and remote tasks.html":{"url":"chapter6/section3/subsection6/Interactive jobs and remote tasks.html","title":"交互式作业和远程任务","keywords":"","body":"交互式作业和远程任务 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section4/Configuring and sharing job resources.html":{"url":"chapter6/section4/Configuring and sharing job resources.html","title":"6.4 配置和共享工作资源","keywords":"","body":"6.4 Configuring and sharing job resources © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section4/subsection1/About LSF resources.html":{"url":"chapter6/section4/subsection1/About LSF resources.html","title":"关于 LSF 资源","keywords":"","body":"关于 LSF 资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section4/subsection2/Representing job resources in LSF.html":{"url":"chapter6/section4/subsection2/Representing job resources in LSF.html","title":"在 LSF 中代表作业资源","keywords":"","body":"在 LSF 中代表作业资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section4/subsection3/Plan-based scheduling and reservations.html":{"url":"chapter6/section4/subsection3/Plan-based scheduling and reservations.html","title":"基于计划的调度与预留","keywords":"","body":"基于计划的调度与预留 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section4/subsection4/Distributing job resources to users in LSF.html":{"url":"chapter6/section4/subsection4/Distributing job resources to users in LSF.html","title":"在 LSF 中向用户分配作业资源","keywords":"","body":"在 LSF 中向用户分配作业资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section5/GPU resources.html":{"url":"chapter6/section5/GPU resources.html","title":"6.5 GPU 资源","keywords":"","body":"6.5 GPU resources © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section5/subsection1/Enabling GPU features.html":{"url":"chapter6/section5/subsection1/Enabling GPU features.html","title":"启用 GPU 资源","keywords":"","body":"启用 GPU 资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section5/subsection2/Monitoring GPU resources.html":{"url":"chapter6/section5/subsection2/Monitoring GPU resources.html","title":"监控 GPU 资源","keywords":"","body":"监控 GPU 资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section5/subsection3/Submitting and monitoring GPU jobs.html":{"url":"chapter6/section5/subsection3/Submitting and monitoring GPU jobs.html","title":"提交和监视 GPU 作业","keywords":"","body":"提交和监视 GPU 作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section5/subsection4/GPU features using ELIM.html":{"url":"chapter6/section5/subsection4/GPU features using ELIM.html","title":"使用 ELIM 的 GPU 功能","keywords":"","body":"使用 ELIM 的 GPU 功能 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section6/Configuring containers.html":{"url":"chapter6/section6/Configuring containers.html","title":"6.6 配置容器","keywords":"","body":"6.6 Configuring containers © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section6/subsection1/LSF with Docker.html":{"url":"chapter6/section6/subsection1/LSF with Docker.html","title":"LSF 与 Docker","keywords":"","body":"LSF 与 Docker © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section6/subsection2/LSF with Shifter.html":{"url":"chapter6/section6/subsection2/LSF with Shifter.html","title":"LSF 与 Shifter","keywords":"","body":"LSF 与 Shifter © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section6/subsection3/LSF with Singularity.html":{"url":"chapter6/section6/subsection3/LSF with Singularity.html","title":"LSF 与 Singularity","keywords":"","body":"LSF 与 Singularity © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section7/High throughput workload administration.html":{"url":"chapter6/section7/High throughput workload administration.html","title":"6.7 高吞吐量作业负载管理","keywords":"","body":"6.7 High throughput workload administration © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section7/subsection1/Job packs.html":{"url":"chapter6/section7/subsection1/Job packs.html","title":"作业包","keywords":"","body":"作业包 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section7/subsection2/Job arrays.html":{"url":"chapter6/section7/subsection2/Job arrays.html","title":"作业阵列","keywords":"","body":"作业阵列 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section7/subsection3/Fairshare scheduling.html":{"url":"chapter6/section7/subsection3/Fairshare scheduling.html","title":"公平共享调度","keywords":"","body":"公平共享调度 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section7/subsection4/Guaranteed resource pools.html":{"url":"chapter6/section7/subsection4/Guaranteed resource pools.html","title":"有保证的资源池","keywords":"","body":"有保证的资源池 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section7/subsection5/Reserving memory and license resources.html":{"url":"chapter6/section7/subsection5/Reserving memory and license resources.html","title":"保留内存和许可证资源","keywords":"","body":"保留内存和许可证资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section8/Parallel workload administration.html":{"url":"chapter6/section8/Parallel workload administration.html","title":"6.8 并行作业负载管理","keywords":"","body":"6.8 Parallel workload administration © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section8/subsection1/Running parallel jobs.html":{"url":"chapter6/section8/subsection1/Running parallel jobs.html","title":"运行并行作业","keywords":"","body":"运行并行作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section8/subsection2/Advance reservation.html":{"url":"chapter6/section8/subsection2/Advance reservation.html","title":"提前预定","keywords":"","body":"提前预定 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section8/subsection3/Fairshare scheduling.html":{"url":"chapter6/section8/subsection3/Fairshare scheduling.html","title":"公平共享调度","keywords":"","body":"公平共享调度 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section8/subsection4/Job checkpoint and restart.html":{"url":"chapter6/section8/subsection4/Job checkpoint and restart.html","title":"作业检查点与重启动","keywords":"","body":"作业检查点与重启动 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section8/subsection5/Job migration for checkpointable and rerunnable jobs.html":{"url":"chapter6/section8/subsection5/Job migration for checkpointable and rerunnable jobs.html","title":"可检查和可重新运行作业的作业迁移","keywords":"","body":"可检查和可重新运行作业的作业迁移 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section8/subsection6/Resizable jobs.html":{"url":"chapter6/section8/subsection6/Resizable jobs.html","title":"可调整作业","keywords":"","body":"可调整作业 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section9/Security in LSF.html":{"url":"chapter6/section9/Security in LSF.html","title":"6.9 LSF 中的安全性","keywords":"","body":"6.9 Security in LSF © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section9/subsection1/Security considerations.html":{"url":"chapter6/section9/subsection1/Security considerations.html","title":"安全注意事项","keywords":"","body":"安全注意事项 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section9/subsection2/Secure your LSF cluster.html":{"url":"chapter6/section9/subsection2/Secure your LSF cluster.html","title":"保证 LSF 集群的安全","keywords":"","body":"保证 LSF 集群的安全 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/Advanced configuration.html":{"url":"chapter6/section10/Advanced configuration.html","title":"6.10 进阶设定","keywords":"","body":"6.10 Advanced configuration © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section10/subsection1/Error and event logging.html":{"url":"chapter6/section10/subsection1/Error and event logging.html","title":"错误与事件记录","keywords":"","body":"错误与事件记录 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection2/Event generation.html":{"url":"chapter6/section10/subsection2/Event generation.html","title":"事件产生","keywords":"","body":"事件产生 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection3/Customize batch command messages.html":{"url":"chapter6/section10/subsection3/Customize batch command messages.html","title":"自定义批处理命令消息","keywords":"","body":"自定义批处理命令消息 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection4/How LIM determines host models and types.html":{"url":"chapter6/section10/subsection4/How LIM determines host models and types.html","title":"LIM 如何确定主机型号与类型","keywords":"","body":"LIM 如何确定主机型号与类型 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection5/Shared file access.html":{"url":"chapter6/section10/subsection5/Shared file access.html","title":"共享文件访问","keywords":"","body":"共享文件访问 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection6/Shared configuration file content.html":{"url":"chapter6/section10/subsection6/Shared configuration file content.html","title":"共享的配置文件","keywords":"","body":"共享的配置文件 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection7/Authentication and authorization.html":{"url":"chapter6/section10/subsection7/Authentication and authorization.html","title":"认证与授权","keywords":"","body":"认证与授权 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection8/Handle job exceptions.html":{"url":"chapter6/section10/subsection8/Handle job exceptions.html","title":"处理作业异常","keywords":"","body":"处理作业异常 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection9/Tune CPU factors.html":{"url":"chapter6/section10/subsection9/Tune CPU factors.html","title":"调节 CPU 参数","keywords":"","body":"调节 CPU 参数 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection10/Set clean period for DONE jobs.html":{"url":"chapter6/section10/subsection10/Set clean period for DONE jobs.html","title":"为完成的作业设置清理周期","keywords":"","body":"为完成的作业设置清理周期 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection11/Enable host-based resources.html":{"url":"chapter6/section10/subsection11/Enable host-based resources.html","title":"启用基于主机的资源","keywords":"","body":"启用基于主机的资源 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection12/Global fairshare scheduling.html":{"url":"chapter6/section10/subsection12/Global fairshare scheduling.html","title":"全局公平共享调度","keywords":"","body":"全局公平共享调度 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection13/Manage LSF on EGO.html":{"url":"chapter6/section10/subsection13/Manage LSF on EGO.html","title":"在 EGO 中管理 LSF","keywords":"","body":"在 EGO 中管理 LSF © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection14/Load sharing X applications.html":{"url":"chapter6/section10/subsection14/Load sharing X applications.html","title":"负载共享 X 应用","keywords":"","body":"负载共享 X 应用 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection15/Using LSF with the Etnus TotalView Debugger.html":{"url":"chapter6/section10/subsection15/Using LSF with the Etnus TotalView Debugger.html","title":"将 LSF 与 Etnus TotalView 调试器一起使用","keywords":"","body":"将 LSF 与 Etnus TotalView 调试器一起使用 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section10/subsection16/Register LSF host names and IP addresses to LSF servers.html":{"url":"chapter6/section10/subsection16/Register LSF host names and IP addresses to LSF servers.html","title":"将 LSF 主机名和 IP 地址注册到 LSF 服务器","keywords":"","body":"将 LSF 主机名和 IP 地址注册到 LSF 服务器 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/sectio11/Performance tuning.html":{"url":"chapter6/sectio11/Performance tuning.html","title":"6.11 性能调优","keywords":"","body":"6.11 Performance tuning © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section11/subsection1/Tune your cluster.html":{"url":"chapter6/section11/subsection1/Tune your cluster.html","title":"对集群进行调优","keywords":"","body":"对集群进行调优 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section11/subsection2/Achieve performance and scalability.html":{"url":"chapter6/section11/subsection2/Achieve performance and scalability.html","title":"实现性能和可扩展性","keywords":"","body":"实现性能和可扩展性 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section12/Energy aware scheduling.html":{"url":"chapter6/section12/Energy aware scheduling.html","title":"6.12 能量感知调度","keywords":"","body":"6.12 Energy aware scheduling © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section12/subsection1/Managing host power states.html":{"url":"chapter6/section12/subsection1/Managing host power states.html","title":"管理主机电源状态","keywords":"","body":"管理主机电源状态 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section12/subsection2/CPU frequency management.html":{"url":"chapter6/section12/subsection2/CPU frequency management.html","title":"CPU 频率管理","keywords":"","body":"CPU 频率管理 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section12/subsection3/Automatic CPU frequency selection.html":{"url":"chapter6/section12/subsection3/Automatic CPU frequency selection.html","title":"自动 CPU 频率选择","keywords":"","body":"自动 CPU 频率选择 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section13/LSF multicluster capability.html":{"url":"chapter6/section13/LSF multicluster capability.html","title":"6.13 LSF 多集群功能","keywords":"","body":"6.13 LSF multicluster capability © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section13/subsection1/Overview of LSF multicluster capability.html":{"url":"chapter6/section13/subsection1/Overview of LSF multicluster capability.html","title":"LSF 多集群功能概述","keywords":"","body":"LSF 多集群功能概述 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section13/subsection2/Set up LSF multicluster capability.html":{"url":"chapter6/section13/subsection2/Set up LSF multicluster capability.html","title":"设置 LSF 多集群功能","keywords":"","body":"设置 LSF 多集群功能 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section13/subsection3/Job forwarding model.html":{"url":"chapter6/section13/subsection3/Job forwarding model.html","title":"作业转发模型","keywords":"","body":"作业转发模型 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section13/subsection4/Resource leasing model.html":{"url":"chapter6/section13/subsection4/Resource leasing model.html","title":"资源租赁模型","keywords":"","body":"资源租赁模型 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section14/LSF Advanced Edition.html":{"url":"chapter6/section14/LSF Advanced Edition.html","title":"6.14 LSF 高级版","keywords":"","body":"6.14 LSF Advanced Edition © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter6/section14/subsection1/Overview of LSF Advanced Edition.html":{"url":"chapter6/section14/subsection1/Overview of LSF Advanced Edition.html","title":"LSF 高级版概述","keywords":"","body":"LSF 高级版概述 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section14/subsection2/Set up LSF Advanced Edition.html":{"url":"chapter6/section14/subsection2/Set up LSF Advanced Edition.html","title":"设置 LSF 高级版","keywords":"","body":"设置 LSF 高级版 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section14/subsection3/Configure LSF Advanced Edition features.html":{"url":"chapter6/section14/subsection3/Configure LSF Advanced Edition features.html","title":"配置 LSF Advanced Edition 功能","keywords":"","body":"配置 LSF Advanced Edition 功能 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section14/subsection4/Using LSF Advanced Edition.html":{"url":"chapter6/section14/subsection4/Using LSF Advanced Edition.html","title":"使用 LSF 高级版","keywords":"","body":"使用 LSF 高级版 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter6/section14/subsection5/Reference for LSF Advanced Edition.html":{"url":"chapter6/section14/subsection5/Reference for LSF Advanced Edition.html","title":"LSF 高级版参考","keywords":"","body":"LSF 高级版参考 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 09:32:40 "},"chapter7/Reference.html":{"url":"chapter7/Reference.html","title":"Chapter 7 参考文档","keywords":"","body":"Chapter 7 参考文档 LSF 命令和配置参数的参考信息。 IBM Spectrum LSF 命令参考 IBM Spectrum LSF命令的参考。 IBM Spectrum LSF 配置参考 了解 IBM Spectrum LSF 的相关功能，文件，事件和环境变量的配置参数。 IBM Spectrum LSF API 参考 请参阅对 IBM Spectrum LSF API 的全面参考。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section1/Command_reference.html":{"url":"chapter7/section1/Command_reference.html","title":"7.1 命令参考","keywords":"","body":"7.1 命令参考 IBM Spectrum LSF命令的参考。 bacct Displays accounting statistics about finished jobs. badmin The badmin command is the administrative tool for LSF. bapp Displays information about application profile configuration. battach Runs a shell process to connect to an existing job execution host or container. battr Provides a set of subcommands to manage LSF host attributes for attribute affinity scheduling. bbot Moves a pending job to the bottom of the queue relative to the last job in the queue. bchkpnt Checkpoints one or more checkpointable jobs bclusters Displays information about IBM Spectrum LSF multicluster capability bconf Submits live reconfiguration requests, updating configuration settings in active memory without restarting daemons. bdata Provides a set of subcommands to query and manage IBM Spectrum LSF Data Manager. If no subcommands are supplied, bdata displays the command usage. bentags Queries or removes information about the energy policy tag from the mbatchd daemon, which is saved in the energy-aware scheduling database. Used with energy policy, or energy aware scheduling feature. bgadd Creates job groups bgdel Deletes job groups bgmod Modifies job groups bgpinfo Displays information about global fairshare. bhist Displays historical information about jobs bhosts Displays hosts and their static and dynamic resources bhpart Displays information about host partitions bimages Displays information on Docker container images bjdepinfo Displays job dependencies. bjgroup Displays information about job groups bjobs Displays and filters information about LSF jobs. Specify one or more job IDs (and, optionally, an array index list) to display information about specific jobs (and job arrays). bkill Sends signals to kill, suspend, or resume unfinished jobs bladmin Administrative tool for IBM Spectrum LSF License Scheduler. blaunch Launches parallel tasks on a set of hosts. blcollect License information collection daemon for LSF License Scheduler. The blcollect daemon collects license usage information. blcstat Displays dynamic update information from the blcollect daemon for LSF License Scheduler. blhosts Displays the names of all the hosts that are running the LSF License Scheduler daemon (bld). blimits Displays information about resource allocation limits of running jobs. blinfo Displays static LSF License Scheduler configuration information blkill Terminates an interactive (taskman) LSF License Scheduler task. blparams Displays information about configurable LSF License Scheduler parameters that are defined in the files lsf.licensescheduler and lsf.conf blstat Displays dynamic license information. bltasks Displays LSF License Scheduler interactive task information. blusers Displays license usage information for LSF License Scheduler. bmgroup Displays information about host groups and compute units. bmig Migrates checkpointable or rerunnable jobs. bmod Modifies job submission options of a job. bparams Displays information about configurable system parameters in the lsb.params file. bpeek Displays the stdout and stderr output of an unfinished job. bpost Sends external status messages and attaches data files to a job. bqueues Displays information about queues. bread Reads messages and attached data files from a job. brequeue Kills and requeues a job. bresize Decreases or increases tasks that are allocated to a running resizable job, or cancels pending job resize allocation requests. bresources Displays information about resource reservation, resource limits, and guaranteed resource policies. brestart Restarts checkpointed jobs. bresume Resumes one or more suspended jobs. brlainfo Displays host topology information. brsvadd Adds an advance reservation. brsvdel Deletes an advance reservation. brsvjob Shows information about jobs submitted with the brsvsub command to a specific advance reservation. brsvmod Modifies an advance reservation. brsvs Displays advance reservations. brsvsub Creates a dynamically scheduled reservation and submits a job to fill the advance reservation when the resources required by the job are available. brun Forces a job to run immediately. bsla Displays information about service classes. Service classes are used in guaranteed resource policies and service-level agreement (SLA) scheduling. bslots Displays slots available and backfill windows available for backfill jobs. bstage Stages data files for jobs with data requirements by copying files or creating symbolic links for them between the local staging cache and the job execution environment. You must run bstage only within the context of an LSF job (like blaunch). To access a file with the bstage command, you must have permission to read it. bstatus Gets current external job status or sets new job status. bstop Suspends unfinished jobs. bsub Submits a job to LSF by running the specified command and its arguments. bswitch Switches unfinished jobs from one queue to another. btop Moves a pending job relative to the first job in the queue. bugroup Displays information about user groups. busers Displays information about users and user groups. bwait Pauses and waits for the job query condition to be satisfied. ch Changes the host where subsequent commands run. gpolicyd Displays LSF global policy daemon information. lim Load information manager (LIM) daemon or service, monitoring host load. lsacct Displays accounting statistics on finished RES tasks in the LSF system. lsacctmrg Merges LSF RES task log files. lsadmin Administrative tool to control LIM and RES daemon operations in LSF. lsclusters Displays configuration information about LSF clusters. lseligible Displays whether a task is eligible for remote execution. lsfinstall The LSF installation and configuration script. lsfmon Install or uninstall LSF Monitor in an existing cluster. lsfrestart Restarts the LIM, RES, sbatchd, and mbatchd daemons on all hosts in the cluster lsfshutdown Shuts down the LIM, RES, sbatchd, and mbatchd daemons on all hosts in the cluster. lsfstartup Starts the LIM, RES, and sbatchd daemons on all hosts in the cluster. lsgrun Runs a task on a group of hosts. lshosts Displays hosts and their static resource information. lsid Displays the LSF version number, the cluster name, and the master host name. lsinfo Displays LSF configuration information. lsload Displays load information for hosts. lsloadadj Adjusts load indices on hosts. lslogin Remotely logs in to a lightly loaded host. lsltasks Displays or updates a local task list. lsmake Runs LSF make tasks in parallel. lsmon Displays load information for LSF hosts and periodically updates the display. lspasswd Registers Windows user passwords in LSF. Passwords must be 3 - 23 characters long. lsplace Displays hosts available to run tasks. lsportcheck Displays ports that LSF is currently using or the LSF ports that will be used before starting LSF. lsrcp Remotely copies files through LSF. lsreghost (UNIX) UNIX version of the lsreghost command registers UNIX LSF host names and IP addresses with LSF servers so that LSF servers can internally resolve these hosts without requiring a DNS server. lsreghost (Windows) Windows version of the lsreghost command registers Windows LSF host names and IP addresses with LSF servers so that LSF servers can internally resolve these hosts without requiring a DNS server. lsrtasks Displays or updates a remote task list. lsrun Runs an interactive task through LSF. lstcsh Load sharing tcsh for LSF pam Parallel Application Manager – job starter for MPI applications patchinstall UNIX only. Manage patches in LSF cluster. pversions (UNIX) UNIX version of the command. Displays the version information for IBM Spectrum LSF installed on UNIX hosts. pversions (Windows) Windows version of the command. Displays the version information for IBM Spectrum LSF installed on a Windows host. ssacct Displays accounting statistics about finished LSF session scheduler jobs. ssched Submit tasks through LSF session scheduler. taskman Checks out a license token and manages interactive UNIX applications. tspeek Displays the stdout and stderr output of an unfinished Terminal Services job. tssub Submits a Terminal Services job to LSF. wgpasswd Changes a user’s password for a Microsoft Windows workgroup. wguser Modifies user accounts for a Microsoft Windows workgroup © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section1/subsection1/bdata.html":{"url":"chapter7/section1/subsection1/bdata.html","title":"bdata","keywords":"","body":"bdata Provides a set of subcommands to query and manage IBM Spectrum LSF Data Manager. If no subcommands are supplied, bdata displays the command usage. Synopsis LSF data management subcommands and option syntax synopsis Subcommands LSF data management subcommands and options Help and version options IBM Spectrum LSF Data Manager help and version display options See also bhist, bjobs, bmod, bstage, bsub, lsf.conf, lsf.datamanager © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 12:57:22 "},"chapter7/section1/subsection1/Synopsis.html":{"url":"chapter7/section1/subsection1/Synopsis.html","title":"Synopsis","keywords":"","body":"Synopsis LSF data management subcommands and option syntax synopsis bdata subcommand options bdata [-h[elp] | -V] © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 12:57:30 "},"chapter7/section1/subsection1/Subcommands.html":{"url":"chapter7/section1/subsection1/Subcommands.html","title":"Subcommands","keywords":"","body":"Subcommands LSF data management subcommands and options File-based cache query: bdata cache [-w | -l] [-u all | -u user_name] [-g all | -g user_group_name] [-dmd cluster_name] [host_name**:*]abs_file_path* Job-based cache query: bdata cache [-dmd cluster_name] [-w | -l] job_ID[@*cluster_name*] Job-based cache query: bdata cache [-dmd cluster_name] [-w | -l] job_ID[@*cluster_name*] Change group after stage out: bdata chgrp [-dmd cluster_name] -g user_group_name [host_name**:*]abs_file_path* Change group after stage in: bdata chgrp [-dmd cluster_name] -g user_group_name -tag tag_name Change the file permission mode of a file: bdata chmod [-dmd cluster_name] -mode octal_mode -mode [host_name**:*]abs_file_path* Tag query: bdata tags list [-w] [-u all | -u user_name] [-dmd cluster_name] Tag cleanup: bdata tags clean [-u user_name] [-dmd cluster_name] tag_name Effective configuration query: bdata showconf Connections query: bdata connections [-w] Administration - reconfigure and shut down LSF data manager: bdata admin reconfig bdata admin shutdown [host_name] Common options -w Wide format. Displays the information in a wide format. Use this option only with the cache, connections, and tags list subcommands. -l Long format. Displays additional information about LSF data management files. Use this option only with the cache subcommand. -dmd cluster_name Query the LSF data manager corresponding to the specified remote cluster. Use this option only with the cache, and tags subcommands. -u all | -u user_name Query files in the cache for the specified user. Use -u all or -u user_name with file-based bdata cache and bdata tags list. You can use only -u user_name with bdata tags clean. cache Queries the LSF data management cache. chgrp Changes the user group of a file in the LSF data management cache. chmod Changes the file permission mode of a file that is staged in to the LSF data management cache. tags LSF data management tag query and cleanup options showconf LSF data management effective configuration query option connections Query LSF data management connections. Lists currently connected mbatchd daemons, with master LSF data manager host names, their status, and the outgoing and incoming connections for remote LSF data managers. admin Reconfigure and shut down the LSF data manager daemon (dmd). © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 12:58:11 "},"chapter7/section1/subsection1/Help and version display.html":{"url":"chapter7/section1/subsection1/Help and version display.html","title":"Help and version display","keywords":"","body":"Help and version display IBM Spectrum LSF Data Manager help and version display options bdata [-h[elp] | -V] -h[help] Displays the command usage of the bdata command to stderr and exits. -V Prints the IBM Spectrum LSF Data Manager release version to stderr and exits. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 12:58:23 "},"chapter7/section1/subsection1/See also.html":{"url":"chapter7/section1/subsection1/See also.html","title":"See also","keywords":"","body":"See also bhist, bjobs, bmod, bstage, bsub, lsf.conf, lsf.datamanager © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 12:58:33 "},"chapter7/section1/subsection2/bjobs.html":{"url":"chapter7/section1/subsection2/bjobs.html","title":"bjobs","keywords":"","body":"bjobs © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 12:58:47 "},"chapter7/section1/subsection2/Categories.html":{"url":"chapter7/section1/subsection2/Categories.html","title":"Categories","keywords":"","body":"Categories © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection2/Categories_filter.html":{"url":"chapter7/section1/subsection2/Categories_filter.html","title":"Category: filter","keywords":"","body":"Category: filter © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection2/Categories_format.html":{"url":"chapter7/section1/subsection2/Categories_format.html","title":"Category: format","keywords":"","body":"Category: format © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection2/Categories_state.html":{"url":"chapter7/section1/subsection2/Categories_state.html","title":"Category: state","keywords":"","body":"Category: state © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection2/Options.html":{"url":"chapter7/section1/subsection2/Options.html","title":"Options","keywords":"","body":"Options © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection2/Description.html":{"url":"chapter7/section1/subsection2/Description.html","title":"Description","keywords":"","body":"Description © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection3/bstage.html":{"url":"chapter7/section1/subsection3/bstage.html","title":"bstage","keywords":"","body":"bstage Stages data files for jobs with data requirements by copying files or creating symbolic links for them between the local staging cache and the job execution environment. You must run bstage only within the context of an LSF job (like blaunch). To access a file with the bstage command, you must have permission to read it. bstage in Stages in data files for jobs with data requirements. bstage copies or symbolically links files from the data manager staging area to the job execution host. bstage out Stages out data files for jobs with data requirements. The bstage command copies or creates symbolic links to files from the job current working directory to the data management cache, then requests a transfer job to copy the file or folder to a host. Help and version options IBM Spectrum LSF Data Manager help and version display options See also bdata, bhist, bjobs, bmod, bsub, lsf.conf, lsf.datamanager © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:02:05 "},"chapter7/section1/subsection3/bstage_in.html":{"url":"chapter7/section1/subsection3/bstage_in.html","title":"bstage in","keywords":"","body":"bstage in © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection3/bstage_out.html":{"url":"chapter7/section1/subsection3/bstage_out.html","title":"bstage out","keywords":"","body":"bstage out © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection3/Help and version display.html":{"url":"chapter7/section1/subsection3/Help and version display.html","title":"Help and version display","keywords":"","body":"Help and version display © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection3/See also.html":{"url":"chapter7/section1/subsection3/See also.html","title":"See also","keywords":"","body":"See also © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection4/bsub.html":{"url":"chapter7/section1/subsection4/bsub.html","title":"bsub","keywords":"","body":"bsub © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 10:48:40 "},"chapter7/section1/subsection4/Categories.html":{"url":"chapter7/section1/subsection4/Categories.html","title":"Categories","keywords":"","body":"Categories © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection4/Options.html":{"url":"chapter7/section1/subsection4/Options.html","title":"Options","keywords":"","body":"Options © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section1/subsection4/Description.html":{"url":"chapter7/section1/subsection4/Description.html","title":"Description","keywords":"","body":"Description © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-13 13:07:07 "},"chapter7/section2/Configuration_reference.html":{"url":"chapter7/section2/Configuration_reference.html","title":"7.2 配置参考","keywords":"","body":"7.2 配置参考 了解有关 IBM Spectrum LSF 功能，文件，事件和环境变量的配置参数。 配置文件 LSF 配置文件参考。 环境变量 了解如何为作业执行，作业调整大小通知命令和会话调度程序（ssched）设置 LSF 环境变量。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section2/subsection1/Configuration_files.html":{"url":"chapter7/section2/subsection1/Configuration_files.html","title":"配置文件","keywords":"","body":"Configuration files LSF configuration files reference. Important Specify any domain names in all uppercase letters in all configuration files. cshrc.lsf and profile.lsf The user environment shell files cshrc.lsf and profile.lsf set the LSF operating environment on an LSF host.hosts For hosts with multiple IP addresses and different official host names configured at the system level, this file associates the host names and IP addresses in LSF.install.config The install.config file contains options for LSF installation and configuration. Use the lsfinstall -f install.config command to install LSF with the options that are specified in the install.config file.lim.acct The lim.acct file is the log file for the LSF Load Information Manager (LIM). Produced by the lsmon command, the lim.acct file contains host load information that is collected and distributed by LIM.lsb.acct The lsb.acct file is the batch job log file of LSF.lsb.applications The lsb.applications file defines application profiles. Use application profiles to define common parameters for the same type of jobs, including the execution requirements of the applications, the resources they require, and how they should be run and managed.lsb.events The LSF batch event log file lsb.events is used to display LSF batch event history and for mbatchd failure recovery.lsb.globalpolicies This configuration file defines global policies for multiple clusters.lsb.hosts lsb.modules The lsb.modules file contains configuration information for LSF scheduler and resource broker modules. The file contains only one section, named PluginModule.lsb.params lsb.queues The lsb.queues file defines batch queues. Numerous controls are available at the queue level to allow cluster administrators to customize site policies.lsb.reasons lsb.resources The lsb.resources file contains configuration information for resource allocation limits, exports, resource usage limits, and guarantee policies. This file is optional.lsb.serviceclasses lsb.threshold The lsb.threshold configuration file defines energy-saving and CPU frequency policies. This file is optional.lsb.users lsf.acct lsf.cluster The cluster configuration file. There is one file for each cluster, called lsf.cluster.cluster_name. The cluster_name suffix is the name of the cluster defined in the Cluster section of the lsf.shared file. All LSF hosts are listed in this file, along with the list of LSF administrators and the installed LSF features.lsf.conf The lsf.conf file controls the operation of LSF. The lsf.conf file is created during installation and records all the settings chosen when LSF was installed. The lsf.conf file dictates the location of the specific configuration files and operation of individual servers and applications.lsf.datamanager The lsf.datamanager file controls the operation of IBM Spectrum LSF Data Manager features. Each cluster has one LSF data management configuration file, called lsf.datamanager.cluster_name. The cluster_name suffix is the name of the cluster that is defined in the Cluster section of the lsf.shared file. The file is read by the LSF data management daemon dmd. Since one LSF data manager can serve multiple LSF clusters, the contents of this file must be identical on each cluster that shares LSF data manager.lsf.licensescheduler The lsf.licensescheduler file contains LSF License Scheduler configuration information. All sections except ProjectGroup are required. In cluster mode, the Project section is also not required.lsf.shared The lsf.shared file contains common definitions that are shared by all load sharing clusters defined by lsf.cluster.cluster_name files.lsf.sudoers lsf.task setup.config slave.config The slave.config file contains options for installing and configuring a server host that can be dynamically added or removed. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-07 21:08:06 "},"chapter7/section2/subsection2/Environment_variables.html":{"url":"chapter7/section2/subsection2/Environment_variables.html","title":"环境变量","keywords":"","body":"Environment variables Learn how LSF environment variables are set for job execution, job resize notification command, and for session scheduler (ssched). Environment variables set for job execution In addition to environment variables inherited from the user environment, LSF also sets several other environment variables for batch jobs.Environment variables for resize notification command Environment variables for session scheduler (ssched) Environment variables for data provenance Environment variable reference Reference for LSF environment variables. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-07 21:09:38 "},"chapter7/section2/subsection2/Environment variables set for job execution.html":{"url":"chapter7/section2/subsection2/Environment variables set for job execution.html","title":"为作业执行而设置的环境变量","keywords":"","body":"Environment variables set for job execution © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section2/subsection2/Environment variables for resize notification command.html":{"url":"chapter7/section2/subsection2/Environment variables for resize notification command.html","title":"调整大小通知命令的环境变量","keywords":"","body":"Environment variables for resize notification command © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section2/subsection2/Environment variables for session scheduler.html":{"url":"chapter7/section2/subsection2/Environment variables for session scheduler.html","title":"会话调度程序的环境变量","keywords":"","body":"Environment variables for session scheduler (ssched) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section2/subsection2/Environment variables for data provenance.html":{"url":"chapter7/section2/subsection2/Environment variables for data provenance.html","title":"用于数据来源的环境变量","keywords":"","body":"Environment variables for data provenance © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section2/subsection2/Environment variable reference.html":{"url":"chapter7/section2/subsection2/Environment variable reference.html","title":"环境变量参考","keywords":"","body":"Environment variable reference © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter7/section3/API_reference.html":{"url":"chapter7/section3/API_reference.html","title":"7.3 API 参考","keywords":"","body":"7.3 API reference 请参阅对 IBM Spectrum LSF API 的全面参考。 LSF API reference © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-11 09:17:01 "},"chapter8/Extend_LSF.html":{"url":"chapter8/Extend_LSF.html","title":" Chapter 8 LSF 拓展","keywords":"","body":"Chapter 8 LSF 拓展 配置和使用 IBM Spectrum LSF 集成。 IBM Spectrum LSF 会话调度程序 IBM Spectrum LSF Session Scheduler 安装，管理和使用 IBM Spectrum LSF Session Scheduler。 通过使用作业级任务调度程序，在单个 LSF 作业的分配范围内，运行大量短期任务的集合，该任务级任务调度程序为该作业分配一次资源，并为每个任务重用分配的资源。 IBM Spectrum LSF Session Scheduler 是运行短作业的理想选择，无论它们是任务列表还是带有参数执行的作业阵列。 带有 IBM Rational ClearCase 的 IBM Spectrum LSF IBM Spectrum LSF with IBM Rational ClearCase 许多站点使用 IBM®Rational®ClearCase®（ClearCase）环境进行修订版源控制和开发。 了解如何通过 IBM Rational ClearCase软件，来安装，配置和使用 IBM Spectrum LSF。 Cray Linux上的IBM Spectrum LSF IBM Spectrum LSF on Cray Linux IBM Spectrum LSF 与 Cray Linux 的集成适用于 LSF 版本8.0或更高版本，并支持与 Cray Linux Environment 4.0或更高版本的集成。 您必须有 LSF Standard Edition 或 LSF Advanced Edition。 LSF Express Edition不支持Cray Linux集成。 带有Apache Spark的IBM Spectrum LSF IBM Spectrum LSF with Apache Spark 在 Apache Spark 应用程序中配置和使用 IBM Spectrum LSF。 带有Apache Hadoop的IBM Spectrum LSF IBM Spectrum LSF with Apache Hadoop 在 Apache Hadoop 应用程序中，使用 IBM Spectrum LSF。 带有IBM Cluster Systems Manager的IBM Spectrum LSF IBM Spectrum LSF with IBM Cluster Systems Manager IBM Cluster Systems Manager（CSM）是一种系统管理工具，旨在对分布式和集群化的 IBM Power Systems 进行简单，低成本的管理。 了解如何在IBM Cluster Systems Manager中安装，配置和使用IBM Spectrum LSF。 具有 IBM Cloud Private 的 IBM Spectrum LSF IBM Spectrum LSF with IBM Cloud Private 可变地使用许可，用于扩展到云的动态计算工作负载，使您可以通过具有成本效益的按需购买即用许可，来优化基于云的资源使用。 管理员可以配置 IBM Spectrum LSF 集群，以通过外部负载索引监视器（ELIM）将CPU内核，CPU插槽，GPU插槽和主机计数，上载到 IBM Cloud Private 中的计量服务。 然后，管理员可以从IBM Cloud Private中的计量仪表板审核IBM Spectrum LSF资源使用情况。 LSF 作业步骤管理器 LSF Job Step Manager 使用JSDL提交作业 Submitting jobs using JSDL IBM Spectrum LSF模拟器 IBM Spectrum LSF Simulator 使用 LSF Simulator 通过在单独的内部环境中，模拟 LSF 集群来分析和调整 LSF 配置。 使用 LSF Simulator，您可以在不中断 LSF 生产环境的情况下使用不同的工作负载跟踪运行实验。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 11:00:30 "},"chapter9/Best_practices_and_tips.html":{"url":"chapter9/Best_practices_and_tips.html","title":"Chapter 9 最佳实践与建议","keywords":"","body":"Chapter 9 经验与建议总结 查看使用 LSF 的各种最佳实践和技巧。 会计文件管理 Accounting file management 将 CPU 分配为并行作业的块 Allocating CPUs as blocks for parallel jobs 并行作业始终要求运行多个CPU。 如果可以将分配的CPU分配为块，则某些作业可以运行得更快。 清理并行作业执行问题 Cleaning up parallel job execution problems 将 IBM Aspera 配置为数据传输工具 Configuring IBM Aspera as a data transfer tool IBM Aspera 是一种数据传输工具，可以在高延迟网络中高效，基于策略地使用网络带宽。 自定义作业查询输出格式 Customizing job query output format 定义基于主机的外部资源 Defining external host-based resources 加强作业内存并与 Linux cgroup 交换 Enforcing job memory and swap with Linux cgroups 作业访问控制 Job access control 将IBM Spectrum LSF与Andrew File System（AFS）结合使用 Using IBM Spectrum LSF with Andrew File System (AFS) 了解 LSF 如何与 Andrew File System（AFS）集成，以便您可以配置 LSF 以适合您的需求。 维持集群性能 Maintaining cluster performance 在 LSF 中管理浮动软件许可证 Managing floating software licenses in LSF 通常，浮动软件许可证池由 LSF 中的数字资源表示。 每个需要许可证的工作都必须在其 rusag 表达式中包括许可证要求，以确保在分发工作时为该工作释放了足够的许可证。 在启用 CPU 频率调节器的情况下优化 LSF 作业处理 Optimizing LSF job processing with CPU frequency governors enabled Oracle Solaris 和 IBM AIX 上的操作系统分区和虚拟化 Operating system partitioning and virtualization on Oracle Solaris and IBM AIX 本文介绍了 LSF 在 OS 分区和虚拟化环境中的工作方式，重点是 Oracle Solaris 容器和 IBM AIX 分区。 基于主机的可用作业位置放置作业 Placing jobs based on available job slots of hosts 运行 checksum 以验证安装映像 Running checksum to verify installation images 跟踪作业依赖性 Tracking job dependencies 了解 mbatchd 的性能指标 Understanding mbatchd performance metrics 使用计算单元进行拓扑调度 Using compute units for topology scheduling 使用作业目录 Using job directories 使用 lsmake 加速 Android 构建 Using lsmake to accelerate Android builds 将 NVIDIA DGX 系统与 LSF 一起使用 Using NVIDIA DGX systems with LSF 将 ssh X11 转发与 IBM Spectrum LSF 一起使用 Using ssh X11 forwarding with IBM Spectrum LSF 为了使启用 X 的应用程序能够按预期运行，必须通过 ssh 来建立 X 连接，这是一种安全的方法。 为LSF API 使用 Python wrapper Using the Python wrapper for LSF API © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 11:00:39 "},"chapter10/LSF License Scheduler.html":{"url":"chapter10/LSF License Scheduler.html","title":"Chapter 10 LSF 许可证调度程序","keywords":"","body":"Chapter 10 LSF 许可证调度程序 安装，配置和使用 IBM Spectrum LSF License Scheduler（LSF License Scheduler）。 了解制定策略，来控制组织中不同用户或项目之间，如何共享软件应用程序许可证。 介绍 安装与启动许可证调度程序 LSF 许可证调度器相关概念 配置许可证调度器 查询信息与错误排查 参考 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:10:58 "},"chapter10/section1/Introduction.html":{"url":"chapter10/section1/Introduction.html","title":"介绍","keywords":"","body":"介绍 概览 LSF License Scheduler版本之间的差异 LSF License Scheduler有两个版本：基本版和标准版。 词汇表 架构 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:22:01 "},"chapter10/section1/Overview.html":{"url":"chapter10/section1/Overview.html","title":"概览","keywords":"","body":"概览 将策略应用于共享许可证的方式，既可以提高生产率，又可以节省成本。 更轻松地共享许可证 IBM Spectrum LSF License Scheduler (LSF License Scheduler) makes it easy to share licenses between project teams and departments within the same design center or around the globe. With tools to allocate and monitor licenses, license owners can share licenses not in use, while still ensuring immediate access to licenses when needed. With more effective sharing, all users perceive a larger pool of licenses. 确保适当的许可证分配 License Scheduler enables flexible, hierarchical sharing policies that reflect the needs of the business. During quiet periods, when licenses are not in contention, licenses can be allocated to anyone who needs them keeping utilization and throughput high. During busy periods, the supply of licenses can be allocated based on policy toward the most time or revenue critical projects. 提高服务水平和生产力 By ensuring access to a minimum share of licenses and enabling allocation to flex between clusters that are based on need, licenses are more readily available and jobs are less likely to pend in queues that are awaiting license resources. This translates into reduced wait times and better productivity, and contributes to a faster, more efficient design environment. 减少或避免成本 By being able to allocate scarce licenses to the most critical projects, and by being able to analyze license usage in the context of cluster resources, users and projects, planners are better able to find and remove bottlenecks, making their existing licenses more productive. With better visibility to how licenses are being used, they can plan license requirements more effectively ultimately helping to contain costs and boost productivity. License Scheduler controls the software license sharing in your organization. License Scheduler works with FlexNet™ and Reprise License Manager™ products to control and monitor license usage. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:23:17 "},"chapter10/section1/Differences between LSF License Scheduler editions.html":{"url":"chapter10/section1/Differences between LSF License Scheduler editions.html","title":"LSF License Scheduler 版本之间的差异","keywords":"","body":"LSF License Scheduler 版本之间的差异 LSF License Scheduler is available in two editions: Basic Edition and Standard Edition. LSF License Scheduler Basic Edition is included with LSF Standard Edition and Advanced Edition, and is not intended to apply policies on how licenses are shared between clusters or projects. Rather, LSF License Scheduler Basic Edition is intended to replace an external load information manager (elim) to collect external load indicies for licenses managed by FlexNet or Reprise License Manager. To replace this elim, LSF License Scheduler Basic Edition limits the license use of jobs of a single cluster to prevent overuse of the licenses and tracks license use of individual jobs by matching license checkouts to these jobs. LSF License Scheduler LSF License Schedulerfunctionality, including support for all modes (cluster mode, project mode, and fast dispatch project mode), multiple clusters, features and feature groups, multiple service domains per license feature.LSF License Scheduler LSF Advanced Edition Important A LSF License Scheduler entitlement file (ls.entitlement) is now required to run LSF License Scheduler Standard Edition. Copy the entitlement file (ls.entitlement) to the $LSF_ENVDIR directory before starting LSF License Scheduler to run as Standard Edition. To install and run LSF License Scheduler Basic Edition, download and install the LSF License Scheduler packages as described in Install License Scheduler, but follow any specific steps for installing and configuring LSF License Scheduler Basic Edition instead of Standard Edition. LSF License Scheduler Standard Edition is assumed in all LSF License Scheduler documentation unless it is explicitly stated as describing LSF License Scheduler Basic Edition. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:35:45 "},"chapter10/section1/Glossary.html":{"url":"chapter10/section1/Glossary.html","title":"词汇表","keywords":"","body":"词汇表 blcollect 许可证调度程序守护程序，用于查询许可软件以获取许可证使用情况。 blcollect 从许可证管理器收集信息。 您可以通过在多个UNIX主机上运行许可证信息收集守护程序来分散许可证收集的负载。 它也称为收集器。 bld 许可证调度程序批处理守护程序。 cluster mode 许可证令牌由许可证调度程序分配给集群，每个集群内的作业调度由本地 mbatchd 管理。 集群模式仅适用于License Scheduler 8.0 及更高版本。 每个许可证功能都可以使用集群模式或项目模式，但不能同时使用两者。 lmgrd 主要的 FlexNet 许可守护程序。 通常在 License Scheduler 中分为服务域。 project mode 许可证令牌，由许可证计划程序分配给项目，并且许可证项目的作业计划，在遵循为每个项目配置的许可证分配策略的集群之间进行。 对应于 License Scheduler 版本 7.0.5 及更早版本。 每个许可证功能都可以使用集群模式或项目模式，但不能同时使用两者。 service domain 一组一个或多个FlexNet许可证服务器。 您可以使用为网络提供许可证的许可证服务器名称和端口号来配置服务域。 taskman job 由 LSF 之外的 IBM Spectrum LSF（LSF）任务管理器（taskman）工具运行，但由许可计划程序调度的作业。 token 一个许可证令牌代表一个实际的许可证，许可证调度程序使用它来跟踪许可证的使用，并确定接下来要分发的作业。 License Scheduler 管理许可证令牌，而不是直接控制许可证。 他们保留许可证令牌后，将调度作业，然后启动需要许可证的应用程序。 LSF 可用的令牌数量与许可证服务器可用的许可证数量相对应，因此，如果令牌不可用，则不会分派作业。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:59:00 "},"chapter10/section1/Architecture.html":{"url":"chapter10/section1/Architecture.html","title":"架构","keywords":"","body":"架构 LSF License Scheduler manages license tokens instead of controlling the licenses directly. Using LSF License Scheduler, jobs receive a license token before starting the application. The number of tokens available from IBM Spectrum LSF (LSF) andIBM Spectrum LSF Advanced Edition (LSF Advanced Edition) corresponds to the number of licenses available from the license server, so if a token is not available, the job does not start. In this way, the number of licenses that are requested by running jobs does not exceed the number of available licenses. When a job starts, the application is not aware of LSF License Scheduler. The application checks out licenses from the license server in the usual manner. Figure 1. Daemon interaction 调度策略如何工作 With LSF License Scheduler, LSF gathers information about the licensing requirements of pending jobs to efficiently distribute available licenses. Other LSF scheduling policies are independent from LSF License Scheduler policies. The basic LSF scheduling comes first when starting a job. LSF License Scheduler has no influence on job scheduling priority. Jobs are considered for dispatch according to the prioritization policies configured in each cluster. For example, a job must have a candidate LSF host on which to start before the LSF License Scheduler fairshare policy (for the license project this job belongs to) applies. Other LSF fairshare policies are based on CPU time, run time, and usage. If LSF fairshare scheduling is configured, LSFdetermines which user or queue has the highest priority, then considers other resources. In this way, the other LSF fairshare policies have priority over LSF License Scheduler. 当 mbatchd 脱机时 When a cluster is running, the mbatchd maintains a TCP connection to bld. When the cluster is disconnected (such as when the cluster goes down or is restarted), the bld removes all information about jobs in the cluster. LSF License Scheduler considers licenses that are checked out by jobs in a disconnected cluster to be non-LSF use of licenses. When mbatchd comes back online, the bld immediately receives updated information about the number of tokens that are currently distributed to the cluster. 当 bld 脱机时 If the mbatchd loses the connection with the bld, the mbatchd cannot get bld’s token distribution decisions to update its own. However, because the mbatchd logs token status every minute in$LSF_TOP/work/data/featureName.ServiceDomainName.dat file, if the connection is lost, the mbatchd uses the last logged information to schedule jobs. f3.LanServer1.dat # f3 LanServer1 3 2 # p1 50 p2 50 12/3 14:20:38 2 0 2 0 1 0 1 0 12/3 14:21:39 2 0 2 0 1 0 1 0 12/3 14:22:40 3 3 0 0 0 0 0 0 12/3 14:23:41 3 3 0 0 0 0 0 0 12/3 14:24:42 1 0 1 0 2 0 2 0 12/3 14:25:43 1 0 1 0 2 0 2 0 12/3 14:26:44 1 0 1 0 2 0 2 0 12/3 14:27:55 1 0 1 0 2 0 2 0 f3 on LanServer1 has three tokens and two projects. Projects p1 and p2 share licenses 50:50. At 14:27:55, the bld dispatched one token to p1, which has 0 in use, 1 free, 0 reserve. At the same time, the blddispatched two tokens to p2, which has 0 in use, 2 free, and 0 reserve. The mbatchd continues to schedule jobs that are based on the token distribution that is logged at 14:27:55 until the connection with the bld is re-established. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:38:03 "},"chapter10/section2/Installing and starting License Scheduler.html":{"url":"chapter10/section2/Installing and starting License Scheduler.html","title":"安装和启动许可证调度程序","keywords":"","body":"安装和启动许可证调度程序 安装许可证计划程序 启动许可证计划程序 许可证调度程序中的 LSF 参数 关于提交工作 配置更改之后 将集群添加到 License Scheduler 配置多个管理员 升级许可证计划程序 防火墙 LSF，许可证调度程序和 taskman 互操作性的配置。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:57:48 "},"chapter10/section2/subsection1/Install License Scheduler.html":{"url":"chapter10/section2/subsection1/Install License Scheduler.html","title":"安装 License Scheduler","keywords":"","body":"Install License Scheduler Perform the pre-installation steps. Choose an installation plan: UNIX: License Scheduler manages licenses for jobs that run through LSF and through applications other than LSF. Windows, in a mixed cluster: A Licenser Scheduler installation requires UNIX hosts to run the bld. Windows hosts in a mixed cluster can run License Scheduler commands. When you have License Scheduler UNIX hosts working with LSF, run License Scheduler on Windows hosts as well. Before you install What the License Scheduler setup script does Install License Scheduler with LSF (UNIX) Install License Scheduler on Windows You can install License Scheduler on Windows hosts when your cluster includes both Windows and UNIX hosts. Troubleshoot Configure LSF License Scheduler Basic Edition Configure LSF and LSF License Scheduler Basic Edition. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:23:15 "},"chapter10/section2/subsection1/Before you install.html":{"url":"chapter10/section2/subsection1/Before you install.html","title":"安装之前","keywords":"","body":"Before you install About this task LSF must be installed and running before you install License Scheduler. Procedure Log on to any LSF host as root and use lsid to make sure that the cluster is running. If you see the message \"Cannot open lsf.conf file\", verify that the $LSF_ENVDIR environment variable is set correctly. To set your LSF environment: For csh or tcsh: % source LSF_TOP/conf/cshrc.lsf For sh, ksh, or bash: $ . LSF_TOP/conf/profile.lsf © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:23:17 "},"chapter10/section2/subsection1/What the License Scheduler setup script does.html":{"url":"chapter10/section2/subsection1/What the License Scheduler setup script does.html","title":"License Scheduler 设置脚本的作用","keywords":"","body":"What the License Scheduler setup script does Finds the appropriate lsf.conf for the running cluster. Copies the License Scheduler files to your LSF directories: $LSF_ENVDIR: lsf.licensescheduler ls.users $LSF_SERVERDIR: bld blcollect globauth esub.ls_auth $LSF_BINDIR: blstat blcstat blusers blinfo bladmin blstartup blhosts blkill bltasks blparams taskman $LSF_LIBDIR: libglb.a libglb.so liblic.so $LSF_MANDIR: various man pages Finds the appropriate lsf.cluster.cluster_name file for the running cluster. Creates the following additional directories: $LSB_SHAREDIR/cluster_name/db $LSB_SHAREDIR/cluster_name/data Sets your License Scheduler administrators list in the lsf.licensescheduler file. Configures LSF to use License Scheduler. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:26:40 "},"chapter10/section2/subsection1/Install License Scheduler with LSF UNIX.html":{"url":"chapter10/section2/subsection1/Install License Scheduler with LSF UNIX.html","title":"使用LSF（UNIX）安装 License Scheduler","keywords":"","body":"Install License Scheduler with LSF (UNIX) Before you begin You must have write access to the LSF_TOP directories. Procedure Log on as root to the installation file server host. Download, uncompress, and extract the LSF License Scheduler packages for the platforms you need. For example, for x86 64-bit systems that run Linux kernel 2.6.x and compiled with glibc 2.3.x, download lsf10.1_licsched_lnx26-x64.tar.Z. Extract the distribution file. For example: # zcat lsf10.1_licsched_lnx26-x64.tar.Z | tar xvf - Change to the extracted distribution directory. For example: # cd lsf10.1_licsched_linux2.6-glibc2.3-x86_64 Run the setup script as root: # ./setup Note If you are installing License Scheduler into a non-LSF environment or doing a silent install, edit ./setup.config prior to your installation. Enter y (yes) to confirm that the path to lsf.conf is correct. To enter a path to a different lsf.conf, type n (no) and specify the full path to the lsf.conf file you want to use. Enter y to confirm that the path to lsf.cluster.cluster_name is correct. To enter a path to a different lsf.cluster.cluster_name file, type n (no) and specify the full path to the lsf.cluster.cluster_name file you want to use. Enter y to confirm that you want to use the LSF Administrators list for License Scheduler with LSF. To enter a different list of administrators for License Scheduler, enter a space-separated list of administrator user names. You can change your License Scheduler administrators list later, if necessary. If you are installing LSF License Scheduler Standard Edition, copy the LSF License Scheduler entitlement file (ls.entitlement) to the $LSF_ENVDIR directory. If you do not copy the entitlement file to $LSF_ENVDIR before starting LSF License Scheduler, LSF License Scheduler runs as Basic Edition. What to do next Start License Scheduler Note Before starting LSF License Scheduler, if you are installing LSF License Scheduler Basic Edition, configure License Scheduler Basic Edition and LSF as described in Configure License Scheduler Basic Edition . If you are installing LSF License Scheduler Standard Edition, configure LSF License Scheduler Standard Edition and LSF as described in Configuring License Scheduler. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:24:13 "},"chapter10/section2/subsection1/Install License Scheduler on Windows.html":{"url":"chapter10/section2/subsection1/Install License Scheduler on Windows.html","title":"在windows 上安装 License Scheduler","keywords":"","body":"Install License Scheduler on Windows You can install License Scheduler on Windows hosts when your cluster includes both Windows and UNIX hosts. The License Scheduler Windows Client package includes: README Commands: blstat.exe blcstat.exe blinfo.exe blusers.exe bladmin.exe blhosts.exe blkill.exe bltasks.exe blparams.exe taskman.exe lsf.licensescheduler: License Scheduler configuration file lsf.conf: LSF configuration file Install License Scheduler with LSF (Windows) © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:24:34 "},"chapter10/section2/subsection1/Install License Scheduler with LSF Windows.html":{"url":"chapter10/section2/subsection1/Install License Scheduler with LSF Windows.html","title":"使用 LSF(Windows) 安装 License Scheduler","keywords":"","body":"Install License Scheduler with LSF (Windows) Before you begin You must already have LSF installed on all Windows hosts you intend to install License Scheduler on. About this task This installation option means that License Scheduler manages licenses for jobs that are submitted through LSF and through any other applications. Install License Scheduler on Windows hosts only when your LSF cluster includes both UNIX and Windows hosts. Procedure Download the License Scheduler Client for Windows package. Copy all commands to $LSF_BINDIR (the bin subdirectory in your LSF installation directory) on your Windows hosts. Copy lsf.licensescheduler to $LSF_ENVDIR. Edit lsf.licensescheduler to suit your License Scheduler Master host configuration. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:25:08 "},"chapter10/section2/subsection1/Troubleshoot.html":{"url":"chapter10/section2/subsection1/Troubleshoot.html","title":"故障排除","keywords":"","body":"Troubleshoot Procedure If you receive the following message, configure your Windows host name and IP address in the /etc/hosts file on the master host: Failed in an LSF library call: Failed in sending/receiving a message: error 0: The operation completed successfully. To enable the blhosts command, make sure that your Windows host can resolve the master host IP address correctly. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:41:07 "},"chapter10/section2/subsection1/Configure LSF License Scheduler Basic Edition.html":{"url":"chapter10/section2/subsection1/Configure LSF License Scheduler Basic Edition.html","title":"配置 LSF License Scheduler 基础版","keywords":"","body":"Configure LSF License Scheduler Basic Edition Configure LSF and LSF License Scheduler Basic Edition. Parent topic: Install License Scheduler Configuring LSF License Scheduler Basic Edition and LSF About this task Configure LSF to use LSF License Scheduler Basic Edition as a replacement for an elim to collect external load indices where the external resources are licenses managed by FlexNet or Reprise License Manager. The following example assumes that LSF cluster named cluster1 uses an elim for a license resource named f1. Procedure In the LSF environment, disable the existing elim for the license resource by removing the license feature configuration from the lsf.shared and lsf.cluster.cluster_name files. For example, remove the configuration for f1 from the lsf.shared and lsf.cluster.cluster_name files. Configure the lsf.licenscheduler file with the appropriate hosts and the license feature. For example, configure the following sections in lsf.licenscheduler: Begin Parameters PORT=1700 HOSTS=hostA ADMIN=lsadmin LM_STAT_INTERVAL=15 LMSTAT_PATH=/usr/bin End Parameters Begin Clusters CLUSTERS cluster1 End Clusters Begin ServiceDomain NAME=LanServer LIC_SERVERS=((19999@hostA)) End ServiceDomain Begin Feature NAME=f1 CLUSTER_MODE=Y CLUSTER_DISTRIBUTION=LanServer(cluster1) End Feature Start LSF License Scheduler and LSF. For more details, refer to Start License Scheduler. What to do next From LSF, use bsub to submit a job without a duration requesting the f1 resource. For example, bsub -R \"rusage[f1=1]\" myjob Upgrading from LSF License Scheduler Basic Edition to Standard Edition About this task If you use LSF License Scheduler Basic Edition and wish to upgrade to LSF License Scheduler Standard Edition, obtain the LSF License Scheduler entitlement file, then upgrade LSF License Scheduler as follows: Procedure Copy the LSF License Scheduler entitlement file (ls.entitlement) to the LSF_ENVDIR directory. Restart LSF License Scheduler. bladmin reconfig Restart the mbatchd on the LSF master host. badmin mbdrestart Supported parameters for LSF License Scheduler Basic Edition The following is a list of specific lsf.licensescheduler parameters that LSF License Scheduler Basic Edition supports: Parameters section: ADMIN BLC_HEARTBEAT_FACTOR CLUSTER_MODE (LSF License Scheduler Basic Edition only supports CLUSTER_MODE=Y) HEARTBEAT_INTERVAL HEARTBEAT_TIMEOUT HOSTS LIB_CONNTIMEOUT LIB_RECVTIMEOUT LM_STAT_INTERVAL LM_STAT_TIMEOUT LM_TYPE LMSTAT_PATH LOG_EVENT LOG_INTERVAL LS_DEBUG_BLC LS_DEBUG_BLD LS_DEBUG_CMD LS_LOG_MASK LS_MAX_STREAM_FILE_NUMBER LS_MAX_STREAM_SIZE LS_STREAM_SIZE LS_STREAM_FILE MBD_HEARTBEAT_INTERVAL MBD_REFRESH_INTERVAL RLMSTAT_PATH STANDBY_CONNTIMEOUT Clusters section: CLUSTERS (one cluster only, LSF License Scheduler Basic Edition ignores additional clusters) ServiceDomain section (one ServiceDomain section per license feature only, LSF License Scheduler Basic Edition ignores additional ServiceDomain sections in the same license feature): NAME LIC_SERVERS LM_STAT_INTERVAL LM_STAT_TIMEOUT LM_TYPE LIC_COLLECTOR Feature section: NAME CLUSTER_MODE (Optional. This parameter may be specified in the Parameters section instead, but LSF License Scheduler Basic Edition only supports CLUSTER_MODE=Y) LM_LICENSE_NAME (Optional. LSF License Scheduler Basic Edition does not support the specification of multiple license manager feature names to combine into a single alias) CLUSTER_DISTRIBUTION (LSF License Scheduler Basic Edition supports a single cluster with a single service domain only, and ignores any additional clusters or service domains). Tip A specific lsf.licensescheduler configuration template for LSF License Scheduler Basic Edition is available and contains specifications for all supported parameters. This file is named lsf.licensescheduler.basic and is included in the LSF License Scheduler installation package. LSF License Scheduler uses the Standard Edition configuration file by default, but LSF License Scheduler Basic Edition ignores unsupported Standard Edition parameters with a warning message. To ensure that LSF License Scheduler Basic Edition uses only supported parameters and to prevent the logging of the warning messages, back up the lsf.licensescheduler configuration file, then move the lsf.licensescheduler.basic file to the $LSF_ENVDIR directory and rename it to lsf.licensescheduler. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:25:49 "},"chapter10/section2/Start License Scheduler.html":{"url":"chapter10/section2/Start License Scheduler.html","title":"启动 License Scheduler","keywords":"","body":"启动许可证计划程序 关于此任务 You can configure LSF to start the License Scheduler daemon (bld) on the License Scheduler host as well as on candidate License Scheduler hosts that can take over license distribution in the case of a network failure. The LSF LIM daemon starts bld automatically. 步骤 Log on as the primary LSF administrator. Set your LSF environment: For csh or tcsh: % source LSF_TOP/conf/cshrc.lsf For sh, ksh, or bash: $. LSF_TOP/conf/profile.lsf In LSF_CONFDIR/lsf.conf, specify a space-separated list of hosts for the LSF_LIC_SCHED_HOSTS parameters: LSF_LIC_SCHED_HOSTS=\"hostname_1 hostname_2 ... hostname_n\" Where: hostname_1, hostname_2, hostname_n are hosts on which the LSF LIM daemon starts the License Scheduler daemon. The order of the host names is ignored. Note Set the LSF_LIC_SCHED_HOSTS parameter to the same list of candidate hosts you used in the lsf.licensescheduler HOSTS parameter. The LSF_LIC_SCHED_HOSTS parameter is not used in any other function. Run lsadmin reconfig to reconfigure the LIM. Use ps -ef to make sure that bld is running on the candidate hosts. Run badmin mbdrestart to restart mbatchd. If you specified a LIC_COLLECTOR name in your service domains, start each license collector manually: blcollect -m \"host_list\" -p lic_scheduler_port -c lic_collector_name Where: host_list Specifies a space-separated list of License Scheduler candidate hosts to which license information is sent. Use fully qualified host names. lic_scheduler_port Corresponds to the License Scheduler listening port, which is set in lsf.licensescheduler. lic_collector_name Specifies the name of the license collector you set for LIC_COLLECTOR in the service domain section of lsf.licensescheduler. For example: blcollect -m \"hostD.designcenter_b.com hostA.designcenter_a.com\" -p 9581 -c CenterB A file named collectors/CenterB is created in your LSF_WORKDIR. Note If you do not specify a license collector name in a License Scheduler service domain, the master bld host starts a default blcollect. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:21:46 "},"chapter10/section2/LSF parameters in License Scheduler.html":{"url":"chapter10/section2/LSF parameters in License Scheduler.html","title":"License Scheduler 中的 LSF 参数","keywords":"","body":"LSF parameters in License Scheduler Parameters in lsf.conf that start with LSF_LIC_SCHED are relevant to both LSF and License Scheduler: LSF_LIC_SCHED_HOSTS: LIM starts the License Scheduler daemon (bld) on candidate License Scheduler hosts. CAUTION You cannot use LSF_LIC_SCHED_HOSTS if your cluster was installed with UNIFORM_DIRECTORY_PATH or UNIFORM_DIRECTORY_PATH_EGO. Do not set UNIFORM_DIRECTORY_PATH or UNIFORM_DIRECTORY_PATH_EGO for new or upgrade installations. They are for compatibility with earlier versions only. LSF_LIC_SCHED_PREEMPT_REQUEUE: Requeues a job whose license is preempted by License Scheduler. The job is killed and requeued instead of suspended. LSF_LIC_SCHED_PREEMPT_SLOT_RELEASE: Releases memory and slot resources of a License Scheduler job that is suspended. These resources are only available to pending License Scheduler jobs that request at least one license that is the same as the suspended job. Job slots are released by default, but memory resources are also released if memory preemption is enabled (that is, PREEMPTABLE_RESOURCES = mem is set in lsb.params). LSF_LIC_SCHED_PREEMPT_STOP: Uses job controls to stop a job that is preempted. When this parameter is set, a UNIX SIGSTOP signal is sent to suspend a job instead of a UNIX SIGTSTP. LSF_LIC_SCHED_STRICT_PROJECT_NAME: Enforces strict checking of the License Scheduler project name upon job submission. If the project named is misspelled (case sensitivity applies), the job is rejected. LSF parameters used by License Scheduler LSB_SHAREDIR: Directory where the job history and accounting logs are kept for each cluster LSF_LOG_MASK: Logging level of error messages for LSF daemons LSF_LOGDIR: LSF system log file directory © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:43:07 "},"chapter10/section2/About submitting jobs.html":{"url":"chapter10/section2/About submitting jobs.html","title":"关于提交作业","keywords":"","body":"About submitting jobs When you submit an LSF job, you must reserve the license with the resource requirement usage section (bsub -R \"rusage...\" option). You cannot successfully reserve a license by running bsub -R \"select\". Specify the license token name (same as specifying a shared resource). If you use project mode, specify a license project name with the bsub -Lp option. If you also have LSF_LIC_SCHED_STRICT_PROJECT_NAME=y in lsf.conf and without configuring a default project for the required feature, the job is rejected. Tip Use the blstat command to view information about the default license project. Update resource requirements. If your queue or job starter scripts request a license that is managed by an LSF ELIM, you must update the job submission scripts to request that license that uses the license token name. Examples: bsub -R \"rusage[AppB=1]\" -Lp Lp1 myjob This command submits a job named myjob to license project Lp1 and requests one AppB license bsub -R \"rusage[AppC=1]\" myjob This command submits a job named myjob and requests one AppC license. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:28:32 "},"chapter10/section2/After configuration changes.html":{"url":"chapter10/section2/After configuration changes.html","title":"配置更改之后","keywords":"","body":"After configuration changes About this task If you make configuration changes to License Scheduler, you must reconfigure License Scheduler to apply the changes. If you make configuration changes to LSF, you must also reconfigure LSF. Procedure Run bld -C to test for configuration errors. Run bladmin reconfig all. If you changed lsf.conf or other LSF configuration files, run badmin mbdrestart and lsadmin reconfig. Note After certain License Scheduler configuration changes, you must run badmin mbdrestart for the changes to take effect. The following configuration changes require you to run badmin mbdrestart: Project changes, additions, or deletions Feature changes, additions, or deletions, including mode changes Cluster locations changes You must also run lsadmin reconfig for any changes to the LIM to take effect (for example, if you changed LSF_LIC_SCHED_HOSTS). © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:44:58 "},"chapter10/section2/Add a cluster to License Scheduler.html":{"url":"chapter10/section2/Add a cluster to License Scheduler.html","title":"将集群添加到 License Scheduler","keywords":"","body":"Add a cluster to License Scheduler Before you begin You must be a License Scheduler administrator. About this task You can add a new cluster to an existing License Scheduler implementation. When adding LSF Advanced Edition clusters, you only need to add the submission clusters to LSF License Scheduler, because the submission clusters will forward LSF License Scheduler jobs to their execution clusters. Procedure Download the License Scheduler package. NoteAcquire the same version of master bld binary files and other architectures that are used in existing member clusters. Install the License Scheduler package on the new cluster. Use an existing lsf.licensescheduler from $LSF_ENVDIR of another cluster with the same bld master. Add new cluster name to the Clusters section of lsf.licensescheduler. Add or modify license distribution policies that are defined in lsf.licensescheduler. Maintain one central lsf.licensescheduler file and have all the clusters access it. Remember The lsf.licensescheduler file in each cluster must be identical. You can accomplish this using either of the following methods: Create a symbolic link from each cluster’s $LSF_ENVDIR to the central lsf.licensescheduler file. Use a CRON-based synchronization script to synchronize the changes that are made from the central lsf.licensescheduler file to the corresponding lsf.licensescheduler files in all the clusters. Check that there is no firewall or network issue with communication from the PORT in the lsf.licensescheduler file Run bladmin reconfig on all hosts where bld is running. On the newly added cluster, run lsadmin limrestart and then badmin mbdrestart. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:45:11 "},"chapter10/section2/Configure multiple administrators.html":{"url":"chapter10/section2/Configure multiple administrators.html","title":"配置多个管理员","keywords":"","body":"Configure multiple administrators Before you begin The primary License Scheduler admin account must have write permissions in the LSF working directory of the primary LSF admin account. About this task The administrator account uses a list of users that you specified when you installed License Scheduler. Edit this parameter if you want to add or change administrators. The first user name in the list is the primary License Scheduler administrator. By default, all the working files and directories that are created by License Scheduler are owned by the primary License Scheduler account. Procedure Log on as the primary License Scheduler administrator. In lsf.licensescheduler, edit the ADMIN parameter if you want to change the License Scheduler administrator. You can specify multiple administrators that are separated by spaces. For example: ADMIN = lsfadmin user1 user2 root Run bld -C to test for configuration errors. Run bladmin reconfig all to apply your changes. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:45:33 "},"chapter10/section2/Upgrade License Scheduler.html":{"url":"chapter10/section2/Upgrade License Scheduler.html","title":"升级 License Scheduler","keywords":"","body":"Upgrade License Scheduler Before you begin You must have License Scheduler installed before you can upgrade. You must be a cluster administrator. About this task You can upgrade to a new version of License Scheduler without uninstalling and reinstalling. Procedure Download the new version of the License Scheduler distribution tar files. Deactivate all queues. Deactivating all queues pends any running jobs and prevents new jobs from being dispatched. badmin qinact all If you have the IBM Spectrum LSF Application Center installed, shut it down. pmcadmin stop Back up your existing LSF_CONFDIR, LSB_CONFDIR, and LSB_SHAREDIR according to the procedures at your site. Optional. To use the fast dispatch project mode in LSF License Scheduler, upgrade LSF to version higher than 9.1.1. After completing the upgrade, restart LSF. Use the setup script to upgrade LSF License Scheduler. Source cshrc.lsf or profile.lsf in old LSF cluster. Navigate to the location of your tar files and extract. Run the setup script. If you are installing License Scheduler Standard Edition, copy the License Scheduler entitlement file (ls.entitlement) to the $LSF_ENVDIR directory. If you do not copy the entitlement file to $LSF_ENVDIR before starting License Scheduler, License Scheduler runs as Basic Edition. Start License Scheduler. Source cshrc.lsf or profile.lsf. Run bladmin reconfig. Run ps -ef to make sure the bld is running on the candidate hosts. Run badmin mbdrestart. Activate the queues. badmin qact all If you have the IBM Spectrum LSF Application Center installed, restart it. pmcadmin start Note IBM Spectrum LSF Application Center displays License Scheduler workload for both project mode and cluster mode. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:22:29 "},"chapter10/section2/Firewalls.html":{"url":"chapter10/section2/Firewalls.html","title":"防火墙","keywords":"","body":"Firewalls Configuration for LSF, License Scheduler, and taskman interoperability. Parent topic: Installing and starting License Scheduler Set up firewall communication About this task The mbatchd and bld listening ports (inbound connections) must be open on either side of the firewall. mbatchd: Set by LSB_MBD_PORT in lsf.conf bld: Set by PORT in lsf.licensescheduler Procedure If a firewall is between the mbatchd and bld hosts, both listening ports must be open. If a firewall is between bld and blcollect hosts (for example, blcollect is configured to run locally on the license servers and bld is on the LSF master host), the bld listening port must be open. If a firewall is between taskman and bld (where jobs use taskman to interface with License Scheduler), the bld listening port must be open. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:26:04 "},"chapter10/section3/LSF License Scheduler concepts.html":{"url":"chapter10/section3/LSF License Scheduler concepts.html","title":"LSF 许可证调度程序概念","keywords":"","body":"LSF 许可证调度程序概念 许可计划程序模式 项目组 许可计划程序中的服务域 发行政策 项目模式抢占 FlexNet 和 Reprise License Manager 的许可证使用情况 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:18:05 "},"chapter10/section3/License Scheduler modes.html":{"url":"chapter10/section3/License Scheduler modes.html","title":"License Scheduler 模式","keywords":"","body":"License Scheduler modes When you configure your installation of License Scheduler, you must choose which of project mode and cluster mode best suits your needs for each license you use. Both project mode and cluster mode can be configured in one installation, however, all different licenses that are required by a job must belong to the same mode. cluster mode Distributes license tokens to clusters, where LSF scheduling takes over.Cluster mode emphasizes high utilization of license tokens over other considerations such as ownership. License ownership and sharing can still be configured, but within each cluster instead of across multiple clusters. Preemption of jobs (and licenses) also occurs within each cluster instead of across clusters.License tokens are reused by LSF when a job finishes, without waiting for confirmation from lmstat or rlmstat that license tokens are available and reported in the next blcollect cycle. This results in higher license utilization for short jobs.Cluster mode was introduced in License Scheduler 8.0. project mode Distributes license token to projects configured across all clusters.Project mode emphasizes ownership of license tokens by specific projects which span multiple clusters. When License Scheduler is running in project mode, License Scheduler checks demand from license owners across all LSF clusters before allocating license tokens in project mode. The process of collecting and evaluating demand for all projects in all clusters slows down each scheduling cycle. License tokens are distributed in the next scheduling cycle after lmstat or rlmstat confirms license token availability.Project mode was the only choice available before License Scheduler 8.0. Difference between cluster mode and project mode The following figure illustrates license utilization in cluster mode for short jobs with the corresponding lmstat or rlmstat reporting times: In cluster mode, when one job finishes running, the next job gets its license immediately without having to wait for the next lmstat or rlmstat interval. For example, four jobs that require license 2 are able to run without waiting for lmstat or rlmstat to report token distribution. The following figure illustrates license utilization in project mode for short jobs with the lmstat or rlmstat reporting times: In project mode, each job must wait for lmstat or rlmstat to report token distribution before it can get a license and start running. In this example, three jobs that require license 2 are able to start within the lmstat or rlmstat intervals illustrated. When to use cluster mode Cluster mode is most appropriate for your needs if: Your primary goal is to maximize license use. Ownership of licenses is a secondary consideration. Many jobs are short relative to the blcollect cycle (60 seconds by default, set by LM_STAT_INTERVAL). When to use project mode Project mode is most appropriate for your needs if the following applies: Your primary goal is to ensure ownership of the group. Maximizing license use is a secondary consideration. Most jobs are long relative to the blcollect cycle (60 seconds by default, set by LM_STAT_INTERVAL). © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:18:31 "},"chapter10/section3/Project groups.html":{"url":"chapter10/section3/Project groups.html","title":"项目组","keywords":"","body":"Project groups When you are configuring your installation of License Scheduler in project mode, you can choose to configure projects, or extend your project configuration further to form hierarchical project groups. Project groups pool multiple service domains together and treat them as one source for licenses, and distribute them in a hierarchical fairshare tree. The leaves of the policy tree are the license projects that jobs can belong to. Each project group in the tree has a set of values, including shares and limits. License ownership is applied at the leaf level; that is, on individual license projects. Ownership of a given internal node equals to sum of the ownership of all of its direct children. Each feature has its own hierarchical group, but features can share hierarchy. The hierarchical scheduling is done per feature across service domains. projects Projects alone apply one distribution policy within one service domain. The same local distribution policy can be applied to more than one service domain, but is implemented locally. groups of projects Groups of projects apply one distribution policy within one service domain, but assign shares and ownership to groups of projects for greater flexibility. With group license ownership, projects trigger preemption either when the project is using fewer licenses than it owns or when the group to which the project belongs is using fewer licenses than the group owns. project groups Projects groups apply one distribution policy across multiple service domains following the configured hierarchical structure. You can also use project groups to apply hard limits to the number of licenses that are distributed to each project.After configuration, the same project group hierarchy can be used for more than one feature. When to use groups of projects Grouping projects together in project mode is most appropriate for your needs if: Licenses are owned at multiple levels, for example by a department and also by projects within the department. License ownership is within one service domain. As for ungrouped projects, distribution policies are implemented locally for groups of projects. When to use project groups Extending your configuration to include project groups is most appropriate for your needs if: License ownership spans service domains. One distribution policy must be applied across several service domains. Project limits must be applied across clusters. NoteIf required, use LSF to configure license project limits within one cluster. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:18:44 "},"chapter10/section3/Service domains in License Scheduler.html":{"url":"chapter10/section3/Service domains in License Scheduler.html","title":"License Scheduler 中的服务域","keywords":"","body":"Service domains in License Scheduler A service domain is a group of one or more license servers. License Scheduler manages the scheduling of the license tokens, but the license server actually supplies the licenses. You configure the service domain with the license server names and port numbers that serve licenses to a network. LAN: a service domain that serves licenses to a single cluster WAN: a sevice domain that serves licenses to multiple clusters License Scheduler assumes that any license in the service domain is available to any user who can receive a token from License Scheduler. Therefore, every user that is associated with a project specified in the distribution policy must meet the following requirements: The user is able to make a network connection to every license server host in the service domain. The user environment is configured with permissions to check out the license from every license server host in the service domain. You must configure at least one service domain for License Scheduler. It groups license server hosts that serve licenses to LSF jobs and is used when you define a policy for sharing software licenses among your projects. If a license server is not part of a License Scheduler service domain, its licenses are not managed by License Scheduler (the license distribution policies you configure in LSF do not apply to these licenses and usage of these licenses does not influence LSF scheduling decisions). Service domain locality You can use license feature locality to limit features from different service domains to a specific cluster so that License Scheduler does not grant tokens to jobs from license that legally cannot be used on the cluster that requested the token. The LAN service domains that are used in cluster mode are configured with single-cluster locality. Project mode In project mode, a cluster can access the same license feature from multiple service domains. If your license servers restrict the serving of license tokens to specific geographical locations, use LOCAL_TO to specify the locality of a license token for any features that cannot be shared across all the locations. This parameter avoids having to define different distribution and allocation policies for different service domains, and allows hierarchical project group configurations. To use License Scheduler tokens in project mode, a job submission must specify the -Lp (license project) option. The project must be defined for the requested feature in lsf.licensescheduler. Cluster mode In cluster mode, each license feature in a cluster can access a single license feature from at most one WAN and one LAN service domain. License Scheduler does not control application checkout behavior. If the same license is available from both the LAN and WAN service domains, License Scheduler expects jobs to try to obtain the license from the LAN first. Parallel jobs When LSF dispatches a parallel job, LSF License Scheduler attempts to check out user@host keys in the parallel job constructed using the user name and all execution host names, and merges the corresponding checkout information on the service domain if found. For example, in project mode, for feature F1 with two projects (P1 and P2) in service domain sd1, with ten tokens, a parallel job is dispatched to four execution hosts using the following command: bsub -n 4 -Lp P1 -R \"rusage[F1=4]\" mycmd The job on each execution host checks out one F1 license from the sd1 service domain. If the four execution hosts are hostA, hostB, hostC, and hostD, there are checkout keys for user@hostA, user@hostB, user@hostC, and user@hostD, and each entry contributes corresponds with one token checked out. These tokens all merge into data for the P1 project in the F1 feature. Therefore, running blstat displays the following information for the F1 feature: FEATURE: F1 SERVICE_DOMAIN: LanServer TOTAL_INUSE: 4 TOTAL_RESERVE: 0 TOTAL_FREE: 6 OTHERS: 0 PROJECT SHARE OWN INUSE RESERVE FREE DEMAND P1 50.0 % 0 4 0 1 0 P2 50.0 % 0 0 0 5 0 The four checkout keys from the four execution hosts are merged into the P1 project. If MERGE_BY_SERVICE_DOMAIN=Y is defined, LSF License Scheduler also merges multiple user@host data for parallel jobs across different service domains. For example, if you have the same setup as the previous example, but with an additional service domain sd2 also with two projects (P1 and P2) and ten tokens, and you have MERGE_BY_SERVICE_DOMAIN=Y defined, running blstat displays the following information for the F1 feature: blstat FEATURE: F1 SERVICE_DOMAIN: sd1 TOTAL_INUSE: 2 TOTAL_RESERVE: 0 TOTAL_FREE: 8 OTHERS: 0 PROJECT SHARE OWN INUSE RESERVE FREE DEMAND P1 50.0 % 0 2 0 3 0 P2 50.0 % 0 0 0 5 0 SERVICE_DOMAIN: sd2 TOTAL_INUSE: 2 TOTAL_RESERVE: 0 TOTAL_FREE: 8 OTHERS: 0 PROJECT SHARE OWN INUSE RESERVE FREE DEMAND P1 50.0 % 0 2 0 3 0 P2 50.0 % 0 0 0 5 0 Two checkout keys are merged into the P1 project in the sd1 domain, while two checkout keys are merged into the P1 project under the sd2 domain. If CHECKOUT_FROM_FIRST_HOST_ONLY=Y is defined, LSF License Scheduler only considers user@host information for the first execution host of a parallel job when merging the license usage data. Setting in individual Feature sections overrides the global setting in the Parameters section. If a feature has multiple Feature sections (using LOCAL_TO), each section must have the same setting for CHECKOUT_FROM_FIRST_HOST_ONLY. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:19:03 "},"chapter10/section3/Distribution policies.html":{"url":"chapter10/section3/Distribution policies.html","title":"发行政策","keywords":"","body":"Distribution policies The most important part of License Scheduler is license token distribution. The license distribution policy determines how license tokens are shared among projects or clusters. Whenever there is competition, the configured share assignment determines the portion of license tokens each project or cluster is entitled to. We refer to both licenses and license tokens because License Scheduler does not control licenses directly. Instead, it controls the dispatch of jobs that require licenses that are submitted through LSF or taskman by tracking license tokens. Total license tokens The total number of license tokens that are managed by License Scheduler for a single feature in one service domain depends on the following factors: The number of active license servers in the service domain The number of licenses that are checked out by applications that are not managed by LSF License shares License shares that are assigned in the distribution policy determine what portion of total licenses a project (in project mode) or cluster (in cluster mode) receives. Each project or cluster able to use a license feature must have a share of the license feature in the service domain. The formula for converting a number of shares to a number of licenses for any license feature is: (shares assigned to project or cluster) ______________________________ x (total number of licenses) (sum of all shares assigned) The number of shares that are assigned to a license project or cluster is only meaningful when you compare it to the number assigned to other projects or clusters, or to the total number of shares. When there are no jobs in the system, each project or cluster is assigned license tokens that are based on share assignments. Parent topic: LSF License Scheduler concepts Cluster mode distribution policies static A portion of the total licenses is allocated to the cluster based on the configured share. The amount is static, and does not depend on the workload in the system. dynamic Shares of the total licenses are assigned to each cluster, along with a buffer size. The configured shares set the number of licenses each cluster receives initially, but this number is adjusted regularly based on demand from the cluster.License distribution changes whenever a cluster requests an allocation update, by default every 15 seconds. In each update, the allocation can increase by as much as the buffer size. There is no restriction on decreasing cluster allocation.When dynamic license distribution is used in cluster mode, minimum and maximum allocation values can be configured for each cluster. The minimum allocation is like the number of non-shared licenses for project mode, as this number of tokens is reserved for the exclusive use of the cluster.If the minimum value configured exceeds the share assignment for the cluster, only the assigned share is reserved for the cluster.Cluster shares take precedence over minimum allocations configured. If the minimum allocation exceeds the cluster's share of the total tokens, a cluster's allocation as given by bld may be less than the configured minimum allocation. guarantees within a cluster Guaranteed shares of licenses are assigned to projects within a cluster that use LSF guarantee-type SLAs. Optionally, sharing of guaranteed licenses not in use can be configured.Guarantees are like ownership for cluster mode, and can be used with both static and dynamic distribution policies.NoteGuarantee-type SLAs are only available in LSF version 8.0 or newer. When to use static license distribution Configure shares for all license features in cluster mode. Static license distribution is the basic license distribution policy, and is built on by adding more configuration. The basic static configuration can meet your needs if the demand for licenses across clusters is predictable and unchanging, or licenses are strictly owned by clusters, or you always have extra licenses. When to use dynamic license distribution Dynamic license allocation can meet your needs if the demand for licenses changes across clusters. When to use LSF guarantee SLAs with License Scheduler Configuring guarantee SLAs within LSF clusters can meet your needs if the licenses within a cluster are owned, and used either preferentially or exclusively by the license owners. Project mode distribution policies fairshare Shares of the total licenses are assigned to each license project.Unused licenses are shared wherever there is demand, however, when demand exceeds the number of licenses, share assignments are followed. Jobs are not preempted to redistribute licenses; instead licenses are redistributed when jobs finish running. ownership and preemption Shares of the total licenses are assigned to each license project. Owned shares of licenses are also assigned.Unused licenses are shared wherever there is demand, however, when demand exceeds the number of licenses, the owned share is reclaimed using preemption.Preemption occurs only while the specified number of owned licenses are not yet in use, and no free licenses are available. Once all owned licenses are used, License Scheduler waits for licenses to become free (instead of using preemption) and then distributes more tokens until the share is reached.Jobs that are preempted by License Scheduler are automatically resumed once licenses become available.By default, LSF releases the job slot of a suspended job when License Scheduler preempts the license from the job.NoteFor License Scheduler to give a license token to another project, the applications must be able to release their licenses upon job suspension. active ownership Active ownership allows ownership to automatically adjust based on project activity. Ownership is expressed as a percent of the total ownership for active projects. The actual ownership for each project decreases as more projects become active. Set percentage ownership values to total more than 100% to benefit from active ownership. non-shared licenses Some licenses are designated as non-shared, and are reserved for exclusive use instead of being shared when not in use.The number of non-shared licenses is contained by the number of owned licenses, but this number is not included in share calculations for the project. To designate some licenses as non-shared, add the non-shared number to both the owned and the non-shared values. When to use fairshare with project mode Configure fairshare for all license features in project mode. Fairshare is the basic license distribution policy, and is built on by adding additional configuration. The basic fairshare configuration can meet your needs without configuring additional distribution policies if the licenses are assigned to specific license projects, but not strictly owned. When to add ownership (and preemption) Configure licenses as owned when: Licenses are owned by licenses projects, but can be loaned out when not in use. Maximizing license usage and license ownership are both important considerations. Loaned licenses must be returned to the owners as quickly as possible when needed (using preemption). Jobs borrowing licenses can be preempted. When to add active ownership Configure active ownership for owned licenses when: Ownership values are dynamic instead of being fixed values, and usually decrease as more projects actively seek licenses. When to add non-shared licenses Configure licenses as non-shared when: Licenses are owned. Licenses are used exclusively by the owners. Having licenses always available to the owners is more important than maximizing license use. © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:16:50 "},"chapter10/section3/subsection1/Project mode preemption.html":{"url":"chapter10/section3/subsection1/Project mode preemption.html","title":"项目模式抢占","keywords":"","body":"Project mode preemption © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection1/Preemption restrictions.html":{"url":"chapter10/section3/subsection1/Preemption restrictions.html","title":"抢占限制","keywords":"","body":"Preemption restrictions © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection1/LSF preemption with License Scheduler preemption.html":{"url":"chapter10/section3/subsection1/LSF preemption with License Scheduler preemption.html","title":"LSF 抢占与 License Scheduler 抢占","keywords":"","body":"LSF preemption with License Scheduler preemption © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection2/License usage with FlexNet and Reprise License Manager.html":{"url":"chapter10/section3/subsection2/License usage with FlexNet and Reprise License Manager.html","title":"FlexNet 和 Reprise License Manager的许可证使用情况","keywords":"","body":"License usage with FlexNet and Reprise License Manager © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection2/Known license requirements.html":{"url":"chapter10/section3/subsection2/Known license requirements.html","title":"已知许可要求","keywords":"","body":"Known license requirements © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection2/Unknown license requirements.html":{"url":"chapter10/section3/subsection2/Unknown license requirements.html","title":"未知许可要求","keywords":"","body":"Unknown license requirements © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection2/Project mode.html":{"url":"chapter10/section3/subsection2/Project mode.html","title":"项目模式","keywords":"","body":"Project mode © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection2/Cluster mode.html":{"url":"chapter10/section3/subsection2/Cluster mode.html","title":"集群模式","keywords":"","body":"Cluster mode © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section3/subsection2/Reserved FlexNet Manager licenses.html":{"url":"chapter10/section3/subsection2/Reserved FlexNet Manager licenses.html","title":"保留的 FlexNet Manager 许可证","keywords":"","body":"Reserved FlexNet Manager licenses © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/Configuring License Scheduler.html":{"url":"chapter10/section4/Configuring License Scheduler.html","title":"配置许可证调度程序","keywords":"","body":"配置许可证调度程序 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:37:52 "},"chapter10/section4/Configure cluster mode.html":{"url":"chapter10/section4/Configure cluster mode.html","title":"配置集群模式","keywords":"","body":"Configure cluster mode © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/Configure cluster mode with guarantees.html":{"url":"chapter10/section4/Configure cluster mode with guarantees.html","title":"保证配置集群模式","keywords":"","body":"Configure cluster mode with guarantees © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/Project mode with projects.html":{"url":"chapter10/section4/Project mode with projects.html","title":"项目模式与项目","keywords":"","body":"Project mode with projects © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/Project mode optional settings.html":{"url":"chapter10/section4/Project mode optional settings.html","title":"项目模式可选设置","keywords":"","body":"Project mode optional settings © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/Project mode with project groups.html":{"url":"chapter10/section4/Project mode with project groups.html","title":"项目组的项目模式","keywords":"","body":"Project mode with project groups © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection1/Configure fast dispatch project mode.html":{"url":"chapter10/section4/subsection1/Configure fast dispatch project mode.html","title":"配置快速调度项目模式","keywords":"","body":"Configure fast dispatch project mode © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection1/Configure lmremove or rlmremove preemption.html":{"url":"chapter10/section4/subsection1/Configure lmremove or rlmremove preemption.html","title":"配置lmremove或rlmremove抢占","keywords":"","body":"Configure lmremove or rlmremove preemption © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/Automatic time-based configuration.html":{"url":"chapter10/section4/Automatic time-based configuration.html","title":"基于时间的自动配置","keywords":"","body":"Automatic time-based configuration © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/Failover.html":{"url":"chapter10/section4/subsection2/Failover.html","title":"故障转移","keywords":"","body":"Failover © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/Failover provisioning for LANs.html":{"url":"chapter10/section4/subsection2/Failover provisioning for LANs.html","title":"局域网的故障转移配置","keywords":"","body":"Failover provisioning for LANs © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/Failover provisioning for WANs.html":{"url":"chapter10/section4/subsection2/Failover provisioning for WANs.html","title":"外网的故障转移配置","keywords":"","body":"Failover provisioning for WANs © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/Configure and start License Scheduler in a WAN.html":{"url":"chapter10/section4/subsection2/Configure and start License Scheduler in a WAN.html","title":"在 WAN 中配置并启动 License Scheduler","keywords":"","body":"Configure and start License Scheduler in a WAN © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/WAN example.html":{"url":"chapter10/section4/subsection2/WAN example.html","title":"WAN 示例","keywords":"","body":"WAN example © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/Service provisioning at the host and network levels.html":{"url":"chapter10/section4/subsection2/Service provisioning at the host and network levels.html","title":"主机和网络级别的服务供应","keywords":"","body":"Service provisioning at the host and network levels © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/subsection2/Set up fod.html":{"url":"chapter10/section4/subsection2/Set up fod.html","title":"设置 fod","keywords":"","body":"Set up fod © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section4/User authentication.html":{"url":"chapter10/section4/User authentication.html","title":"用户认证","keywords":"","body":"User authentication © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/Viewing information and troubleshooting.html":{"url":"chapter10/section5/Viewing information and troubleshooting.html","title":"查看信息和故障排除","keywords":"","body":"查看信息和故障排除 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-21 10:37:52 "},"chapter10/section5/subsection1/About viewing available licenses.html":{"url":"chapter10/section5/subsection1/About viewing available licenses.html","title":"关于查看可用许可证","keywords":"","body":"About viewing available licenses © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection1/View license server and license feature information passed to jobs.html":{"url":"chapter10/section5/subsection1/View license server and license feature information passed to jobs.html","title":"查看传递给作业的许可证服务器和许可证功能信息","keywords":"","body":"View license server and license feature information passed to jobs © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection1/Customize dynamic license information output.html":{"url":"chapter10/section5/subsection1/Customize dynamic license information output.html","title":"自定义动态许可证信息输出","keywords":"","body":"Customize dynamic license information output © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection2/About error logs.html":{"url":"chapter10/section5/subsection2/About error logs.html","title":"关于错误日志","keywords":"","body":"About error logs © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection2/Manage log files.html":{"url":"chapter10/section5/subsection2/Manage log files.html","title":"管理日志文件","keywords":"","body":"Manage log files © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection2/Temporarily change the log level.html":{"url":"chapter10/section5/subsection2/Temporarily change the log level.html","title":"临时更改日志级别","keywords":"","body":"Temporarily change the log level © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection3/Troubleshooting.html":{"url":"chapter10/section5/subsection3/Troubleshooting.html","title":"故障排除","keywords":"","body":"Troubleshooting © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection3/File locations.html":{"url":"chapter10/section5/subsection3/File locations.html","title":"文件位置","keywords":"","body":"File locations © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection3/Check that lmstat is supported by blcollect.html":{"url":"chapter10/section5/subsection3/Check that lmstat is supported by blcollect.html","title":"检查 blstat 是否支持 lmstat","keywords":"","body":"Check that lmstat is supported by blcollect © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section5/subsection3/Do not delete lsb.tokens unless you defined a LSF License Scheduler elim.html":{"url":"chapter10/section5/subsection3/Do not delete lsb.tokens unless you defined a LSF License Scheduler elim.html","title":"除非您定义了 LSF License Scheduler elim，否则不要删除lsb.tokens","keywords":"","body":"Do not delete lsb.tokens unless you defined a LSF License Scheduler elim © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:24:21 "},"chapter10/section6/Reference.html":{"url":"chapter10/section6/Reference.html","title":"参考","keywords":"","body":"参考 lsf.licensescheduler lsf.licensescheduler 文件包含 LSF License Scheduler 配置信息。 除 ProjectGroup 之外的所有部分都是必需的。 在集群模式下，也不需要 “Project” 部分。 bladmin IBM Spectrum LSF 许可证计划程序的管理工具。 blcollect LSF License Scheduler 的许可证信息收集守护程序。 blcollect 守护程序收集许可证使用信息。 blcstat 显示来自 LSF License Scheduler 的 blcollect 守护程序的动态更新信息。 blhosts 显示正在运行 LSF License Scheduler 守护程序（bld）的所有主机的名称。 blinfo 显示静态 LSF License Scheduler 配置信息 blkill 终止交互式（taskman）LSF License Scheduler 任务。 blparams 显示有关在文件 lsf.licensescheduler 和 lsf.conf 中定义的可配置 LSF License Scheduler 参数的信息。 blstat 显示动态许可证信息。 bltasks 显示 LSF License Scheduler 交互式任务信息。 blusers 显示 LSF License Scheduler 的许可证使用信息。 fod.conf fod.conf 文件包含 FOD 配置信息。 所有部分都是必需的。 fodadmin 在 FOD 下启动应用程序或关闭 FOD fodapps 显示由 FOD 管理的应用程序的状态。 fodhosts 显示 FOD 主机的状态。 fodid 显示 FOD 主站主机和版本信息。 taskman 签出许可证令牌并管理交互式 UNIX 应用程序。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 10:10:26 "},"chapter10000000000/DRAFT.html":{"url":"chapter10000000000/DRAFT.html","title":"Chapter 10000000000","keywords":"","body":"Chapter 10000000000 草稿 第 10 ~ 12 章内容的构思与取舍 chapter 10 ：侧重于前置知识 chapter 11： 侧重于集群的实际操作经验总结 chapter 12： 侧重于产品的对比分析，行业调研等 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-10 15:04:19 "},"NOTE.html":{"url":"NOTE.html","title":"后记","keywords":"","body":"后记 联系作者 作者技术博客：BYA's Blog 微信：156 5657 5965 （联系请备注：姓名 - 行业 - 原因） 手机：176 2603 7549 邮箱：bya@mail.ustc.edu.cn; baiyongan1507@163.com 更新说明 原则： 具体内容优先级，按工作需求，择重点进行翻译，总结。 长期不定时更新关于 前置知识，行业经验的总结。 要求： 翻译：主要借助谷歌翻译，保证文字流畅。 排版格式：主要参照 《中文技术文档写作规范》 Github Repo：baiyongan/LSF_Doc 工具： 电子书编辑：gitbook、calibre markdown：typora 版本控制：git 内容评估： 更新频率：平均每天一个 section / subsection chapter 1：5 section chapter 2：略 chapter 3：4 section chapter 4：3 section， 6 subsection chapter 5：3 section，7 subsection chapter 6：14 section，66 subsection chapter 7：只链接，不翻译 chapter 8：10 section，9 subsection chapter 9：23 section chapter 10：6 section，8 subsection 译作记录 2020.7.2 开始，配置 gitbook， 预计一个月左右，业余时间完成翻译初稿。将会是一个漫长、寂寞而枯燥的翻译、遣词造句、排版、美化的过程。 | 内容 | 优先级 | 初稿 | 定稿 | | -------------------------------------------------- | ------ | ---------------------- | ---- | | 说明、后记等，目录框架调整 | 高 | 7/2~7/4，7/5 afternoon | Y | | chapter 1 快速入门部分--section 7 | 高 | 7/7 1:00 am | Y | | 每一章的简介 README 部分 | 高 | 7/8 0:30 am, 9:00 am | Y | | chapter 1 增加第一小节 LSF 简介，更新参考资料 | 低 | 7/8 15:00 pm | Y | | chapter 3 普通用户操作基本章节 共4 section | 高 | 7/8 21:00 pm | Y | | 添加附录、参考文献等，临时新增 草稿页面 | 低 | 7/9 9:00 am | N | | chapter 3 section2 | 高 | 7/9 10:00 am | Y | | chapter 3 section 2 & 3 & 草稿页面 | 高 | 7/10 11:00 am 11:30 pm | Y | | chapter 3 section 4 & chapter 4 content | 高 | 7/11 9:00 am | Y | | chapter 2 & 6 content | 中 | 7/12 8:30 am | Y | | chapter 4 section1 | 高 | 7/13 9:30am | Y | | chapter4 section2 subsection1 & chapter 10 added | 高 | 7/21 9:30am | Y | | chapter4 section2 subsection2 & chapter 10 content | 高 | 7/22 9:30am | Y | | chapter 10 content | 高 | 7/23 11:20 pm | Y | | chapter 10 | | | | | | | | | | | | | | | | | | | | chapter 4 管理员基本操作 共 3 section 6subsection | 高 | | | | chapter 5 作业调度管理章节 共 14 section | 高 | | | | chapter 6 集群管理高级操作 | 中高 | | | | chapter 11~ 12 个人经验部分 | 中高 | | | | chapter 7 参考文档 | 中 | | | | chapter 8 LSF 拓展 | 中低 | | | | chapter 9 最佳实践 | 低 | | | | chapter 2 安装、迁移 | 低 | | | | chapter 1 入门介绍完善 | 低 | | | | 全体校验、发布电子版 | 低 | | | 2020.8 开始着重于 同行业应用 的结合，与经验总结。 2020.9 长期优化更新，搜集反馈。 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-27 09:10:20 "},"APPENDIX.html":{"url":"APPENDIX.html","title":"附录","keywords":"","body":"附录 部分关注企业/机构 超算平台 中科大超算中心 全球 Top 500 超级计算机 HPC 云平台 华为云｜高性能计算解决方案 阿里云｜弹性高性能计算 E-HPC EDA 行业相关 华为海思 AI 行业相关 HPC 行业相关 © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-24 11:57:49 "},"REFERENCE.html":{"url":"REFERENCE.html","title":"参考资料","keywords":"","body":"参考资料 主要参考 IBM Spectrum LSF V10.1 documentation Slurm version 20.02. GitBook 文档（中文版） IBM 系列 IBM Knowledge Center IBM 知识中心 IBM Developer IBM 开发者平台 IBM Support Product List IBM 支持团队产品目录 Platform Computing Legacy Documentation Platform Computing PDF 文档 相关 github 项目 IBM Spectrum Computing Public GitHub Respository SchedMD/slurm baiyongan/HPC_LogFile_Analysis © 2020 小白大侠 all right reserved，powered by Gitbook本文修订于： 2020-07-09 10:10:33 "}}